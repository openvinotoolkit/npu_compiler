// automatically generated by the FlatBuffers compiler, do not modify


#ifndef FLATBUFFERS_GENERATED_FILEHEADER_MVCNN_H_
#define FLATBUFFERS_GENERATED_FILEHEADER_MVCNN_H_

#include "flatbuffers/flatbuffers.h"

#include "memoryManagement_generated.h"
#include "structure_generated.h"

namespace MVCNN {

struct Version;
struct VersionT;

struct Resources;
struct ResourcesT;

struct SummaryHeader;
struct SummaryHeaderT;

enum ExecutionFlag {
  ExecutionFlag_INVALID = 0,
  ExecutionFlag_DynamicBarriers = 1,
  ExecutionFlag_Compiled_For_VPU3 = 2,
  ExecutionFlag_MIN = ExecutionFlag_INVALID,
  ExecutionFlag_MAX = ExecutionFlag_Compiled_For_VPU3
};

inline const ExecutionFlag (&EnumValuesExecutionFlag())[3] {
  static const ExecutionFlag values[] = {
    ExecutionFlag_INVALID,
    ExecutionFlag_DynamicBarriers,
    ExecutionFlag_Compiled_For_VPU3
  };
  return values;
}

inline const char * const *EnumNamesExecutionFlag() {
  static const char * const names[] = {
    "INVALID",
    "DynamicBarriers",
    "Compiled_For_VPU3",
    nullptr
  };
  return names;
}

inline const char *EnumNameExecutionFlag(ExecutionFlag e) {
  if (e < ExecutionFlag_INVALID || e > ExecutionFlag_Compiled_For_VPU3) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesExecutionFlag()[index];
}

struct VersionT : public flatbuffers::NativeTable {
  typedef Version TableType;
  uint32_t majorV;
  uint32_t minorV;
  uint32_t patchV;
  std::string hash;
  VersionT()
      : majorV(0),
        minorV(0),
        patchV(0) {
  }
};

struct Version FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef VersionT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_MAJORV = 4,
    VT_MINORV = 6,
    VT_PATCHV = 8,
    VT_HASH = 10
  };
  /// Version of the schema that the graphfile was generated with.
  /// Major Version: Sigificant Architectural Change (This will probably require design documentation and such)
  /// Minor Verson: Regular Release of Graphfile Schema.
  /// Patch Version: Hot-Fixes and Patches if needed.
  uint32_t majorV() const {
    return GetField<uint32_t>(VT_MAJORV, 0);
  }
  uint32_t minorV() const {
    return GetField<uint32_t>(VT_MINORV, 0);
  }
  uint32_t patchV() const {
    return GetField<uint32_t>(VT_PATCHV, 0);
  }
  /// You can provide a string to pin-point the exact commit hash or tag a graphfile came from.
  /// This can be used for other types of labelling if desired.
  const flatbuffers::String *hash() const {
    return GetPointer<const flatbuffers::String *>(VT_HASH);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint32_t>(verifier, VT_MAJORV) &&
           VerifyField<uint32_t>(verifier, VT_MINORV) &&
           VerifyField<uint32_t>(verifier, VT_PATCHV) &&
           VerifyOffset(verifier, VT_HASH) &&
           verifier.VerifyString(hash()) &&
           verifier.EndTable();
  }
  VersionT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(VersionT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<Version> Pack(flatbuffers::FlatBufferBuilder &_fbb, const VersionT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct VersionBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_majorV(uint32_t majorV) {
    fbb_.AddElement<uint32_t>(Version::VT_MAJORV, majorV, 0);
  }
  void add_minorV(uint32_t minorV) {
    fbb_.AddElement<uint32_t>(Version::VT_MINORV, minorV, 0);
  }
  void add_patchV(uint32_t patchV) {
    fbb_.AddElement<uint32_t>(Version::VT_PATCHV, patchV, 0);
  }
  void add_hash(flatbuffers::Offset<flatbuffers::String> hash) {
    fbb_.AddOffset(Version::VT_HASH, hash);
  }
  explicit VersionBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  VersionBuilder &operator=(const VersionBuilder &);
  flatbuffers::Offset<Version> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Version>(end);
    return o;
  }
};

inline flatbuffers::Offset<Version> CreateVersion(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint32_t majorV = 0,
    uint32_t minorV = 0,
    uint32_t patchV = 0,
    flatbuffers::Offset<flatbuffers::String> hash = 0) {
  VersionBuilder builder_(_fbb);
  builder_.add_hash(hash);
  builder_.add_patchV(patchV);
  builder_.add_minorV(minorV);
  builder_.add_majorV(majorV);
  return builder_.Finish();
}

inline flatbuffers::Offset<Version> CreateVersionDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint32_t majorV = 0,
    uint32_t minorV = 0,
    uint32_t patchV = 0,
    const char *hash = nullptr) {
  auto hash__ = hash ? _fbb.CreateString(hash) : 0;
  return MVCNN::CreateVersion(
      _fbb,
      majorV,
      minorV,
      patchV,
      hash__);
}

flatbuffers::Offset<Version> CreateVersion(flatbuffers::FlatBufferBuilder &_fbb, const VersionT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct ResourcesT : public flatbuffers::NativeTable {
  typedef Resources TableType;
  uint32_t upa_shaves;
  int8_t nce1_blocks;
  uint32_t nce2_blocks;
  uint32_t upa_shared_cmx;
  uint32_t nn_cmx_per_slice;
  uint32_t nn_cmx_slice_amount;
  uint32_t ddr_scratch;
  uint32_t arm_freq;
  uint32_t lnn_freq;
  uint32_t lupa_freq;
  uint32_t dpu_freq;
  uint32_t csram_freq;
  uint32_t nncmx_to_ddr_BW;
  uint32_t ddr_to_nncmx_BW;
  uint32_t nncmx_to_upacmx_BW;
  uint32_t upacmx_to_nncmx_BW;
  uint32_t nncmx_to_dpu_BW;
  uint32_t dpu_to_nncmx_BW;
  ResourcesT()
      : upa_shaves(0),
        nce1_blocks(0),
        nce2_blocks(0),
        upa_shared_cmx(0),
        nn_cmx_per_slice(0),
        nn_cmx_slice_amount(0),
        ddr_scratch(0),
        arm_freq(0),
        lnn_freq(0),
        lupa_freq(0),
        dpu_freq(0),
        csram_freq(0),
        nncmx_to_ddr_BW(0),
        ddr_to_nncmx_BW(0),
        nncmx_to_upacmx_BW(0),
        upacmx_to_nncmx_BW(0),
        nncmx_to_dpu_BW(0),
        dpu_to_nncmx_BW(0) {
  }
};

struct Resources FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef ResourcesT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_UPA_SHAVES = 4,
    VT_NCE1_BLOCKS = 6,
    VT_NCE2_BLOCKS = 8,
    VT_UPA_SHARED_CMX = 10,
    VT_NN_CMX_PER_SLICE = 12,
    VT_NN_CMX_SLICE_AMOUNT = 14,
    VT_DDR_SCRATCH = 18,
    VT_ARM_FREQ = 20,
    VT_LNN_FREQ = 22,
    VT_LUPA_FREQ = 24,
    VT_DPU_FREQ = 26,
    VT_CSRAM_FREQ = 28,
    VT_NNCMX_TO_DDR_BW = 30,
    VT_DDR_TO_NNCMX_BW = 32,
    VT_NNCMX_TO_UPACMX_BW = 34,
    VT_UPACMX_TO_NNCMX_BW = 36,
    VT_NNCMX_TO_DPU_BW = 38,
    VT_DPU_TO_NNCMX_BW = 40
  };
  uint32_t upa_shaves() const {
    return GetField<uint32_t>(VT_UPA_SHAVES, 0);
  }
  int8_t nce1_blocks() const {
    return GetField<int8_t>(VT_NCE1_BLOCKS, 0);
  }
  uint32_t nce2_blocks() const {
    return GetField<uint32_t>(VT_NCE2_BLOCKS, 0);
  }
  uint32_t upa_shared_cmx() const {
    return GetField<uint32_t>(VT_UPA_SHARED_CMX, 0);
  }
  uint32_t nn_cmx_per_slice() const {
    return GetField<uint32_t>(VT_NN_CMX_PER_SLICE, 0);
  }
  uint32_t nn_cmx_slice_amount() const {
    return GetField<uint32_t>(VT_NN_CMX_SLICE_AMOUNT, 0);
  }
  uint32_t ddr_scratch() const {
    return GetField<uint32_t>(VT_DDR_SCRATCH, 0);
  }
  uint32_t arm_freq() const {
    return GetField<uint32_t>(VT_ARM_FREQ, 0);
  }
  uint32_t lnn_freq() const {
    return GetField<uint32_t>(VT_LNN_FREQ, 0);
  }
  uint32_t lupa_freq() const {
    return GetField<uint32_t>(VT_LUPA_FREQ, 0);
  }
  uint32_t dpu_freq() const {
    return GetField<uint32_t>(VT_DPU_FREQ, 0);
  }
  uint32_t csram_freq() const {
    return GetField<uint32_t>(VT_CSRAM_FREQ, 0);
  }
  uint32_t nncmx_to_ddr_BW() const {
    return GetField<uint32_t>(VT_NNCMX_TO_DDR_BW, 0);
  }
  uint32_t ddr_to_nncmx_BW() const {
    return GetField<uint32_t>(VT_DDR_TO_NNCMX_BW, 0);
  }
  uint32_t nncmx_to_upacmx_BW() const {
    return GetField<uint32_t>(VT_NNCMX_TO_UPACMX_BW, 0);
  }
  uint32_t upacmx_to_nncmx_BW() const {
    return GetField<uint32_t>(VT_UPACMX_TO_NNCMX_BW, 0);
  }
  uint32_t nncmx_to_dpu_BW() const {
    return GetField<uint32_t>(VT_NNCMX_TO_DPU_BW, 0);
  }
  uint32_t dpu_to_nncmx_BW() const {
    return GetField<uint32_t>(VT_DPU_TO_NNCMX_BW, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint32_t>(verifier, VT_UPA_SHAVES) &&
           VerifyField<int8_t>(verifier, VT_NCE1_BLOCKS) &&
           VerifyField<uint32_t>(verifier, VT_NCE2_BLOCKS) &&
           VerifyField<uint32_t>(verifier, VT_UPA_SHARED_CMX) &&
           VerifyField<uint32_t>(verifier, VT_NN_CMX_PER_SLICE) &&
           VerifyField<uint32_t>(verifier, VT_NN_CMX_SLICE_AMOUNT) &&
           VerifyField<uint32_t>(verifier, VT_DDR_SCRATCH) &&
           VerifyField<uint32_t>(verifier, VT_ARM_FREQ) &&
           VerifyField<uint32_t>(verifier, VT_LNN_FREQ) &&
           VerifyField<uint32_t>(verifier, VT_LUPA_FREQ) &&
           VerifyField<uint32_t>(verifier, VT_DPU_FREQ) &&
           VerifyField<uint32_t>(verifier, VT_CSRAM_FREQ) &&
           VerifyField<uint32_t>(verifier, VT_NNCMX_TO_DDR_BW) &&
           VerifyField<uint32_t>(verifier, VT_DDR_TO_NNCMX_BW) &&
           VerifyField<uint32_t>(verifier, VT_NNCMX_TO_UPACMX_BW) &&
           VerifyField<uint32_t>(verifier, VT_UPACMX_TO_NNCMX_BW) &&
           VerifyField<uint32_t>(verifier, VT_NNCMX_TO_DPU_BW) &&
           VerifyField<uint32_t>(verifier, VT_DPU_TO_NNCMX_BW) &&
           verifier.EndTable();
  }
  ResourcesT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(ResourcesT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<Resources> Pack(flatbuffers::FlatBufferBuilder &_fbb, const ResourcesT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct ResourcesBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_upa_shaves(uint32_t upa_shaves) {
    fbb_.AddElement<uint32_t>(Resources::VT_UPA_SHAVES, upa_shaves, 0);
  }
  void add_nce1_blocks(int8_t nce1_blocks) {
    fbb_.AddElement<int8_t>(Resources::VT_NCE1_BLOCKS, nce1_blocks, 0);
  }
  void add_nce2_blocks(uint32_t nce2_blocks) {
    fbb_.AddElement<uint32_t>(Resources::VT_NCE2_BLOCKS, nce2_blocks, 0);
  }
  void add_upa_shared_cmx(uint32_t upa_shared_cmx) {
    fbb_.AddElement<uint32_t>(Resources::VT_UPA_SHARED_CMX, upa_shared_cmx, 0);
  }
  void add_nn_cmx_per_slice(uint32_t nn_cmx_per_slice) {
    fbb_.AddElement<uint32_t>(Resources::VT_NN_CMX_PER_SLICE, nn_cmx_per_slice, 0);
  }
  void add_nn_cmx_slice_amount(uint32_t nn_cmx_slice_amount) {
    fbb_.AddElement<uint32_t>(Resources::VT_NN_CMX_SLICE_AMOUNT, nn_cmx_slice_amount, 0);
  }
  void add_ddr_scratch(uint32_t ddr_scratch) {
    fbb_.AddElement<uint32_t>(Resources::VT_DDR_SCRATCH, ddr_scratch, 0);
  }
  void add_arm_freq(uint32_t arm_freq) {
    fbb_.AddElement<uint32_t>(Resources::VT_ARM_FREQ, arm_freq, 0);
  }
  void add_lnn_freq(uint32_t lnn_freq) {
    fbb_.AddElement<uint32_t>(Resources::VT_LNN_FREQ, lnn_freq, 0);
  }
  void add_lupa_freq(uint32_t lupa_freq) {
    fbb_.AddElement<uint32_t>(Resources::VT_LUPA_FREQ, lupa_freq, 0);
  }
  void add_dpu_freq(uint32_t dpu_freq) {
    fbb_.AddElement<uint32_t>(Resources::VT_DPU_FREQ, dpu_freq, 0);
  }
  void add_csram_freq(uint32_t csram_freq) {
    fbb_.AddElement<uint32_t>(Resources::VT_CSRAM_FREQ, csram_freq, 0);
  }
  void add_nncmx_to_ddr_BW(uint32_t nncmx_to_ddr_BW) {
    fbb_.AddElement<uint32_t>(Resources::VT_NNCMX_TO_DDR_BW, nncmx_to_ddr_BW, 0);
  }
  void add_ddr_to_nncmx_BW(uint32_t ddr_to_nncmx_BW) {
    fbb_.AddElement<uint32_t>(Resources::VT_DDR_TO_NNCMX_BW, ddr_to_nncmx_BW, 0);
  }
  void add_nncmx_to_upacmx_BW(uint32_t nncmx_to_upacmx_BW) {
    fbb_.AddElement<uint32_t>(Resources::VT_NNCMX_TO_UPACMX_BW, nncmx_to_upacmx_BW, 0);
  }
  void add_upacmx_to_nncmx_BW(uint32_t upacmx_to_nncmx_BW) {
    fbb_.AddElement<uint32_t>(Resources::VT_UPACMX_TO_NNCMX_BW, upacmx_to_nncmx_BW, 0);
  }
  void add_nncmx_to_dpu_BW(uint32_t nncmx_to_dpu_BW) {
    fbb_.AddElement<uint32_t>(Resources::VT_NNCMX_TO_DPU_BW, nncmx_to_dpu_BW, 0);
  }
  void add_dpu_to_nncmx_BW(uint32_t dpu_to_nncmx_BW) {
    fbb_.AddElement<uint32_t>(Resources::VT_DPU_TO_NNCMX_BW, dpu_to_nncmx_BW, 0);
  }
  explicit ResourcesBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  ResourcesBuilder &operator=(const ResourcesBuilder &);
  flatbuffers::Offset<Resources> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Resources>(end);
    return o;
  }
};

inline flatbuffers::Offset<Resources> CreateResources(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint32_t upa_shaves = 0,
    int8_t nce1_blocks = 0,
    uint32_t nce2_blocks = 0,
    uint32_t upa_shared_cmx = 0,
    uint32_t nn_cmx_per_slice = 0,
    uint32_t nn_cmx_slice_amount = 0,
    uint32_t ddr_scratch = 0,
    uint32_t arm_freq = 0,
    uint32_t lnn_freq = 0,
    uint32_t lupa_freq = 0,
    uint32_t dpu_freq = 0,
    uint32_t csram_freq = 0,
    uint32_t nncmx_to_ddr_BW = 0,
    uint32_t ddr_to_nncmx_BW = 0,
    uint32_t nncmx_to_upacmx_BW = 0,
    uint32_t upacmx_to_nncmx_BW = 0,
    uint32_t nncmx_to_dpu_BW = 0,
    uint32_t dpu_to_nncmx_BW = 0) {
  ResourcesBuilder builder_(_fbb);
  builder_.add_dpu_to_nncmx_BW(dpu_to_nncmx_BW);
  builder_.add_nncmx_to_dpu_BW(nncmx_to_dpu_BW);
  builder_.add_upacmx_to_nncmx_BW(upacmx_to_nncmx_BW);
  builder_.add_nncmx_to_upacmx_BW(nncmx_to_upacmx_BW);
  builder_.add_ddr_to_nncmx_BW(ddr_to_nncmx_BW);
  builder_.add_nncmx_to_ddr_BW(nncmx_to_ddr_BW);
  builder_.add_csram_freq(csram_freq);
  builder_.add_dpu_freq(dpu_freq);
  builder_.add_lupa_freq(lupa_freq);
  builder_.add_lnn_freq(lnn_freq);
  builder_.add_arm_freq(arm_freq);
  builder_.add_ddr_scratch(ddr_scratch);
  builder_.add_nn_cmx_slice_amount(nn_cmx_slice_amount);
  builder_.add_nn_cmx_per_slice(nn_cmx_per_slice);
  builder_.add_upa_shared_cmx(upa_shared_cmx);
  builder_.add_nce2_blocks(nce2_blocks);
  builder_.add_upa_shaves(upa_shaves);
  builder_.add_nce1_blocks(nce1_blocks);
  return builder_.Finish();
}

flatbuffers::Offset<Resources> CreateResources(flatbuffers::FlatBufferBuilder &_fbb, const ResourcesT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct SummaryHeaderT : public flatbuffers::NativeTable {
  typedef SummaryHeader TableType;
  std::unique_ptr<VersionT> version;
  std::string identifier;
  std::vector<std::unique_ptr<TensorReferenceT>> net_input;
  std::vector<std::unique_ptr<TensorReferenceT>> net_output;
  uint32_t task_count;
  uint32_t layer_count;
  std::vector<ExecutionFlag> options;
  std::unique_ptr<ResourcesT> resources;
  std::unique_ptr<SourceStructureT> original_structure;
  SummaryHeaderT()
      : task_count(0),
        layer_count(0) {
  }
};

struct SummaryHeader FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef SummaryHeaderT NativeTableType;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VERSION = 4,
    VT_IDENTIFIER = 6,
    VT_NET_INPUT = 8,
    VT_NET_OUTPUT = 10,
    VT_TASK_COUNT = 12,
    VT_LAYER_COUNT = 14,
    VT_OPTIONS = 16,
    VT_RESOURCES = 18,
    VT_ORIGINAL_STRUCTURE = 20
  };
  const Version *version() const {
    return GetPointer<const Version *>(VT_VERSION);
  }
  const flatbuffers::String *identifier() const {
    return GetPointer<const flatbuffers::String *>(VT_IDENTIFIER);
  }
  const flatbuffers::Vector<flatbuffers::Offset<TensorReference>> *net_input() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<TensorReference>> *>(VT_NET_INPUT);
  }
  const flatbuffers::Vector<flatbuffers::Offset<TensorReference>> *net_output() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<TensorReference>> *>(VT_NET_OUTPUT);
  }
  uint32_t task_count() const {
    return GetField<uint32_t>(VT_TASK_COUNT, 0);
  }
  uint32_t layer_count() const {
    return GetField<uint32_t>(VT_LAYER_COUNT, 0);
  }
  const flatbuffers::Vector<int8_t> *options() const {
    return GetPointer<const flatbuffers::Vector<int8_t> *>(VT_OPTIONS);
  }
  const Resources *resources() const {
    return GetPointer<const Resources *>(VT_RESOURCES);
  }
  const SourceStructure *original_structure() const {
    return GetPointer<const SourceStructure *>(VT_ORIGINAL_STRUCTURE);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_VERSION) &&
           verifier.VerifyTable(version()) &&
           VerifyOffset(verifier, VT_IDENTIFIER) &&
           verifier.VerifyString(identifier()) &&
           VerifyOffset(verifier, VT_NET_INPUT) &&
           verifier.VerifyVector(net_input()) &&
           verifier.VerifyVectorOfTables(net_input()) &&
           VerifyOffset(verifier, VT_NET_OUTPUT) &&
           verifier.VerifyVector(net_output()) &&
           verifier.VerifyVectorOfTables(net_output()) &&
           VerifyField<uint32_t>(verifier, VT_TASK_COUNT) &&
           VerifyField<uint32_t>(verifier, VT_LAYER_COUNT) &&
           VerifyOffset(verifier, VT_OPTIONS) &&
           verifier.VerifyVector(options()) &&
           VerifyOffset(verifier, VT_RESOURCES) &&
           verifier.VerifyTable(resources()) &&
           VerifyOffset(verifier, VT_ORIGINAL_STRUCTURE) &&
           verifier.VerifyTable(original_structure()) &&
           verifier.EndTable();
  }
  SummaryHeaderT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(SummaryHeaderT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<SummaryHeader> Pack(flatbuffers::FlatBufferBuilder &_fbb, const SummaryHeaderT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct SummaryHeaderBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_version(flatbuffers::Offset<Version> version) {
    fbb_.AddOffset(SummaryHeader::VT_VERSION, version);
  }
  void add_identifier(flatbuffers::Offset<flatbuffers::String> identifier) {
    fbb_.AddOffset(SummaryHeader::VT_IDENTIFIER, identifier);
  }
  void add_net_input(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<TensorReference>>> net_input) {
    fbb_.AddOffset(SummaryHeader::VT_NET_INPUT, net_input);
  }
  void add_net_output(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<TensorReference>>> net_output) {
    fbb_.AddOffset(SummaryHeader::VT_NET_OUTPUT, net_output);
  }
  void add_task_count(uint32_t task_count) {
    fbb_.AddElement<uint32_t>(SummaryHeader::VT_TASK_COUNT, task_count, 0);
  }
  void add_layer_count(uint32_t layer_count) {
    fbb_.AddElement<uint32_t>(SummaryHeader::VT_LAYER_COUNT, layer_count, 0);
  }
  void add_options(flatbuffers::Offset<flatbuffers::Vector<int8_t>> options) {
    fbb_.AddOffset(SummaryHeader::VT_OPTIONS, options);
  }
  void add_resources(flatbuffers::Offset<Resources> resources) {
    fbb_.AddOffset(SummaryHeader::VT_RESOURCES, resources);
  }
  void add_original_structure(flatbuffers::Offset<SourceStructure> original_structure) {
    fbb_.AddOffset(SummaryHeader::VT_ORIGINAL_STRUCTURE, original_structure);
  }
  explicit SummaryHeaderBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  SummaryHeaderBuilder &operator=(const SummaryHeaderBuilder &);
  flatbuffers::Offset<SummaryHeader> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<SummaryHeader>(end);
    return o;
  }
};

inline flatbuffers::Offset<SummaryHeader> CreateSummaryHeader(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<Version> version = 0,
    flatbuffers::Offset<flatbuffers::String> identifier = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<TensorReference>>> net_input = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<TensorReference>>> net_output = 0,
    uint32_t task_count = 0,
    uint32_t layer_count = 0,
    flatbuffers::Offset<flatbuffers::Vector<int8_t>> options = 0,
    flatbuffers::Offset<Resources> resources = 0,
    flatbuffers::Offset<SourceStructure> original_structure = 0) {
  SummaryHeaderBuilder builder_(_fbb);
  builder_.add_original_structure(original_structure);
  builder_.add_resources(resources);
  builder_.add_options(options);
  builder_.add_layer_count(layer_count);
  builder_.add_task_count(task_count);
  builder_.add_net_output(net_output);
  builder_.add_net_input(net_input);
  builder_.add_identifier(identifier);
  builder_.add_version(version);
  return builder_.Finish();
}

inline flatbuffers::Offset<SummaryHeader> CreateSummaryHeaderDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<Version> version = 0,
    const char *identifier = nullptr,
    const std::vector<flatbuffers::Offset<TensorReference>> *net_input = nullptr,
    const std::vector<flatbuffers::Offset<TensorReference>> *net_output = nullptr,
    uint32_t task_count = 0,
    uint32_t layer_count = 0,
    const std::vector<int8_t> *options = nullptr,
    flatbuffers::Offset<Resources> resources = 0,
    flatbuffers::Offset<SourceStructure> original_structure = 0) {
  auto identifier__ = identifier ? _fbb.CreateString(identifier) : 0;
  auto net_input__ = net_input ? _fbb.CreateVector<flatbuffers::Offset<TensorReference>>(*net_input) : 0;
  auto net_output__ = net_output ? _fbb.CreateVector<flatbuffers::Offset<TensorReference>>(*net_output) : 0;
  auto options__ = options ? _fbb.CreateVector<int8_t>(*options) : 0;
  return MVCNN::CreateSummaryHeader(
      _fbb,
      version,
      identifier__,
      net_input__,
      net_output__,
      task_count,
      layer_count,
      options__,
      resources,
      original_structure);
}

flatbuffers::Offset<SummaryHeader> CreateSummaryHeader(flatbuffers::FlatBufferBuilder &_fbb, const SummaryHeaderT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

inline VersionT *Version::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = new VersionT();
  UnPackTo(_o, _resolver);
  return _o;
}

inline void Version::UnPackTo(VersionT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = majorV(); _o->majorV = _e; };
  { auto _e = minorV(); _o->minorV = _e; };
  { auto _e = patchV(); _o->patchV = _e; };
  { auto _e = hash(); if (_e) _o->hash = _e->str(); };
}

inline flatbuffers::Offset<Version> Version::Pack(flatbuffers::FlatBufferBuilder &_fbb, const VersionT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateVersion(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<Version> CreateVersion(flatbuffers::FlatBufferBuilder &_fbb, const VersionT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const VersionT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _majorV = _o->majorV;
  auto _minorV = _o->minorV;
  auto _patchV = _o->patchV;
  auto _hash = _o->hash.empty() ? _fbb.CreateSharedString("") : _fbb.CreateString(_o->hash);
  return MVCNN::CreateVersion(
      _fbb,
      _majorV,
      _minorV,
      _patchV,
      _hash);
}

inline ResourcesT *Resources::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = new ResourcesT();
  UnPackTo(_o, _resolver);
  return _o;
}

inline void Resources::UnPackTo(ResourcesT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = upa_shaves(); _o->upa_shaves = _e; };
  { auto _e = nce1_blocks(); _o->nce1_blocks = _e; };
  { auto _e = nce2_blocks(); _o->nce2_blocks = _e; };
  { auto _e = upa_shared_cmx(); _o->upa_shared_cmx = _e; };
  { auto _e = nn_cmx_per_slice(); _o->nn_cmx_per_slice = _e; };
  { auto _e = nn_cmx_slice_amount(); _o->nn_cmx_slice_amount = _e; };
  { auto _e = ddr_scratch(); _o->ddr_scratch = _e; };
  { auto _e = arm_freq(); _o->arm_freq = _e; };
  { auto _e = lnn_freq(); _o->lnn_freq = _e; };
  { auto _e = lupa_freq(); _o->lupa_freq = _e; };
  { auto _e = dpu_freq(); _o->dpu_freq = _e; };
  { auto _e = csram_freq(); _o->csram_freq = _e; };
  { auto _e = nncmx_to_ddr_BW(); _o->nncmx_to_ddr_BW = _e; };
  { auto _e = ddr_to_nncmx_BW(); _o->ddr_to_nncmx_BW = _e; };
  { auto _e = nncmx_to_upacmx_BW(); _o->nncmx_to_upacmx_BW = _e; };
  { auto _e = upacmx_to_nncmx_BW(); _o->upacmx_to_nncmx_BW = _e; };
  { auto _e = nncmx_to_dpu_BW(); _o->nncmx_to_dpu_BW = _e; };
  { auto _e = dpu_to_nncmx_BW(); _o->dpu_to_nncmx_BW = _e; };
}

inline flatbuffers::Offset<Resources> Resources::Pack(flatbuffers::FlatBufferBuilder &_fbb, const ResourcesT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateResources(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<Resources> CreateResources(flatbuffers::FlatBufferBuilder &_fbb, const ResourcesT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const ResourcesT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _upa_shaves = _o->upa_shaves;
  auto _nce1_blocks = _o->nce1_blocks;
  auto _nce2_blocks = _o->nce2_blocks;
  auto _upa_shared_cmx = _o->upa_shared_cmx;
  auto _nn_cmx_per_slice = _o->nn_cmx_per_slice;
  auto _nn_cmx_slice_amount = _o->nn_cmx_slice_amount;
  auto _ddr_scratch = _o->ddr_scratch;
  auto _arm_freq = _o->arm_freq;
  auto _lnn_freq = _o->lnn_freq;
  auto _lupa_freq = _o->lupa_freq;
  auto _dpu_freq = _o->dpu_freq;
  auto _csram_freq = _o->csram_freq;
  auto _nncmx_to_ddr_BW = _o->nncmx_to_ddr_BW;
  auto _ddr_to_nncmx_BW = _o->ddr_to_nncmx_BW;
  auto _nncmx_to_upacmx_BW = _o->nncmx_to_upacmx_BW;
  auto _upacmx_to_nncmx_BW = _o->upacmx_to_nncmx_BW;
  auto _nncmx_to_dpu_BW = _o->nncmx_to_dpu_BW;
  auto _dpu_to_nncmx_BW = _o->dpu_to_nncmx_BW;
  return MVCNN::CreateResources(
      _fbb,
      _upa_shaves,
      _nce1_blocks,
      _nce2_blocks,
      _upa_shared_cmx,
      _nn_cmx_per_slice,
      _nn_cmx_slice_amount,
      _ddr_scratch,
      _arm_freq,
      _lnn_freq,
      _lupa_freq,
      _dpu_freq,
      _csram_freq,
      _nncmx_to_ddr_BW,
      _ddr_to_nncmx_BW,
      _nncmx_to_upacmx_BW,
      _upacmx_to_nncmx_BW,
      _nncmx_to_dpu_BW,
      _dpu_to_nncmx_BW);
}

inline SummaryHeaderT *SummaryHeader::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = new SummaryHeaderT();
  UnPackTo(_o, _resolver);
  return _o;
}

inline void SummaryHeader::UnPackTo(SummaryHeaderT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = version(); if (_e) _o->version = std::unique_ptr<VersionT>(_e->UnPack(_resolver)); };
  { auto _e = identifier(); if (_e) _o->identifier = _e->str(); };
  { auto _e = net_input(); if (_e) { _o->net_input.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->net_input[_i] = std::unique_ptr<TensorReferenceT>(_e->Get(_i)->UnPack(_resolver)); } } };
  { auto _e = net_output(); if (_e) { _o->net_output.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->net_output[_i] = std::unique_ptr<TensorReferenceT>(_e->Get(_i)->UnPack(_resolver)); } } };
  { auto _e = task_count(); _o->task_count = _e; };
  { auto _e = layer_count(); _o->layer_count = _e; };
  { auto _e = options(); if (_e) { _o->options.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->options[_i] = static_cast<ExecutionFlag>(_e->Get(_i)); } } };
  { auto _e = resources(); if (_e) _o->resources = std::unique_ptr<ResourcesT>(_e->UnPack(_resolver)); };
  { auto _e = original_structure(); if (_e) _o->original_structure = std::unique_ptr<SourceStructureT>(_e->UnPack(_resolver)); };
}

inline flatbuffers::Offset<SummaryHeader> SummaryHeader::Pack(flatbuffers::FlatBufferBuilder &_fbb, const SummaryHeaderT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateSummaryHeader(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<SummaryHeader> CreateSummaryHeader(flatbuffers::FlatBufferBuilder &_fbb, const SummaryHeaderT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const SummaryHeaderT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _version = _o->version ? CreateVersion(_fbb, _o->version.get(), _rehasher) : 0;
  auto _identifier = _o->identifier.empty() ? _fbb.CreateSharedString("") : _fbb.CreateString(_o->identifier);
  auto _net_input = _fbb.CreateVector<flatbuffers::Offset<TensorReference>> (_o->net_input.size(), [](size_t i, _VectorArgs *__va) { return CreateTensorReference(*__va->__fbb, __va->__o->net_input[i].get(), __va->__rehasher); }, &_va );
  auto _net_output = _fbb.CreateVector<flatbuffers::Offset<TensorReference>> (_o->net_output.size(), [](size_t i, _VectorArgs *__va) { return CreateTensorReference(*__va->__fbb, __va->__o->net_output[i].get(), __va->__rehasher); }, &_va );
  auto _task_count = _o->task_count;
  auto _layer_count = _o->layer_count;
  auto _options = _fbb.CreateVectorScalarCast<int8_t>(flatbuffers::data(_o->options), _o->options.size());
  auto _resources = _o->resources ? CreateResources(_fbb, _o->resources.get(), _rehasher) : 0;
  auto _original_structure = _o->original_structure ? CreateSourceStructure(_fbb, _o->original_structure.get(), _rehasher) : 0;
  return MVCNN::CreateSummaryHeader(
      _fbb,
      _version,
      _identifier,
      _net_input,
      _net_output,
      _task_count,
      _layer_count,
      _options,
      _resources,
      _original_structure);
}

}  // namespace MVCNN

#endif  // FLATBUFFERS_GENERATED_FILEHEADER_MVCNN_H_
