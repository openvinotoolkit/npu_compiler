//
// Copyright 2019 Intel Corporation.
//
// This software and the related documents are Intel copyrighted materials,
// and your use of them is governed by the express license under which they
// were provided to you (End User License Agreement for the Intel(R) Software
// Development Products (Version May 2017)). Unless the License provides
// otherwise, you may not use, modify, copy, publish, distribute, disclose or
// transmit this software or the related documents without Intel's prior
// written permission.
//
// This software and the related documents are provided as is, with no
// express or implied warranties, other than those that are expressly
// stated in the License.
//

#include <fstream>
#include <vector>
#include <string>

#include <inference_engine.hpp>

#include <samples/common.hpp>
#include <samples/args_helper.hpp>
#include <samples/classification_results.h>

#include "classification_sample.h"

using namespace InferenceEngine;

ConsoleErrorListener error_listener;

bool ParseAndCheckCommandLine(int argc, char *argv[]) {
    // ---------------------------Parsing and validation of input args--------------------------------------
    gflags::ParseCommandLineNonHelpFlags(&argc, &argv, true);
    if (FLAGS_h) {
        showUsage();
        return false;
    }
    slog::info << "Parsing input parameters" << slog::endl;

    if (FLAGS_i.empty()) {
        throw std::logic_error("Parameter -i is not set");
    }

    if (FLAGS_m.empty()) {
        throw std::logic_error("Parameter -m is not set");
    }

    return true;
}

bool readBinaryFile(std::string input_binary, std::string& data) {
    std::ifstream in(input_binary, std::ios_base::binary | std::ios_base::ate);

    size_t sizeFile = in.tellg();
    in.seekg(0, std::ios_base::beg);
    data.resize(sizeFile);
    bool status = false;
    if(in.good()) {
        in.read(&data.front(), sizeFile);
        status = true;
    }
    return status;
}

/**
* @brief The entry point the Inference Engine sample application
* @file classification_sample/main.cpp
* @example classification_sample/main.cpp
*/
int main(int argc, char *argv[]) {
    try {
        slog::info << "InferenceEngine: " << GetInferenceEngineVersion() << slog::endl;

        // ------------------------------ Parsing and validation of input args ---------------------------------
        if (!ParseAndCheckCommandLine(argc, argv)) {
            return 0;
        }

        /** This vector stores paths to the processed images **/
        std::vector<std::string> imageNames;
        parseInputFilesArguments(imageNames);
        if (imageNames.empty()) throw std::logic_error("No suitable images were found");

        // -----------------------------------------------------------------------------------------------------

        // --------------------------- 1. Load inference engine -------------------------------------
        slog::info << "Creating Inference Engine" << slog::endl;
        Core ie;

        if (FLAGS_p_msg) {
            ie.SetLogCallback(error_listener);
        }

        // -----------------------------------------------------------------------------------------------------

        // --------------------------- 2. Read blob Generated by MCM Compiler ----------------------------------
        std::string binFileName = FLAGS_m;
        slog::info << "Loading blob:\t" << binFileName << slog::endl;

        InferenceEngine::IExecutableNetwork::Ptr importedNetworkPtr = ie.ImportNetwork(binFileName, "KMB", {});
        if (importedNetworkPtr == nullptr) {
            throw std::logic_error("ImportNetwork failed");
        }
        // -----------------------------------------------------------------------------------------------------

        // --------------------------- 3. Configure input & output ---------------------------------------------
        InferenceEngine::ResponseDesc response;
        ConstInputsDataMap inputInfo;
        importedNetworkPtr->GetInputsInfo(inputInfo, &response);
        if (inputInfo.size() != 1) throw std::logic_error("Sample supports topologies only with 1 input");

        std::vector<std::string> imagesData;
        for (auto & inputFilePath : imageNames) {
            std::string data;
            if (!readBinaryFile(inputFilePath, data)) {
                slog::info << "failed to read " << inputFilePath << slog::endl;
                continue;
            }
            /** Store image data **/
            imagesData.push_back(data);
        }
        if (imagesData.empty()) throw std::logic_error("Valid input images were not found!");
        // -----------------------------------------------------------------------------------------------------

        // --------------------------- 4. Create infer request -------------------------------------------------
        InferenceEngine::IInferRequest::Ptr inferRequest;
        auto status = importedNetworkPtr->CreateInferRequest(inferRequest, &response);
        if (status == StatusCode::OK) {
            slog::info << "CreateInferRequest completed successfully" << slog::endl;
        } else {
            slog::info << "CreateInferRequest failed with status code: " << status << ", response: " << response.msg << slog::endl;
            throw std::logic_error("CreateInferRequest failed");
        }
        // -----------------------------------------------------------------------------------------------------

        // --------------------------- 5. Prepare input --------------------------------------------------------
        /** Iterate over all the input blobs **/
        for (const auto & item : inputInfo) {
            /** Creating input blob **/
            Blob::Ptr input;
            inferRequest->GetBlob(item.first.c_str(), input, &response);

            /** Filling input tensor with images. First b channel, then g and r channels **/
            size_t num_channels = input->getTensorDesc().getDims()[1];
            size_t image_size = input->getTensorDesc().getDims()[2] * input->getTensorDesc().getDims()[3];

            auto data = input->buffer().as<PrecisionTrait<Precision::U8>::value_type*>();

            /** Iterate over all input images **/
            for (size_t image_id = 0; image_id < imagesData.size(); ++image_id) {
                /** Iterate over all pixel in image (b,g,r) **/
                for (size_t pid = 0; pid < image_size; pid++) {
                    /** Iterate over all channels **/
                    for (size_t ch = 0; ch < num_channels; ++ch) {
                        /**          [images stride + channels stride + pixel id ] all in bytes            **/
                        data[image_id * image_size * num_channels + ch * image_size + pid ] = imagesData.at(image_id).at(pid*num_channels + ch);
                    }
                }
            }
        }

        status = inferRequest->Infer(&response);
        if (status == StatusCode::OK) {
            slog::info << "inferRequest completed successfully" << slog::endl;
        } else {
            slog::info << "inferRequest failed with status code: " << status << ", response: " << response.msg << slog::endl;
            throw std::logic_error("inferRequest failed");
        }

        // -----------------------------------------------------------------------------------------------------

        // --------------------------- 6. Process output -------------------------------------------------------
        slog::info << "Processing output blobs" << slog::endl;

        ConstOutputsDataMap outputInfo;
        importedNetworkPtr->GetOutputsInfo(outputInfo, &response);

        std::string firstOutputName;
        for (auto & item : outputInfo) {
            if (firstOutputName.empty()) {
                firstOutputName = item.first;
            }
        }

        Blob::Ptr output_blob;
        inferRequest->GetBlob(firstOutputName.c_str(), output_blob, &response);

        /** Read labels from file (e.x. AlexNet.labels) **/
        std::string labelFileName = fileNameNoExt(FLAGS_m) + ".labels";
        std::vector<std::string> labels;

        std::ifstream inputFile;
        inputFile.open(labelFileName, std::ios::in);
        if (inputFile.is_open()) {
            std::string strLine;
            while (std::getline(inputFile, strLine)) {
                trim(strLine);
                labels.push_back(strLine);
            }
        }

        auto inputInfoItem = *inputInfo.begin();
        Blob::Ptr input_blob;
        inferRequest->GetBlob(inputInfoItem.first.c_str(), input_blob, &response);

        const SizeVector inputDims = input_blob->getTensorDesc().getDims();
        size_t batchSize = inputDims.at(1);

        const size_t resultsCnt = output_blob->size() / batchSize;
        ClassificationResult classificationResult(output_blob, imageNames,
                                                  batchSize, resultsCnt,
                                                  labels);
        classificationResult.print();
    }
    catch (const std::exception& error) {
        slog::err << "" << error.what() << slog::endl;
        return 1;
    }
    catch (...) {
        slog::err << "Unknown/internal exception happened." << slog::endl;
        return 1;
    }

    slog::info << "Execution successful" << slog::endl;
    return 0;
}
