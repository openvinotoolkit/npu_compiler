//
// Copyright 2019 Intel Corporation.
//
// This software and the related documents are Intel copyrighted materials,
// and your use of them is governed by the express license under which they
// were provided to you (End User License Agreement for the Intel(R) Software
// Development Products (Version May 2017)). Unless the License provides
// otherwise, you may not use, modify, copy, publish, distribute, disclose or
// transmit this software or the related documents without Intel's prior
// written permission.
//
// This software and the related documents are provided as is, with no
// express or implied warranties, other than those that are expressly
// stated in the License.
//

#include <string>
#include <map>

#include <inference_engine.hpp>
#include <format_reader_ptr.h>

#include <samples/common.hpp>

#include <ie_icnn_network_stats.hpp>
#include <cnn_network_int8_normalizer.hpp>
#include <ie_util_internal.hpp>
#include <ie_plugin_dispatcher.hpp>

#include <vpu/kmb_plugin_config.hpp>
#include "full_pipeline_compile_app.h"
#include "utils.hpp"

namespace {
bool ParseAndCheckCommandLine(int argc, char *argv[]) {
    // ---------------------------Parsing and validation of input args--------------------------------------
    slog::info << "Parsing input parameters" << slog::endl;

    gflags::ParseCommandLineNonHelpFlags(&argc, &argv, true);
    if (FLAGS_h) {
        showUsage();
        return false;
    }
    slog::info << "Parsing input parameters" << slog::endl;

    if (FLAGS_m.empty()) {
        throw std::logic_error("Parameter -m is not set");
    }

    if (FLAGS_split.empty()) {
        throw std::logic_error("Parameter -split is not set");
    }

    return true;
}
}  // namespace

using namespace InferenceEngine;
using namespace Utils;

ConsoleErrorListener error_listener;

int main(int argc, char *argv[]) {
    try {
        slog::info << "InferenceEngine: " << GetInferenceEngineVersion() << slog::endl;

        // ------------------------------ Parsing and validation of input args ---------------------------------
        if (!ParseAndCheckCommandLine(argc, argv)) {
            return 0;
        }

        std::map<std::string, modelPart> requiredParts;

        /** Path to save subnetworks .xml and .bin files**/
        if (FLAGS_out.empty()) {
            requiredParts["head"].path = "";
            requiredParts["body"].path = "";
            requiredParts["tail"].path = "";
        } else {
            requiredParts["head"].path = FLAGS_out;
            requiredParts["body"].path = FLAGS_out;
            requiredParts["tail"].path = FLAGS_out;
        }

        // --------------------------- 1. Load inference engine -------------------------------------
        slog::info << "Creating Inference Engine" << slog::endl;

        Core ie;

        if (FLAGS_p_msg) {
            ie.SetLogCallback(error_listener);
        }

        // --------------------------- 2. Read IR Generated by ModelOptimizer (.xml and .bin files) ------------
        slog::info << "Loading network files" << slog::endl;

        CNNNetwork network = ie.ReadNetwork(FLAGS_m);
        // -----------------------------------------------------------------------------------------------------

        // --------------------------- 3. Configure input & output ---------------------------------------------

        /** Taking information about all topology inputs **/
        InputsDataMap inputInfo(network.getInputsInfo());
        if (inputInfo.size() != 1) throw std::logic_error("Sample supports topologies with 1 input only");


        network.setBatchSize(1);
        size_t batchSize = network.getBatchSize();
        slog::info << "Batch size is " << std::to_string(batchSize) << slog::endl;

        // -----------------------------------------------------------------------------------------------------

        // --------------------------- 4. Normalizing model ------------------------------------------

        details::CNNNetworkImplPtr clonedNetwork;
        ICNNNetworkStats* pstats = nullptr;
        if (FLAGS_no_quantize) {
            clonedNetwork = cloneNet(network);
        } else {
            StatusCode s = ((ICNNNetwork&)network).getStats(&pstats, nullptr);

            if (s == StatusCode::OK && pstats && !pstats->isEmpty()) {
                details::CNNNetworkInt8Normalizer cnnorm;

                clonedNetwork = cloneNet(network);
                cnnorm.NormalizeNetwork(*clonedNetwork, *pstats);
            } else {
                throw std::logic_error("Can not get statistics for normalizer!");
            }
            {
                ResponseDesc resp;
                std::string xml;
                std::string bin;
                std::string fname = clonedNetwork->getName();
                std::replace(fname.begin(), fname.end(), '/', '_');
                if (requiredParts["body"].path.empty()) {
                    xml = "./" + fname + "_quantized_full.xml";
                    bin = "./" + fname + "_quantized_full.bin";
                } else {
                    xml = requiredParts["body"].path + "/" + fname + "_quantized_full.xml";
                    bin = requiredParts["body"].path + "/" + fname + "_quantized_full.bin";
                }
                clonedNetwork->serialize(xml, bin, &resp);
            }
        }
        // --------------------------- 5. Split model on three --------------------------------------
        details::CNNNetworkIterator el(clonedNetwork.get());

        std::ifstream layersListFile;
        layersListFile.open(FLAGS_split);
        if (!layersListFile.good()) {
            throw std::logic_error("Can't open split list file (-split parameter)");
        }
        std::string line;
        std::map<std::string, std::string> layersList;
        while (layersListFile.good()) {
            getline(layersListFile, line);
            size_t pos = 0;
            std::string key;
            std::string value;
            if ((pos = line.find("\t")) != std::string::npos) {
                key = line.substr(0, pos);
                value = line.substr(pos + 1, line.size());
                layersList[key] = value;
                slog::info << key << "\t" << value << slog::endl;
            }
        }
        layersListFile.close();

        while (el != details::CNNNetworkIterator()) {
            CNNLayer::Ptr layer = *el;

            if (layersList[layer->name] == "head") {
                layer->affinity = "head";
            } else if (layersList[layer->name] == "tail") {
                layer->affinity = "tail";
            } else {
                layer->affinity = "body";
            }
            el++;
        }

        doSplitGraph(clonedNetwork, requiredParts);

        OutputsDataMap bodyOutputs;
        (requiredParts["body"].networkPart)->getOutputsInfo(bodyOutputs);

        for (auto &&o : bodyOutputs) {
            o.second->setPrecision(Precision::U8);
        }
        // -----------------------------------------------------------------------------------------------------

        // --------------------------- 6. Compiling middle network ------------------------------------------
        slog::info << "Loading model to the device" << slog::endl;
        std::map<std::string, std::string> config;
        if (FLAGS_d ==  "KMB") {
            config[VPU_KMB_CONFIG_KEY(MCM_PARSING_ONLY)]  = CONFIG_VALUE(NO);
            config[VPU_KMB_CONFIG_KEY(MCM_GENERATE_BLOB)] = CONFIG_VALUE(YES);
        }

        ExecutableNetwork executableNetwork = ie.LoadNetwork(CNNNetwork(requiredParts["body"].networkPart), FLAGS_d, config);

        std::string blob;
        if (FLAGS_blob.empty()) {
            blob = "./" + (requiredParts["body"].networkPart)->getName() + ".blob";
        } else {
            blob = FLAGS_blob + "/" + (requiredParts["body"].networkPart)->getName() + ".blob";
        }
        executableNetwork.Export(blob);
        // -----------------------------------------------------------------------------------------------------
    }
    catch (const std::exception& error) {
        slog::err << error.what() << slog::endl;
        return 1;
    }
    catch (...) {
        slog::err << "Unknown/internal exception happened." << slog::endl;
        return 1;
    }

    slog::info << "Execution successful" << slog::endl;
    slog::info << slog::endl << "This sample is an API example, for any performance measurements "
                                "please use the dedicated benchmark_app tool" << slog::endl;
    return 0;
}
