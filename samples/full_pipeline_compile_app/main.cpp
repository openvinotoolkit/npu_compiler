//
// Copyright 2019 Intel Corporation.
//
// This software and the related documents are Intel copyrighted materials,
// and your use of them is governed by the express license under which they
// were provided to you (End User License Agreement for the Intel(R) Software
// Development Products (Version May 2017)). Unless the License provides
// otherwise, you may not use, modify, copy, publish, distribute, disclose or
// transmit this software or the related documents without Intel's prior
// written permission.
//
// This software and the related documents are provided as is, with no
// express or implied warranties, other than those that are expressly
// stated in the License.
//

#include <fstream>
#include <vector>
#include <memory>
#include <algorithm>
#include <string>
#include <map>
#include <condition_variable>
#include <mutex>

#include <inference_engine.hpp>

#include <format_reader_ptr.h>

#include <samples/common.hpp>
#include <samples/slog.hpp>
#include <samples/args_helper.hpp>
#include <samples/classification_results.h>

#include <ie_icnn_network_stats.hpp>
#include <cnn_network_int8_normalizer.hpp>
#include <ie_util_internal.hpp>

#include <sys/stat.h>

#include "classification_sample_async.h"
#include <vpu/kmb_plugin_config.hpp>

using namespace InferenceEngine;

ConsoleErrorListener error_listener;

bool ParseAndCheckCommandLine(int argc, char *argv[]) {
    // ---------------------------Parsing and validation of input args--------------------------------------
    slog::info << "Parsing input parameters" << slog::endl;

    gflags::ParseCommandLineNonHelpFlags(&argc, &argv, true);
    if (FLAGS_h) {
        showUsage();
        showAvailableDevices();
        return false;
    }
    slog::info << "Parsing input parameters" << slog::endl;

    if (FLAGS_m.empty()) {
        throw std::logic_error("Parameter -m is not set");
    }

    return true;
}

int main(int argc, char *argv[]) {
    try {
        slog::info << "InferenceEngine: " << GetInferenceEngineVersion() << slog::endl;

        // ------------------------------ Parsing and validation of input args ---------------------------------
        if (!ParseAndCheckCommandLine(argc, argv)) {
            return 0;
        }

        // --------------------------- 1. Load inference engine -------------------------------------
        slog::info << "Creating Inference Engine" << slog::endl;

        Core ie;

        if (FLAGS_p_msg) {
            ie.SetLogCallback(error_listener);
        }

        // --------------------------- 2. Read IR Generated by ModelOptimizer (.xml and .bin files) ------------
        slog::info << "Loading network files" << slog::endl;

        CNNNetReader networkReader;
        /** Read network model **/
        networkReader.ReadNetwork(FLAGS_m);

        /** Extract model name and load weights **/
        std::string binFileName = fileNameNoExt(FLAGS_m) + ".bin";
        networkReader.ReadWeights(binFileName);

        CNNNetwork network = networkReader.getNetwork();
        // -----------------------------------------------------------------------------------------------------

        // --------------------------- 3. Configure input & output ---------------------------------------------

        /** Taking information about all topology inputs **/
        InputsDataMap inputInfo(network.getInputsInfo());
        if (inputInfo.size() != 1) throw std::logic_error("Sample supports topologies with 1 input only");


        network.setBatchSize(1);
        size_t batchSize = network.getBatchSize();
        slog::info << "Batch size is " << std::to_string(batchSize) << slog::endl;

        // -----------------------------------------------------------------------------------------------------

        // --------------------------- 4. Normalizing model ------------------------------------------

        details::CNNNetworkImplPtr clonedNetwork;
        details::CNNNetworkImplPtr headNetwork;
        details::CNNNetworkImplPtr bodyNetwork;
        details::CNNNetworkImplPtr tailNetwork;
        details::CNNNetworkInt8Normalizer cnnorm;

        clonedNetwork = cloneNet(network);

// #define NORMALIZE_NETWORK
#ifdef NORMALIZE_NETWORK
        ICNNNetworkStats* pstats = nullptr;
        /*StatusCode s = */((ICNNNetwork&)network).getStats(&pstats, nullptr);

        if (!pstats->isEmpty()) {
            cnnorm.NormalizeNetwork(clonedNetwork, *pstats);
        } else {
            throw std::logic_error("Can not get statistics for normalizer!");
        }
#endif

        // -----------------------------------------------------------------------------------------------------

        // --------------------------- 5. Split model on three --------------------------------------

        // Move several starting layers to headNetwork
        CNNNetwork clonedCNNNetwork(clonedNetwork);
        headNetwork = cloneNet(clonedCNNNetwork);
        // Move middle layers to body
        bodyNetwork = cloneNet(clonedCNNNetwork);
        // Move several ending layers to tailNetwork
        tailNetwork = cloneNet(clonedCNNNetwork);

        // -----------------------------------------------------------------------------------------------------

        // --------------------------- 4. Loading middle network to the device ------------------------------------------
        slog::info << "Loading model to the device" << slog::endl;
        std::map<std::string, std::string> config;
        if (FLAGS_d ==  "KMB") {
            config[VPU_KMB_CONFIG_KEY(MCM_PARSING_ONLY)]  = CONFIG_VALUE(NO);
            config[VPU_KMB_CONFIG_KEY(MCM_GENERATE_BLOB)] = CONFIG_VALUE(YES);
        }

// TODO: Without real compilation for the starter
//        InferenceEngine::ExecutableNetwork executableNetwork = ie.LoadNetwork(CNNNetwork(bodyNetwork), FLAGS_d, config);
//
//        executableNetwork->Export("tmp.blob", nullptr);
        // -----------------------------------------------------------------------------------------------------

        // --------------------------- 5. Save head network to the file ------------------------------------------

        // -----------------------------------------------------------------------------------------------------

        // --------------------------- 6. Save tail network to the file ------------------------------------------

        // -----------------------------------------------------------------------------------------------------
    }
    catch (const std::exception& error) {
        slog::err << error.what() << slog::endl;
        return 1;
    }
    catch (...) {
        slog::err << "Unknown/internal exception happened." << slog::endl;
        return 1;
    }

    slog::info << "Execution successful" << slog::endl;
    slog::info << slog::endl << "This sample is an API example, for any performance measurements "
                                "please use the dedicated benchmark_app tool" << slog::endl;
    return 0;
}
