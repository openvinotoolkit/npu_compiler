// automatically generated by the FlatBuffers compiler, do not modify


#ifndef FLATBUFFERS_GENERATED_SOFTWARE_MVCNN_H_
#define FLATBUFFERS_GENERATED_SOFTWARE_MVCNN_H_

#include "flatbuffers/flatbuffers.h"

#include "memoryManagement_generated.h"

namespace MVCNN {

struct Tensor;

struct Conv2D;

struct Pooling;

struct ReLU;

struct Passthrough;

struct Custom;

struct MvTensorTask;

struct PPEConfigure;

struct PPEAssist;

struct NNTensorTask;

enum SoftwareLayer {
  SoftwareLayer_NONE = 0,
  SoftwareLayer_Conv2D = 1,
  SoftwareLayer_Pooling = 2,
  SoftwareLayer_ReLU = 3,
  SoftwareLayer_Passthrough = 4,
  SoftwareLayer_Custom = 5,
  SoftwareLayer_MIN = SoftwareLayer_NONE,
  SoftwareLayer_MAX = SoftwareLayer_Custom
};

inline const SoftwareLayer (&EnumValuesSoftwareLayer())[6] {
  static const SoftwareLayer values[] = {
    SoftwareLayer_NONE,
    SoftwareLayer_Conv2D,
    SoftwareLayer_Pooling,
    SoftwareLayer_ReLU,
    SoftwareLayer_Passthrough,
    SoftwareLayer_Custom
  };
  return values;
}

inline const char * const *EnumNamesSoftwareLayer() {
  static const char * const names[] = {
    "NONE",
    "Conv2D",
    "Pooling",
    "ReLU",
    "Passthrough",
    "Custom",
    nullptr
  };
  return names;
}

inline const char *EnumNameSoftwareLayer(SoftwareLayer e) {
  if (e < SoftwareLayer_NONE || e > SoftwareLayer_Custom) return "";
  const size_t index = static_cast<int>(e);
  return EnumNamesSoftwareLayer()[index];
}

template<typename T> struct SoftwareLayerTraits {
  static const SoftwareLayer enum_value = SoftwareLayer_NONE;
};

template<> struct SoftwareLayerTraits<Conv2D> {
  static const SoftwareLayer enum_value = SoftwareLayer_Conv2D;
};

template<> struct SoftwareLayerTraits<Pooling> {
  static const SoftwareLayer enum_value = SoftwareLayer_Pooling;
};

template<> struct SoftwareLayerTraits<ReLU> {
  static const SoftwareLayer enum_value = SoftwareLayer_ReLU;
};

template<> struct SoftwareLayerTraits<Passthrough> {
  static const SoftwareLayer enum_value = SoftwareLayer_Passthrough;
};

template<> struct SoftwareLayerTraits<Custom> {
  static const SoftwareLayer enum_value = SoftwareLayer_Custom;
};

bool VerifySoftwareLayer(flatbuffers::Verifier &verifier, const void *obj, SoftwareLayer type);
bool VerifySoftwareLayerVector(flatbuffers::Verifier &verifier, const flatbuffers::Vector<flatbuffers::Offset<void>> *values, const flatbuffers::Vector<uint8_t> *types);

enum NNHelper {
  NNHelper_NONE = 0,
  NNHelper_PPEConfigure = 1,
  NNHelper_PPEAssist = 2,
  NNHelper_MIN = NNHelper_NONE,
  NNHelper_MAX = NNHelper_PPEAssist
};

inline const NNHelper (&EnumValuesNNHelper())[3] {
  static const NNHelper values[] = {
    NNHelper_NONE,
    NNHelper_PPEConfigure,
    NNHelper_PPEAssist
  };
  return values;
}

inline const char * const *EnumNamesNNHelper() {
  static const char * const names[] = {
    "NONE",
    "PPEConfigure",
    "PPEAssist",
    nullptr
  };
  return names;
}

inline const char *EnumNameNNHelper(NNHelper e) {
  if (e < NNHelper_NONE || e > NNHelper_PPEAssist) return "";
  const size_t index = static_cast<int>(e);
  return EnumNamesNNHelper()[index];
}

template<typename T> struct NNHelperTraits {
  static const NNHelper enum_value = NNHelper_NONE;
};

template<> struct NNHelperTraits<PPEConfigure> {
  static const NNHelper enum_value = NNHelper_PPEConfigure;
};

template<> struct NNHelperTraits<PPEAssist> {
  static const NNHelper enum_value = NNHelper_PPEAssist;
};

bool VerifyNNHelper(flatbuffers::Verifier &verifier, const void *obj, NNHelper type);
bool VerifyNNHelperVector(flatbuffers::Verifier &verifier, const flatbuffers::Vector<flatbuffers::Offset<void>> *values, const flatbuffers::Vector<uint8_t> *types);

struct Tensor FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_DIMX = 4,
    VT_DIMY = 6,
    VT_DIMZ = 8,
    VT_STRIDEX = 10,
    VT_STRIDEY = 12,
    VT_STRIDEZ = 14,
    VT_OFFSET = 16,
    VT_LOCATION = 18,
    VT_DATATYPE = 20,
    VT_ORDER = 22
  };
  uint32_t dimX() const {
    return GetField<uint32_t>(VT_DIMX, 0);
  }
  uint32_t dimY() const {
    return GetField<uint32_t>(VT_DIMY, 0);
  }
  uint32_t dimZ() const {
    return GetField<uint32_t>(VT_DIMZ, 0);
  }
  uint32_t strideX() const {
    return GetField<uint32_t>(VT_STRIDEX, 0);
  }
  uint32_t strideY() const {
    return GetField<uint32_t>(VT_STRIDEY, 0);
  }
  uint32_t strideZ() const {
    return GetField<uint32_t>(VT_STRIDEZ, 0);
  }
  uint32_t offset() const {
    return GetField<uint32_t>(VT_OFFSET, 0);
  }
  uint32_t location() const {
    return GetField<uint32_t>(VT_LOCATION, 0);
  }
  uint32_t dataType() const {
    return GetField<uint32_t>(VT_DATATYPE, 0);
  }
  uint32_t order() const {
    return GetField<uint32_t>(VT_ORDER, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint32_t>(verifier, VT_DIMX) &&
           VerifyField<uint32_t>(verifier, VT_DIMY) &&
           VerifyField<uint32_t>(verifier, VT_DIMZ) &&
           VerifyField<uint32_t>(verifier, VT_STRIDEX) &&
           VerifyField<uint32_t>(verifier, VT_STRIDEY) &&
           VerifyField<uint32_t>(verifier, VT_STRIDEZ) &&
           VerifyField<uint32_t>(verifier, VT_OFFSET) &&
           VerifyField<uint32_t>(verifier, VT_LOCATION) &&
           VerifyField<uint32_t>(verifier, VT_DATATYPE) &&
           VerifyField<uint32_t>(verifier, VT_ORDER) &&
           verifier.EndTable();
  }
};

struct TensorBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_dimX(uint32_t dimX) {
    fbb_.AddElement<uint32_t>(Tensor::VT_DIMX, dimX, 0);
  }
  void add_dimY(uint32_t dimY) {
    fbb_.AddElement<uint32_t>(Tensor::VT_DIMY, dimY, 0);
  }
  void add_dimZ(uint32_t dimZ) {
    fbb_.AddElement<uint32_t>(Tensor::VT_DIMZ, dimZ, 0);
  }
  void add_strideX(uint32_t strideX) {
    fbb_.AddElement<uint32_t>(Tensor::VT_STRIDEX, strideX, 0);
  }
  void add_strideY(uint32_t strideY) {
    fbb_.AddElement<uint32_t>(Tensor::VT_STRIDEY, strideY, 0);
  }
  void add_strideZ(uint32_t strideZ) {
    fbb_.AddElement<uint32_t>(Tensor::VT_STRIDEZ, strideZ, 0);
  }
  void add_offset(uint32_t offset) {
    fbb_.AddElement<uint32_t>(Tensor::VT_OFFSET, offset, 0);
  }
  void add_location(uint32_t location) {
    fbb_.AddElement<uint32_t>(Tensor::VT_LOCATION, location, 0);
  }
  void add_dataType(uint32_t dataType) {
    fbb_.AddElement<uint32_t>(Tensor::VT_DATATYPE, dataType, 0);
  }
  void add_order(uint32_t order) {
    fbb_.AddElement<uint32_t>(Tensor::VT_ORDER, order, 0);
  }
  explicit TensorBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  TensorBuilder &operator=(const TensorBuilder &);
  flatbuffers::Offset<Tensor> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Tensor>(end);
    return o;
  }
};

inline flatbuffers::Offset<Tensor> CreateTensor(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint32_t dimX = 0,
    uint32_t dimY = 0,
    uint32_t dimZ = 0,
    uint32_t strideX = 0,
    uint32_t strideY = 0,
    uint32_t strideZ = 0,
    uint32_t offset = 0,
    uint32_t location = 0,
    uint32_t dataType = 0,
    uint32_t order = 0) {
  TensorBuilder builder_(_fbb);
  builder_.add_order(order);
  builder_.add_dataType(dataType);
  builder_.add_location(location);
  builder_.add_offset(offset);
  builder_.add_strideZ(strideZ);
  builder_.add_strideY(strideY);
  builder_.add_strideX(strideX);
  builder_.add_dimZ(dimZ);
  builder_.add_dimY(dimY);
  builder_.add_dimX(dimX);
  return builder_.Finish();
}

struct Conv2D FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_RADIXX = 4,
    VT_RADIXY = 6,
    VT_STRIDEX = 8,
    VT_STRIDEY = 10,
    VT_PADX = 12,
    VT_PADY = 14,
    VT_PADSTYLE = 16,
    VT_DILATION = 18,
    VT_INPUT = 20,
    VT_OUTPUT = 22,
    VT_WEIGHT = 24,
    VT_BIAS = 26
  };
  uint32_t radixX() const {
    return GetField<uint32_t>(VT_RADIXX, 0);
  }
  uint32_t radixY() const {
    return GetField<uint32_t>(VT_RADIXY, 0);
  }
  uint32_t strideX() const {
    return GetField<uint32_t>(VT_STRIDEX, 0);
  }
  uint32_t strideY() const {
    return GetField<uint32_t>(VT_STRIDEY, 0);
  }
  uint32_t padX() const {
    return GetField<uint32_t>(VT_PADX, 0);
  }
  uint32_t padY() const {
    return GetField<uint32_t>(VT_PADY, 0);
  }
  uint32_t padStyle() const {
    return GetField<uint32_t>(VT_PADSTYLE, 0);
  }
  uint32_t dilation() const {
    return GetField<uint32_t>(VT_DILATION, 0);
  }
  const TensorReference *input() const {
    return GetPointer<const TensorReference *>(VT_INPUT);
  }
  const TensorReference *output() const {
    return GetPointer<const TensorReference *>(VT_OUTPUT);
  }
  const TensorReference *weight() const {
    return GetPointer<const TensorReference *>(VT_WEIGHT);
  }
  const TensorReference *bias() const {
    return GetPointer<const TensorReference *>(VT_BIAS);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint32_t>(verifier, VT_RADIXX) &&
           VerifyField<uint32_t>(verifier, VT_RADIXY) &&
           VerifyField<uint32_t>(verifier, VT_STRIDEX) &&
           VerifyField<uint32_t>(verifier, VT_STRIDEY) &&
           VerifyField<uint32_t>(verifier, VT_PADX) &&
           VerifyField<uint32_t>(verifier, VT_PADY) &&
           VerifyField<uint32_t>(verifier, VT_PADSTYLE) &&
           VerifyField<uint32_t>(verifier, VT_DILATION) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyTable(input()) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyTable(output()) &&
           VerifyOffset(verifier, VT_WEIGHT) &&
           verifier.VerifyTable(weight()) &&
           VerifyOffset(verifier, VT_BIAS) &&
           verifier.VerifyTable(bias()) &&
           verifier.EndTable();
  }
};

struct Conv2DBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_radixX(uint32_t radixX) {
    fbb_.AddElement<uint32_t>(Conv2D::VT_RADIXX, radixX, 0);
  }
  void add_radixY(uint32_t radixY) {
    fbb_.AddElement<uint32_t>(Conv2D::VT_RADIXY, radixY, 0);
  }
  void add_strideX(uint32_t strideX) {
    fbb_.AddElement<uint32_t>(Conv2D::VT_STRIDEX, strideX, 0);
  }
  void add_strideY(uint32_t strideY) {
    fbb_.AddElement<uint32_t>(Conv2D::VT_STRIDEY, strideY, 0);
  }
  void add_padX(uint32_t padX) {
    fbb_.AddElement<uint32_t>(Conv2D::VT_PADX, padX, 0);
  }
  void add_padY(uint32_t padY) {
    fbb_.AddElement<uint32_t>(Conv2D::VT_PADY, padY, 0);
  }
  void add_padStyle(uint32_t padStyle) {
    fbb_.AddElement<uint32_t>(Conv2D::VT_PADSTYLE, padStyle, 0);
  }
  void add_dilation(uint32_t dilation) {
    fbb_.AddElement<uint32_t>(Conv2D::VT_DILATION, dilation, 0);
  }
  void add_input(flatbuffers::Offset<TensorReference> input) {
    fbb_.AddOffset(Conv2D::VT_INPUT, input);
  }
  void add_output(flatbuffers::Offset<TensorReference> output) {
    fbb_.AddOffset(Conv2D::VT_OUTPUT, output);
  }
  void add_weight(flatbuffers::Offset<TensorReference> weight) {
    fbb_.AddOffset(Conv2D::VT_WEIGHT, weight);
  }
  void add_bias(flatbuffers::Offset<TensorReference> bias) {
    fbb_.AddOffset(Conv2D::VT_BIAS, bias);
  }
  explicit Conv2DBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  Conv2DBuilder &operator=(const Conv2DBuilder &);
  flatbuffers::Offset<Conv2D> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Conv2D>(end);
    return o;
  }
};

inline flatbuffers::Offset<Conv2D> CreateConv2D(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint32_t radixX = 0,
    uint32_t radixY = 0,
    uint32_t strideX = 0,
    uint32_t strideY = 0,
    uint32_t padX = 0,
    uint32_t padY = 0,
    uint32_t padStyle = 0,
    uint32_t dilation = 0,
    flatbuffers::Offset<TensorReference> input = 0,
    flatbuffers::Offset<TensorReference> output = 0,
    flatbuffers::Offset<TensorReference> weight = 0,
    flatbuffers::Offset<TensorReference> bias = 0) {
  Conv2DBuilder builder_(_fbb);
  builder_.add_bias(bias);
  builder_.add_weight(weight);
  builder_.add_output(output);
  builder_.add_input(input);
  builder_.add_dilation(dilation);
  builder_.add_padStyle(padStyle);
  builder_.add_padY(padY);
  builder_.add_padX(padX);
  builder_.add_strideY(strideY);
  builder_.add_strideX(strideX);
  builder_.add_radixY(radixY);
  builder_.add_radixX(radixX);
  return builder_.Finish();
}

struct Pooling FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_RADIXX = 4,
    VT_RADIXY = 6,
    VT_STRIDEX = 8,
    VT_STRIDEY = 10,
    VT_PADX = 12,
    VT_PADY = 14,
    VT_PADSTYLE = 16,
    VT_DILATION = 18,
    VT_INPUT = 20,
    VT_OUTPUT = 22
  };
  uint32_t radixX() const {
    return GetField<uint32_t>(VT_RADIXX, 0);
  }
  uint32_t radixY() const {
    return GetField<uint32_t>(VT_RADIXY, 0);
  }
  uint32_t strideX() const {
    return GetField<uint32_t>(VT_STRIDEX, 0);
  }
  uint32_t strideY() const {
    return GetField<uint32_t>(VT_STRIDEY, 0);
  }
  uint32_t padX() const {
    return GetField<uint32_t>(VT_PADX, 0);
  }
  uint32_t padY() const {
    return GetField<uint32_t>(VT_PADY, 0);
  }
  uint32_t padStyle() const {
    return GetField<uint32_t>(VT_PADSTYLE, 0);
  }
  uint32_t dilation() const {
    return GetField<uint32_t>(VT_DILATION, 0);
  }
  const TensorReference *input() const {
    return GetPointer<const TensorReference *>(VT_INPUT);
  }
  const TensorReference *output() const {
    return GetPointer<const TensorReference *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint32_t>(verifier, VT_RADIXX) &&
           VerifyField<uint32_t>(verifier, VT_RADIXY) &&
           VerifyField<uint32_t>(verifier, VT_STRIDEX) &&
           VerifyField<uint32_t>(verifier, VT_STRIDEY) &&
           VerifyField<uint32_t>(verifier, VT_PADX) &&
           VerifyField<uint32_t>(verifier, VT_PADY) &&
           VerifyField<uint32_t>(verifier, VT_PADSTYLE) &&
           VerifyField<uint32_t>(verifier, VT_DILATION) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyTable(input()) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyTable(output()) &&
           verifier.EndTable();
  }
};

struct PoolingBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_radixX(uint32_t radixX) {
    fbb_.AddElement<uint32_t>(Pooling::VT_RADIXX, radixX, 0);
  }
  void add_radixY(uint32_t radixY) {
    fbb_.AddElement<uint32_t>(Pooling::VT_RADIXY, radixY, 0);
  }
  void add_strideX(uint32_t strideX) {
    fbb_.AddElement<uint32_t>(Pooling::VT_STRIDEX, strideX, 0);
  }
  void add_strideY(uint32_t strideY) {
    fbb_.AddElement<uint32_t>(Pooling::VT_STRIDEY, strideY, 0);
  }
  void add_padX(uint32_t padX) {
    fbb_.AddElement<uint32_t>(Pooling::VT_PADX, padX, 0);
  }
  void add_padY(uint32_t padY) {
    fbb_.AddElement<uint32_t>(Pooling::VT_PADY, padY, 0);
  }
  void add_padStyle(uint32_t padStyle) {
    fbb_.AddElement<uint32_t>(Pooling::VT_PADSTYLE, padStyle, 0);
  }
  void add_dilation(uint32_t dilation) {
    fbb_.AddElement<uint32_t>(Pooling::VT_DILATION, dilation, 0);
  }
  void add_input(flatbuffers::Offset<TensorReference> input) {
    fbb_.AddOffset(Pooling::VT_INPUT, input);
  }
  void add_output(flatbuffers::Offset<TensorReference> output) {
    fbb_.AddOffset(Pooling::VT_OUTPUT, output);
  }
  explicit PoolingBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  PoolingBuilder &operator=(const PoolingBuilder &);
  flatbuffers::Offset<Pooling> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Pooling>(end);
    return o;
  }
};

inline flatbuffers::Offset<Pooling> CreatePooling(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint32_t radixX = 0,
    uint32_t radixY = 0,
    uint32_t strideX = 0,
    uint32_t strideY = 0,
    uint32_t padX = 0,
    uint32_t padY = 0,
    uint32_t padStyle = 0,
    uint32_t dilation = 0,
    flatbuffers::Offset<TensorReference> input = 0,
    flatbuffers::Offset<TensorReference> output = 0) {
  PoolingBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_input(input);
  builder_.add_dilation(dilation);
  builder_.add_padStyle(padStyle);
  builder_.add_padY(padY);
  builder_.add_padX(padX);
  builder_.add_strideY(strideY);
  builder_.add_strideX(strideX);
  builder_.add_radixY(radixY);
  builder_.add_radixX(radixX);
  return builder_.Finish();
}

struct ReLU FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_OPX = 4,
    VT_INPUT = 6,
    VT_OUTPUT = 8,
    VT_STRIDEX = 10,
    VT_STRIDEY = 12
  };
  uint32_t opX() const {
    return GetField<uint32_t>(VT_OPX, 0);
  }
  const TensorReference *input() const {
    return GetPointer<const TensorReference *>(VT_INPUT);
  }
  const TensorReference *output() const {
    return GetPointer<const TensorReference *>(VT_OUTPUT);
  }
  uint32_t strideX() const {
    return GetField<uint32_t>(VT_STRIDEX, 0);
  }
  uint32_t strideY() const {
    return GetField<uint32_t>(VT_STRIDEY, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint32_t>(verifier, VT_OPX) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyTable(input()) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyTable(output()) &&
           VerifyField<uint32_t>(verifier, VT_STRIDEX) &&
           VerifyField<uint32_t>(verifier, VT_STRIDEY) &&
           verifier.EndTable();
  }
};

struct ReLUBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_opX(uint32_t opX) {
    fbb_.AddElement<uint32_t>(ReLU::VT_OPX, opX, 0);
  }
  void add_input(flatbuffers::Offset<TensorReference> input) {
    fbb_.AddOffset(ReLU::VT_INPUT, input);
  }
  void add_output(flatbuffers::Offset<TensorReference> output) {
    fbb_.AddOffset(ReLU::VT_OUTPUT, output);
  }
  void add_strideX(uint32_t strideX) {
    fbb_.AddElement<uint32_t>(ReLU::VT_STRIDEX, strideX, 0);
  }
  void add_strideY(uint32_t strideY) {
    fbb_.AddElement<uint32_t>(ReLU::VT_STRIDEY, strideY, 0);
  }
  explicit ReLUBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  ReLUBuilder &operator=(const ReLUBuilder &);
  flatbuffers::Offset<ReLU> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<ReLU>(end);
    return o;
  }
};

inline flatbuffers::Offset<ReLU> CreateReLU(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint32_t opX = 0,
    flatbuffers::Offset<TensorReference> input = 0,
    flatbuffers::Offset<TensorReference> output = 0,
    uint32_t strideX = 0,
    uint32_t strideY = 0) {
  ReLUBuilder builder_(_fbb);
  builder_.add_strideY(strideY);
  builder_.add_strideX(strideX);
  builder_.add_output(output);
  builder_.add_input(input);
  builder_.add_opX(opX);
  return builder_.Finish();
}

struct Passthrough FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INPUT = 4,
    VT_OUTPUT = 6
  };
  const TensorReference *input() const {
    return GetPointer<const TensorReference *>(VT_INPUT);
  }
  const TensorReference *output() const {
    return GetPointer<const TensorReference *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyTable(input()) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyTable(output()) &&
           verifier.EndTable();
  }
};

struct PassthroughBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<TensorReference> input) {
    fbb_.AddOffset(Passthrough::VT_INPUT, input);
  }
  void add_output(flatbuffers::Offset<TensorReference> output) {
    fbb_.AddOffset(Passthrough::VT_OUTPUT, output);
  }
  explicit PassthroughBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  PassthroughBuilder &operator=(const PassthroughBuilder &);
  flatbuffers::Offset<Passthrough> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Passthrough>(end);
    return o;
  }
};

inline flatbuffers::Offset<Passthrough> CreatePassthrough(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<TensorReference> input = 0,
    flatbuffers::Offset<TensorReference> output = 0) {
  PassthroughBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_input(input);
  return builder_.Finish();
}

struct Custom FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_DATA = 4,
    VT_LENGTH = 6,
    VT_ID = 8
  };
  const flatbuffers::Vector<int8_t> *data() const {
    return GetPointer<const flatbuffers::Vector<int8_t> *>(VT_DATA);
  }
  const flatbuffers::Vector<int64_t> *length() const {
    return GetPointer<const flatbuffers::Vector<int64_t> *>(VT_LENGTH);
  }
  int16_t id() const {
    return GetField<int16_t>(VT_ID, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_DATA) &&
           verifier.VerifyVector(data()) &&
           VerifyOffset(verifier, VT_LENGTH) &&
           verifier.VerifyVector(length()) &&
           VerifyField<int16_t>(verifier, VT_ID) &&
           verifier.EndTable();
  }
};

struct CustomBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_data(flatbuffers::Offset<flatbuffers::Vector<int8_t>> data) {
    fbb_.AddOffset(Custom::VT_DATA, data);
  }
  void add_length(flatbuffers::Offset<flatbuffers::Vector<int64_t>> length) {
    fbb_.AddOffset(Custom::VT_LENGTH, length);
  }
  void add_id(int16_t id) {
    fbb_.AddElement<int16_t>(Custom::VT_ID, id, 0);
  }
  explicit CustomBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  CustomBuilder &operator=(const CustomBuilder &);
  flatbuffers::Offset<Custom> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Custom>(end);
    return o;
  }
};

inline flatbuffers::Offset<Custom> CreateCustom(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::Vector<int8_t>> data = 0,
    flatbuffers::Offset<flatbuffers::Vector<int64_t>> length = 0,
    int16_t id = 0) {
  CustomBuilder builder_(_fbb);
  builder_.add_length(length);
  builder_.add_data(data);
  builder_.add_id(id);
  return builder_.Finish();
}

inline flatbuffers::Offset<Custom> CreateCustomDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const std::vector<int8_t> *data = nullptr,
    const std::vector<int64_t> *length = nullptr,
    int16_t id = 0) {
  auto data__ = data ? _fbb.CreateVector<int8_t>(*data) : 0;
  auto length__ = length ? _fbb.CreateVector<int64_t>(*length) : 0;
  return MVCNN::CreateCustom(
      _fbb,
      data__,
      length__,
      id);
}

struct MvTensorTask FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_LAYER_TYPE = 4,
    VT_LAYER = 6
  };
  SoftwareLayer layer_type() const {
    return static_cast<SoftwareLayer>(GetField<uint8_t>(VT_LAYER_TYPE, 0));
  }
  const void *layer() const {
    return GetPointer<const void *>(VT_LAYER);
  }
  template<typename T> const T *layer_as() const;
  const Conv2D *layer_as_Conv2D() const {
    return layer_type() == SoftwareLayer_Conv2D ? static_cast<const Conv2D *>(layer()) : nullptr;
  }
  const Pooling *layer_as_Pooling() const {
    return layer_type() == SoftwareLayer_Pooling ? static_cast<const Pooling *>(layer()) : nullptr;
  }
  const ReLU *layer_as_ReLU() const {
    return layer_type() == SoftwareLayer_ReLU ? static_cast<const ReLU *>(layer()) : nullptr;
  }
  const Passthrough *layer_as_Passthrough() const {
    return layer_type() == SoftwareLayer_Passthrough ? static_cast<const Passthrough *>(layer()) : nullptr;
  }
  const Custom *layer_as_Custom() const {
    return layer_type() == SoftwareLayer_Custom ? static_cast<const Custom *>(layer()) : nullptr;
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint8_t>(verifier, VT_LAYER_TYPE) &&
           VerifyOffset(verifier, VT_LAYER) &&
           VerifySoftwareLayer(verifier, layer(), layer_type()) &&
           verifier.EndTable();
  }
};

template<> inline const Conv2D *MvTensorTask::layer_as<Conv2D>() const {
  return layer_as_Conv2D();
}

template<> inline const Pooling *MvTensorTask::layer_as<Pooling>() const {
  return layer_as_Pooling();
}

template<> inline const ReLU *MvTensorTask::layer_as<ReLU>() const {
  return layer_as_ReLU();
}

template<> inline const Passthrough *MvTensorTask::layer_as<Passthrough>() const {
  return layer_as_Passthrough();
}

template<> inline const Custom *MvTensorTask::layer_as<Custom>() const {
  return layer_as_Custom();
}

struct MvTensorTaskBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_layer_type(SoftwareLayer layer_type) {
    fbb_.AddElement<uint8_t>(MvTensorTask::VT_LAYER_TYPE, static_cast<uint8_t>(layer_type), 0);
  }
  void add_layer(flatbuffers::Offset<void> layer) {
    fbb_.AddOffset(MvTensorTask::VT_LAYER, layer);
  }
  explicit MvTensorTaskBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  MvTensorTaskBuilder &operator=(const MvTensorTaskBuilder &);
  flatbuffers::Offset<MvTensorTask> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<MvTensorTask>(end);
    return o;
  }
};

inline flatbuffers::Offset<MvTensorTask> CreateMvTensorTask(
    flatbuffers::FlatBufferBuilder &_fbb,
    SoftwareLayer layer_type = SoftwareLayer_NONE,
    flatbuffers::Offset<void> layer = 0) {
  MvTensorTaskBuilder builder_(_fbb);
  builder_.add_layer(layer);
  builder_.add_layer_type(layer_type);
  return builder_.Finish();
}

struct PPEConfigure FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VALS = 4
  };
  const flatbuffers::Vector<int8_t> *vals() const {
    return GetPointer<const flatbuffers::Vector<int8_t> *>(VT_VALS);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_VALS) &&
           verifier.VerifyVector(vals()) &&
           verifier.EndTable();
  }
};

struct PPEConfigureBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_vals(flatbuffers::Offset<flatbuffers::Vector<int8_t>> vals) {
    fbb_.AddOffset(PPEConfigure::VT_VALS, vals);
  }
  explicit PPEConfigureBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  PPEConfigureBuilder &operator=(const PPEConfigureBuilder &);
  flatbuffers::Offset<PPEConfigure> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<PPEConfigure>(end);
    return o;
  }
};

inline flatbuffers::Offset<PPEConfigure> CreatePPEConfigure(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::Vector<int8_t>> vals = 0) {
  PPEConfigureBuilder builder_(_fbb);
  builder_.add_vals(vals);
  return builder_.Finish();
}

inline flatbuffers::Offset<PPEConfigure> CreatePPEConfigureDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const std::vector<int8_t> *vals = nullptr) {
  auto vals__ = vals ? _fbb.CreateVector<int8_t>(*vals) : 0;
  return MVCNN::CreatePPEConfigure(
      _fbb,
      vals__);
}

struct PPEAssist FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_OP = 4
  };
  int8_t op() const {
    return GetField<int8_t>(VT_OP, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int8_t>(verifier, VT_OP) &&
           verifier.EndTable();
  }
};

struct PPEAssistBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_op(int8_t op) {
    fbb_.AddElement<int8_t>(PPEAssist::VT_OP, op, 0);
  }
  explicit PPEAssistBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  PPEAssistBuilder &operator=(const PPEAssistBuilder &);
  flatbuffers::Offset<PPEAssist> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<PPEAssist>(end);
    return o;
  }
};

inline flatbuffers::Offset<PPEAssist> CreatePPEAssist(
    flatbuffers::FlatBufferBuilder &_fbb,
    int8_t op = 0) {
  PPEAssistBuilder builder_(_fbb);
  builder_.add_op(op);
  return builder_.Finish();
}

struct NNTensorTask FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_SUBTASK_TYPE = 4,
    VT_SUBTASK = 6
  };
  NNHelper subtask_type() const {
    return static_cast<NNHelper>(GetField<uint8_t>(VT_SUBTASK_TYPE, 0));
  }
  const void *subtask() const {
    return GetPointer<const void *>(VT_SUBTASK);
  }
  template<typename T> const T *subtask_as() const;
  const PPEConfigure *subtask_as_PPEConfigure() const {
    return subtask_type() == NNHelper_PPEConfigure ? static_cast<const PPEConfigure *>(subtask()) : nullptr;
  }
  const PPEAssist *subtask_as_PPEAssist() const {
    return subtask_type() == NNHelper_PPEAssist ? static_cast<const PPEAssist *>(subtask()) : nullptr;
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint8_t>(verifier, VT_SUBTASK_TYPE) &&
           VerifyOffset(verifier, VT_SUBTASK) &&
           VerifyNNHelper(verifier, subtask(), subtask_type()) &&
           verifier.EndTable();
  }
};

template<> inline const PPEConfigure *NNTensorTask::subtask_as<PPEConfigure>() const {
  return subtask_as_PPEConfigure();
}

template<> inline const PPEAssist *NNTensorTask::subtask_as<PPEAssist>() const {
  return subtask_as_PPEAssist();
}

struct NNTensorTaskBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_subtask_type(NNHelper subtask_type) {
    fbb_.AddElement<uint8_t>(NNTensorTask::VT_SUBTASK_TYPE, static_cast<uint8_t>(subtask_type), 0);
  }
  void add_subtask(flatbuffers::Offset<void> subtask) {
    fbb_.AddOffset(NNTensorTask::VT_SUBTASK, subtask);
  }
  explicit NNTensorTaskBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  NNTensorTaskBuilder &operator=(const NNTensorTaskBuilder &);
  flatbuffers::Offset<NNTensorTask> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<NNTensorTask>(end);
    return o;
  }
};

inline flatbuffers::Offset<NNTensorTask> CreateNNTensorTask(
    flatbuffers::FlatBufferBuilder &_fbb,
    NNHelper subtask_type = NNHelper_NONE,
    flatbuffers::Offset<void> subtask = 0) {
  NNTensorTaskBuilder builder_(_fbb);
  builder_.add_subtask(subtask);
  builder_.add_subtask_type(subtask_type);
  return builder_.Finish();
}

inline bool VerifySoftwareLayer(flatbuffers::Verifier &verifier, const void *obj, SoftwareLayer type) {
  switch (type) {
    case SoftwareLayer_NONE: {
      return true;
    }
    case SoftwareLayer_Conv2D: {
      auto ptr = reinterpret_cast<const Conv2D *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case SoftwareLayer_Pooling: {
      auto ptr = reinterpret_cast<const Pooling *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case SoftwareLayer_ReLU: {
      auto ptr = reinterpret_cast<const ReLU *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case SoftwareLayer_Passthrough: {
      auto ptr = reinterpret_cast<const Passthrough *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case SoftwareLayer_Custom: {
      auto ptr = reinterpret_cast<const Custom *>(obj);
      return verifier.VerifyTable(ptr);
    }
    default: return false;
  }
}

inline bool VerifySoftwareLayerVector(flatbuffers::Verifier &verifier, const flatbuffers::Vector<flatbuffers::Offset<void>> *values, const flatbuffers::Vector<uint8_t> *types) {
  if (!values || !types) return !values && !types;
  if (values->size() != types->size()) return false;
  for (flatbuffers::uoffset_t i = 0; i < values->size(); ++i) {
    if (!VerifySoftwareLayer(
        verifier,  values->Get(i), types->GetEnum<SoftwareLayer>(i))) {
      return false;
    }
  }
  return true;
}

inline bool VerifyNNHelper(flatbuffers::Verifier &verifier, const void *obj, NNHelper type) {
  switch (type) {
    case NNHelper_NONE: {
      return true;
    }
    case NNHelper_PPEConfigure: {
      auto ptr = reinterpret_cast<const PPEConfigure *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case NNHelper_PPEAssist: {
      auto ptr = reinterpret_cast<const PPEAssist *>(obj);
      return verifier.VerifyTable(ptr);
    }
    default: return false;
  }
}

inline bool VerifyNNHelperVector(flatbuffers::Verifier &verifier, const flatbuffers::Vector<flatbuffers::Offset<void>> *values, const flatbuffers::Vector<uint8_t> *types) {
  if (!values || !types) return !values && !types;
  if (values->size() != types->size()) return false;
  for (flatbuffers::uoffset_t i = 0; i < values->size(); ++i) {
    if (!VerifyNNHelper(
        verifier,  values->Get(i), types->GetEnum<NNHelper>(i))) {
      return false;
    }
  }
  return true;
}

}  // namespace MVCNN

#endif  // FLATBUFFERS_GENERATED_SOFTWARE_MVCNN_H_
