// automatically generated by the FlatBuffers compiler, do not modify


#ifndef FLATBUFFERS_GENERATED_GRAPHFILE_MVCNN_H_
#define FLATBUFFERS_GENERATED_GRAPHFILE_MVCNN_H_

#include "flatbuffers/flatbuffers.h"

#include "dma_generated.h"
#include "fileHeader_generated.h"
#include "memoryManagement_generated.h"
#include "nnController_generated.h"
#include "nnNCE2_generated.h"
#include "software_generated.h"
#include "structure_generated.h"
#include "upaNCE_generated.h"

namespace MVCNN {

struct GraphFile;

struct TaskList;

struct Task;

enum SpecificTask {
  SpecificTask_NONE = 0,
  SpecificTask_MvTensorTask = 1,
  SpecificTask_UPADMATask = 2,
  SpecificTask_NNDMATask = 3,
  SpecificTask_NCE1Task = 4,
  SpecificTask_NCE2Task = 5,
  SpecificTask_NNTensorTask = 6,
  SpecificTask_ControllerTask = 7,
  SpecificTask_MIN = SpecificTask_NONE,
  SpecificTask_MAX = SpecificTask_ControllerTask
};

inline const SpecificTask (&EnumValuesSpecificTask())[8] {
  static const SpecificTask values[] = {
    SpecificTask_NONE,
    SpecificTask_MvTensorTask,
    SpecificTask_UPADMATask,
    SpecificTask_NNDMATask,
    SpecificTask_NCE1Task,
    SpecificTask_NCE2Task,
    SpecificTask_NNTensorTask,
    SpecificTask_ControllerTask
  };
  return values;
}

inline const char * const *EnumNamesSpecificTask() {
  static const char * const names[] = {
    "NONE",
    "MvTensorTask",
    "UPADMATask",
    "NNDMATask",
    "NCE1Task",
    "NCE2Task",
    "NNTensorTask",
    "ControllerTask",
    nullptr
  };
  return names;
}

inline const char *EnumNameSpecificTask(SpecificTask e) {
  if (e < SpecificTask_NONE || e > SpecificTask_ControllerTask) return "";
  const size_t index = static_cast<int>(e);
  return EnumNamesSpecificTask()[index];
}

template<typename T> struct SpecificTaskTraits {
  static const SpecificTask enum_value = SpecificTask_NONE;
};

template<> struct SpecificTaskTraits<MvTensorTask> {
  static const SpecificTask enum_value = SpecificTask_MvTensorTask;
};

template<> struct SpecificTaskTraits<UPADMATask> {
  static const SpecificTask enum_value = SpecificTask_UPADMATask;
};

template<> struct SpecificTaskTraits<NNDMATask> {
  static const SpecificTask enum_value = SpecificTask_NNDMATask;
};

template<> struct SpecificTaskTraits<NCE1Task> {
  static const SpecificTask enum_value = SpecificTask_NCE1Task;
};

template<> struct SpecificTaskTraits<NCE2Task> {
  static const SpecificTask enum_value = SpecificTask_NCE2Task;
};

template<> struct SpecificTaskTraits<NNTensorTask> {
  static const SpecificTask enum_value = SpecificTask_NNTensorTask;
};

template<> struct SpecificTaskTraits<ControllerTask> {
  static const SpecificTask enum_value = SpecificTask_ControllerTask;
};

bool VerifySpecificTask(flatbuffers::Verifier &verifier, const void *obj, SpecificTask type);
bool VerifySpecificTaskVector(flatbuffers::Verifier &verifier, const flatbuffers::Vector<flatbuffers::Offset<void>> *values, const flatbuffers::Vector<uint8_t> *types);

struct GraphFile FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_HEADER = 4,
    VT_TASK_LISTS = 6,
    VT_BARRIER_TABLE = 8,
    VT_BINARY_DATA = 10
  };
  /// Overview:
  ///    TBC
  ///
  /// @field barrier_table - A list of barriers to be consumed by the
  /// device for its own scheduling.
  /// If you are manually scheduling barriers with leon tasks, you do not need to
  /// populate this field.
  const SummaryHeader *header() const {
    return GetPointer<const SummaryHeader *>(VT_HEADER);
  }
  const flatbuffers::Vector<flatbuffers::Offset<TaskList>> *task_lists() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<TaskList>> *>(VT_TASK_LISTS);
  }
  const flatbuffers::Vector<flatbuffers::Offset<Barrier>> *barrier_table() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<Barrier>> *>(VT_BARRIER_TABLE);
  }
  const flatbuffers::Vector<flatbuffers::Offset<BinaryData>> *binary_data() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<BinaryData>> *>(VT_BINARY_DATA);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_HEADER) &&
           verifier.VerifyTable(header()) &&
           VerifyOffset(verifier, VT_TASK_LISTS) &&
           verifier.VerifyVector(task_lists()) &&
           verifier.VerifyVectorOfTables(task_lists()) &&
           VerifyOffset(verifier, VT_BARRIER_TABLE) &&
           verifier.VerifyVector(barrier_table()) &&
           verifier.VerifyVectorOfTables(barrier_table()) &&
           VerifyOffset(verifier, VT_BINARY_DATA) &&
           verifier.VerifyVector(binary_data()) &&
           verifier.VerifyVectorOfTables(binary_data()) &&
           verifier.EndTable();
  }
};

struct GraphFileBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_header(flatbuffers::Offset<SummaryHeader> header) {
    fbb_.AddOffset(GraphFile::VT_HEADER, header);
  }
  void add_task_lists(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<TaskList>>> task_lists) {
    fbb_.AddOffset(GraphFile::VT_TASK_LISTS, task_lists);
  }
  void add_barrier_table(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Barrier>>> barrier_table) {
    fbb_.AddOffset(GraphFile::VT_BARRIER_TABLE, barrier_table);
  }
  void add_binary_data(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<BinaryData>>> binary_data) {
    fbb_.AddOffset(GraphFile::VT_BINARY_DATA, binary_data);
  }
  explicit GraphFileBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  GraphFileBuilder &operator=(const GraphFileBuilder &);
  flatbuffers::Offset<GraphFile> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<GraphFile>(end);
    return o;
  }
};

inline flatbuffers::Offset<GraphFile> CreateGraphFile(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<SummaryHeader> header = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<TaskList>>> task_lists = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Barrier>>> barrier_table = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<BinaryData>>> binary_data = 0) {
  GraphFileBuilder builder_(_fbb);
  builder_.add_binary_data(binary_data);
  builder_.add_barrier_table(barrier_table);
  builder_.add_task_lists(task_lists);
  builder_.add_header(header);
  return builder_.Finish();
}

inline flatbuffers::Offset<GraphFile> CreateGraphFileDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<SummaryHeader> header = 0,
    const std::vector<flatbuffers::Offset<TaskList>> *task_lists = nullptr,
    const std::vector<flatbuffers::Offset<Barrier>> *barrier_table = nullptr,
    const std::vector<flatbuffers::Offset<BinaryData>> *binary_data = nullptr) {
  auto task_lists__ = task_lists ? _fbb.CreateVector<flatbuffers::Offset<TaskList>>(*task_lists) : 0;
  auto barrier_table__ = barrier_table ? _fbb.CreateVector<flatbuffers::Offset<Barrier>>(*barrier_table) : 0;
  auto binary_data__ = binary_data ? _fbb.CreateVector<flatbuffers::Offset<BinaryData>>(*binary_data) : 0;
  return MVCNN::CreateGraphFile(
      _fbb,
      header,
      task_lists__,
      barrier_table__,
      binary_data__);
}

struct TaskList FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_CONTENT = 4
  };
  const flatbuffers::Vector<flatbuffers::Offset<Task>> *content() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<Task>> *>(VT_CONTENT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_CONTENT) &&
           verifier.VerifyVector(content()) &&
           verifier.VerifyVectorOfTables(content()) &&
           verifier.EndTable();
  }
};

struct TaskListBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_content(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Task>>> content) {
    fbb_.AddOffset(TaskList::VT_CONTENT, content);
  }
  explicit TaskListBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  TaskListBuilder &operator=(const TaskListBuilder &);
  flatbuffers::Offset<TaskList> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<TaskList>(end);
    return o;
  }
};

inline flatbuffers::Offset<TaskList> CreateTaskList(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Task>>> content = 0) {
  TaskListBuilder builder_(_fbb);
  builder_.add_content(content);
  return builder_.Finish();
}

inline flatbuffers::Offset<TaskList> CreateTaskListDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const std::vector<flatbuffers::Offset<Task>> *content = nullptr) {
  auto content__ = content ? _fbb.CreateVector<flatbuffers::Offset<Task>>(*content) : 0;
  return MVCNN::CreateTaskList(
      _fbb,
      content__);
}

struct Task FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_NODEID = 4,
    VT_SOURCETASKIDS = 6,
    VT_ASSOCIATED_BARRIERS = 8,
    VT_TASK_TYPE = 10,
    VT_TASK = 12
  };
  uint32_t nodeID() const {
    return GetField<uint32_t>(VT_NODEID, 0);
  }
  const flatbuffers::Vector<uint32_t> *sourceTaskIDs() const {
    return GetPointer<const flatbuffers::Vector<uint32_t> *>(VT_SOURCETASKIDS);
  }
  const BarrierReference *associated_barriers() const {
    return GetPointer<const BarrierReference *>(VT_ASSOCIATED_BARRIERS);
  }
  SpecificTask task_type() const {
    return static_cast<SpecificTask>(GetField<uint8_t>(VT_TASK_TYPE, 0));
  }
  const void *task() const {
    return GetPointer<const void *>(VT_TASK);
  }
  template<typename T> const T *task_as() const;
  const MvTensorTask *task_as_MvTensorTask() const {
    return task_type() == SpecificTask_MvTensorTask ? static_cast<const MvTensorTask *>(task()) : nullptr;
  }
  const UPADMATask *task_as_UPADMATask() const {
    return task_type() == SpecificTask_UPADMATask ? static_cast<const UPADMATask *>(task()) : nullptr;
  }
  const NNDMATask *task_as_NNDMATask() const {
    return task_type() == SpecificTask_NNDMATask ? static_cast<const NNDMATask *>(task()) : nullptr;
  }
  const NCE1Task *task_as_NCE1Task() const {
    return task_type() == SpecificTask_NCE1Task ? static_cast<const NCE1Task *>(task()) : nullptr;
  }
  const NCE2Task *task_as_NCE2Task() const {
    return task_type() == SpecificTask_NCE2Task ? static_cast<const NCE2Task *>(task()) : nullptr;
  }
  const NNTensorTask *task_as_NNTensorTask() const {
    return task_type() == SpecificTask_NNTensorTask ? static_cast<const NNTensorTask *>(task()) : nullptr;
  }
  const ControllerTask *task_as_ControllerTask() const {
    return task_type() == SpecificTask_ControllerTask ? static_cast<const ControllerTask *>(task()) : nullptr;
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint32_t>(verifier, VT_NODEID) &&
           VerifyOffset(verifier, VT_SOURCETASKIDS) &&
           verifier.VerifyVector(sourceTaskIDs()) &&
           VerifyOffset(verifier, VT_ASSOCIATED_BARRIERS) &&
           verifier.VerifyTable(associated_barriers()) &&
           VerifyField<uint8_t>(verifier, VT_TASK_TYPE) &&
           VerifyOffset(verifier, VT_TASK) &&
           VerifySpecificTask(verifier, task(), task_type()) &&
           verifier.EndTable();
  }
};

template<> inline const MvTensorTask *Task::task_as<MvTensorTask>() const {
  return task_as_MvTensorTask();
}

template<> inline const UPADMATask *Task::task_as<UPADMATask>() const {
  return task_as_UPADMATask();
}

template<> inline const NNDMATask *Task::task_as<NNDMATask>() const {
  return task_as_NNDMATask();
}

template<> inline const NCE1Task *Task::task_as<NCE1Task>() const {
  return task_as_NCE1Task();
}

template<> inline const NCE2Task *Task::task_as<NCE2Task>() const {
  return task_as_NCE2Task();
}

template<> inline const NNTensorTask *Task::task_as<NNTensorTask>() const {
  return task_as_NNTensorTask();
}

template<> inline const ControllerTask *Task::task_as<ControllerTask>() const {
  return task_as_ControllerTask();
}

struct TaskBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_nodeID(uint32_t nodeID) {
    fbb_.AddElement<uint32_t>(Task::VT_NODEID, nodeID, 0);
  }
  void add_sourceTaskIDs(flatbuffers::Offset<flatbuffers::Vector<uint32_t>> sourceTaskIDs) {
    fbb_.AddOffset(Task::VT_SOURCETASKIDS, sourceTaskIDs);
  }
  void add_associated_barriers(flatbuffers::Offset<BarrierReference> associated_barriers) {
    fbb_.AddOffset(Task::VT_ASSOCIATED_BARRIERS, associated_barriers);
  }
  void add_task_type(SpecificTask task_type) {
    fbb_.AddElement<uint8_t>(Task::VT_TASK_TYPE, static_cast<uint8_t>(task_type), 0);
  }
  void add_task(flatbuffers::Offset<void> task) {
    fbb_.AddOffset(Task::VT_TASK, task);
  }
  explicit TaskBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  TaskBuilder &operator=(const TaskBuilder &);
  flatbuffers::Offset<Task> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Task>(end);
    return o;
  }
};

inline flatbuffers::Offset<Task> CreateTask(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint32_t nodeID = 0,
    flatbuffers::Offset<flatbuffers::Vector<uint32_t>> sourceTaskIDs = 0,
    flatbuffers::Offset<BarrierReference> associated_barriers = 0,
    SpecificTask task_type = SpecificTask_NONE,
    flatbuffers::Offset<void> task = 0) {
  TaskBuilder builder_(_fbb);
  builder_.add_task(task);
  builder_.add_associated_barriers(associated_barriers);
  builder_.add_sourceTaskIDs(sourceTaskIDs);
  builder_.add_nodeID(nodeID);
  builder_.add_task_type(task_type);
  return builder_.Finish();
}

inline flatbuffers::Offset<Task> CreateTaskDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint32_t nodeID = 0,
    const std::vector<uint32_t> *sourceTaskIDs = nullptr,
    flatbuffers::Offset<BarrierReference> associated_barriers = 0,
    SpecificTask task_type = SpecificTask_NONE,
    flatbuffers::Offset<void> task = 0) {
  auto sourceTaskIDs__ = sourceTaskIDs ? _fbb.CreateVector<uint32_t>(*sourceTaskIDs) : 0;
  return MVCNN::CreateTask(
      _fbb,
      nodeID,
      sourceTaskIDs__,
      associated_barriers,
      task_type,
      task);
}

inline bool VerifySpecificTask(flatbuffers::Verifier &verifier, const void *obj, SpecificTask type) {
  switch (type) {
    case SpecificTask_NONE: {
      return true;
    }
    case SpecificTask_MvTensorTask: {
      auto ptr = reinterpret_cast<const MvTensorTask *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case SpecificTask_UPADMATask: {
      auto ptr = reinterpret_cast<const UPADMATask *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case SpecificTask_NNDMATask: {
      auto ptr = reinterpret_cast<const NNDMATask *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case SpecificTask_NCE1Task: {
      auto ptr = reinterpret_cast<const NCE1Task *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case SpecificTask_NCE2Task: {
      auto ptr = reinterpret_cast<const NCE2Task *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case SpecificTask_NNTensorTask: {
      auto ptr = reinterpret_cast<const NNTensorTask *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case SpecificTask_ControllerTask: {
      auto ptr = reinterpret_cast<const ControllerTask *>(obj);
      return verifier.VerifyTable(ptr);
    }
    default: return false;
  }
}

inline bool VerifySpecificTaskVector(flatbuffers::Verifier &verifier, const flatbuffers::Vector<flatbuffers::Offset<void>> *values, const flatbuffers::Vector<uint8_t> *types) {
  if (!values || !types) return !values && !types;
  if (values->size() != types->size()) return false;
  for (flatbuffers::uoffset_t i = 0; i < values->size(); ++i) {
    if (!VerifySpecificTask(
        verifier,  values->Get(i), types->GetEnum<SpecificTask>(i))) {
      return false;
    }
  }
  return true;
}

inline const MVCNN::GraphFile *GetGraphFile(const void *buf) {
  return flatbuffers::GetRoot<MVCNN::GraphFile>(buf);
}

inline const MVCNN::GraphFile *GetSizePrefixedGraphFile(const void *buf) {
  return flatbuffers::GetSizePrefixedRoot<MVCNN::GraphFile>(buf);
}

inline const char *GraphFileIdentifier() {
  return "BLOB";
}

inline bool GraphFileBufferHasIdentifier(const void *buf) {
  return flatbuffers::BufferHasIdentifier(
      buf, GraphFileIdentifier());
}

inline bool VerifyGraphFileBuffer(
    flatbuffers::Verifier &verifier) {
  return verifier.VerifyBuffer<MVCNN::GraphFile>(GraphFileIdentifier());
}

inline bool VerifySizePrefixedGraphFileBuffer(
    flatbuffers::Verifier &verifier) {
  return verifier.VerifySizePrefixedBuffer<MVCNN::GraphFile>(GraphFileIdentifier());
}

inline const char *GraphFileExtension() {
  return "blob";
}

inline void FinishGraphFileBuffer(
    flatbuffers::FlatBufferBuilder &fbb,
    flatbuffers::Offset<MVCNN::GraphFile> root) {
  fbb.Finish(root, GraphFileIdentifier());
}

inline void FinishSizePrefixedGraphFileBuffer(
    flatbuffers::FlatBufferBuilder &fbb,
    flatbuffers::Offset<MVCNN::GraphFile> root) {
  fbb.FinishSizePrefixed(root, GraphFileIdentifier());
}

}  // namespace MVCNN

#endif  // FLATBUFFERS_GENERATED_GRAPHFILE_MVCNN_H_
