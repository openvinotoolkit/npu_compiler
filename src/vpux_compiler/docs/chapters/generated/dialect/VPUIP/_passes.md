<!-- Autogenerated by mlir-tblgen; don't manually edit -->
### `-act-shave-profiling`: ActShave task profiling
This pass allocate required memory for ActShaveProfiling profiling and perform buffer spilling
### `-adjust-compress-conv-inputs`: Modify compress conv inputs
This pass checks if weights from a Convolution op were previously padded with zero, remove that pad and insert a ShapeCast op.
Also add a ShapeCast Op to activations if channels there are less than 16 channels
### `-break-data-flow`: Breaks the data flow in the graph
This pass breaks the data flow in the graph. It is required for the VPURT dialect for correct task creation
because all VPUIP dialect tasks will be inside body of the TaskOp and it is impossible to use operation results inside another body of TaskOp.
### `-calculate-async-region-cycle-cost`: Calculates cycle cost of 'async.execute'
### `-compress-weights-btc`: Compress binary data when possible using BitCompactor
This pass applies bitcompactor to tensor binary data. The logic is the following:
1. Find VPUIP::NNDMAOp with Const::DeclareOp source and VPURT::DeclareBufferOp target.
2. Check that weights size matches minimal compression size.
3. Compress weights.
4. Wrap compressed weights to flat tensor shapes with UInt8 data type.
5. Replace original VPUIP::NNDMAOp with VPUIP::CompressedDMAOp

This pass also handles multicluster cases, where NNDMAOp is wrapped in NCEClusterTiling with
DistributedBuffer output type (with DUPLICATED). SOK case is supported as well since this pass
is set to be executed after unroll-cluster-tiling, which splits SEGMENTED buffers into per-cluster
chunks.

This pass behaves differently for pre-VPU37XX and post-VPU37XX platforms. For former the compression
is done using huffman encoding and applied only to quantized data types, for the latter the
compression is done using bit-compactor library.
### `-compute-se-sizes`: Computes the storage element sizes for sparse NCEClusterTask activations
Computes the storage element sizes for the sparse activations of NCEClusterTasks.
The pass should be called twice:
- once with the `onlyInputsConcatOverC` set to true before use-def chains are lost,
  in order to populate the correct information for consumers of buffers that have been
  concatenated over channels; these can be explicit concat operations, broadcasted
  activations or produced by multiple variants;
- once after cluster tiling operations are unrolled, to populate the sizes for the
  rest of the sparse activations based on the number of channels present after unrolling.

Eltwise inputs must have both inputs generated with the same storage element size value.

#### Options
```
-only-inputs-concat-over-c : Flag to choose whether to handle only inputs concatenated over channels on this pass call
```
### `-convert-allocations-to-declarations`: Convert static allocations to declarations
### `-convert-async-ops-to-tasks`: Convert Async Dialect operations to tasks
This pass inlines 'async.execute' body to parent Block and replaces '!async.token' based dependencies with
VPUIP virtual barriers.
### `-convert-eltwise-to-in-place`: Convert Eltwise operation to read and write to the same buffer in memory
This pass will check if Eltwise operation was selected for inplace execution
and convert the Eltwise to write the result into one of the inputs in memory.
A view operation is added to support different quantization parameters for input/output.
Can be extended to support different input/output memory requirements with a subview.
### `-convert-expand`: Convert Expand that cannot fuse with permute to copy and concat subgraph
This pass will convert the Expand to copy and concat subgraph.
### `-convert-func-args-to-declarations`: Replace use of function arguments with result of DeclareBuffer
Operands that are network arguments are replaced by the result of DeclareBuffer operation
with the corresponding buffer section (NetworkInput/NetworkOutput)
### `-convert-to-dma`: Convert Permute and DepthToSpace from SW/UPA ops to DMA ops
This pass will convert some SW/UPA operations (e.g. DepthToSpace, Permute) to DMA ops
if it is possible to achieve better performance
### `-convert-transfer-ops-to-DMAs`: Convert data transfer operations to DMA
### `-convert-view-ops-to-declarations`: Convert view-like operations to declarations
### `-copy-op-hoisting`: Update location of CopyOps in the block
This pass checks all CopyOps and updates their position in the parent block to be close to source op
that generates the copy op source buffer
### `-dma-barrier-optimization`: Optimize DMA related barriers after dma port has been assigned for VPUX37XX
### `-dma-task-profiling`: DMA task profiling using DMA-Timestamps
This pass add DMA task profiling.
### `-dma-task-profiling-after-barrier`: DMA task profiling handling after barrier scheduled
This pass adds DMA profiling tasks after barrier scheduler.
### `-dma-task-profiling-reserve-mem`: DMA task profiling memory reserving
This pass adds in ModuleOp information about reserved memory for DMA profiling.
### `-dpu-profiling`: DPU task profiling
This pass allocate required memory for DPU profiling and perform buffer spilling
### `-dump-statistics-of-task-ops`: Dump the statistics of operations (used Task operations and weights compression)
This pass dumps the statistics for of used operations (e.g. tasks, weights compression) and makes a report as warning for operations not converted to DPU.
### `-feasible-allocation`: Feasible Memory Scheduling Pass
Schedule async.execute opeations based on their dependecies and CMX memory availability

#### Options
```
-memory-space              : Memory space to perform allocation
-second-level-memory-space : Second level memory space to perform spilling
```
### `-flatten-sparse-weights-types`: Flattens types that have a compression scheme
Flattens the type of the sparse weights into a binary buffer of values.
The weights operand of a NCE operation maintains the original type.
### `-fuse-constants`: Fuse constant inputs of NCEClusterOp
Concatenates input constants into one in the following order:
    weight_table -> weights -> weights_sparsity_map -> activation_window
For any NCEClusterTaskOp if the number of constants to fuse is 1 such layers are skipped
Special Case with DWCONV, if the constants to fuse are == 2 such DWCONV are skipped as weights are not constants
Special Case for Compressed Conv layer, if the weights are ShapeCast these such layers are skipped
### `-group-async-execute-ops`: Reduces number of async.execute operations
Groups consecutive operations which utilizes the same executor and max resources into same async.execute region
### `-group-profiling-buffers`: Group profiling buffers into single profiling output buffer
Group profiling buffers from different profiling engines into single profiling output buffer with name as
[offset]_[profiling name]_[offset]_[profiling name] so postprocessing tool can parse it back
### `-linearization`: Perform linearization of the IR
Perform linearization of the IR with fully sequential execution.
### `-maximize-upa-cycles`: Expand cycles for UPA ops
For each SHAVE_UPA executor the pass recalculates cycleBegin, cycleEnd and cycleCost
in order to expand cycle from latest producer of executor to nearest consumer.
It takes maximum of cycleEnd value of producers as new cycleBegin and minimum of cycleBegin
of consumers as new cycleEnd.
### `-move-pure-view-op-before-copy`: Move pure view-like operations before copy
By moving pure view-like ops, this pass creates copy operation chains, that can be fused:
Before: CopyOp -> PermuteCast -> GenericReshape -> CopyOp
After: PermuteCast -> GenericReshape -> CopyOp -> CopyOp
### `-move-view-ops-into-async-regions`: Moves view-like Operations inside the asynchronous regions which depends on them
### `-move-wait-result-to-async-block-args`: Moves 'async.await' result usage from 'async.execute' body to it's operands
### `-operation-stubbing`: Stub operations with StubOp
### `-optimize-async-deps`: Optimizes dependencies between 'async.execute' operations
The pass tries to remove extra explicit `!async.token` based dependencies,
if they are represented implicitly (as a result of transitive dependencies).
### `-optimize-copies`: Removes Copy Ops which are unnecessary
This pass checks if Copy Op can be optimized out to reduce the amount of unnecessary DMAs and intermediate buffers.
### `-optimize-parallel-copies`: Copy the data only once for all the tiles that share the same data
This pass checks all the CopyOps consumed by tiles of one tiling subgraph.
If the CopyOps operate on the same weight or activation, merge the parallel copies into one.
### `-optimize-spilling-copies`: Optimize pattern with CMX->DDR->CMX spilling
Optimize following pattern

NCE Task 16 channels output -> Copy 16 channels -> Concat -> Subview -> 3 channels

to

NCE Task 16 channels output -> Copy 3 channels -> Concat -> Subview -> 3 channels

### `-patch-fused-constants`: Patch the weight table fused in fused constant
This pass converts the U8 weight table values to I32. Updates the address of each weight set
and activation window present in the fused constant for each output channel of the layer
### `-patch-weight-table`: Adjusts weights and sparsity pointers after memory scheduling
This pass adds RelocateWeightsTable transformation to weights table constants. The transformation adds weights and sparsity base pointers
to offset that are already filled in the weights table constants.
### `-propagate-compression-scheme`: Compresses the type of the sparse weights
Propagates the compression scheme attribute from the sparse buffer type to the individual types
that are grouped into a sparse buffer. Starting from the sparse weights constant, all types up to
the consumer NCE operation will have the compression scheme present.
### `-resolve-dma-with-swizzling`: Transform DMAs that operate on swizzled buffers
This pass will transform DMAs that operate on swizzled buffers so that they
copy buffers of size aligned to 512 to satisfy swizzling HW restrictions.
Transformation will result in a flat buffer copy of required size
### `-set-memory-space`: Set specific memory space for all memory buffers
This pass updates all Types for internal memory buffers and function arguments and sets the specified memory space for them.
Also updates the operand types for grouping operations, to cover scenarios where some operands are buffers and some are constants.

#### Options
```
-memory-space : Memory space to perform allocation
```
### `-static-allocation`: Replace dynamic allocations with static
This pass replaces all dynamic `alloc`/`dealloc` Operations with `VPUIP.StaticAlloc`.
It uses simple LinearScan algorithm.

#### Options
```
-memory-space : Memory space to perform allocation
```
### `-swizzling`: Configure swizzling for eligible buffers
On HW with swizzling support (VPUX37XX) enable activation swizzling for DPU to DPU
buffers. This includes setting specific swizzling key and alignment as part of
allocation operation.
Swizzling requirement:
- buffer needs to be properly aligned
- swizzled buffers must be given in CMX space with size of multiple of 512
- activation buffer must be one produced and consumed by DPU type task
- buffer for weights can be swizzled and needs to have swizzling transformation performed on the content
Device supported swizzling key
- 0: 16 bytes alignment
- 1: 1024 bytes alignment
- 2: 2048 bytes alignment
- 3: 4096 bytes alignment
- 4: 8192 bytes alignment
- 5: 16384 bytes alignment
### `-tile-act-shave-kernel-task`: Tile act shave kernel task on multi shaves
This pass will tile act kernel run task on multi shaves.
### `-tile-copies`: Legalizes Copy Ops which do not fit hardware capabilities
This pass checks if Copy Op can be executed at target hardware and splits it into a few tiles if necessary.
To fit hardware requirements it should copy less or equal than 16MB(2**24 bytes) and have less than 256 planes.
The number of planes is defined by the outermost dimension in the tensor (except for N - batch).
Depending on the order of the data in memory, there may be several options for what to count as the number of planes.
For example, if the dimension order (from the outermost to the innermost) is NCHW, then HW (height-width) is considered a plane,
and the number of planes equals to the value of dimension C. The number of planes for different dimension orders:
* For NHWC - H
* For NCHW - C
* For NWCH - W
### `-ungroup-sparse-buffers`: Ungroups sparse buffers into individual buffers
Splits operations that work with sparse buffers into multiple operations,
each working with an individual buffer.

These separate operations are then surrounded by UngroupSparseBuffer
and / or GroupSparseBuffer operations, which can be optimized-out by
the canonicalizer.
### `-unroll-cluster-tiling`: Extracts child operations from ClusterTiling operation
Legalizes chain of ClusterTiling operations according to the tile schema
### `-unroll-depth-to-space-dma`: Split DepthToSpaceDMA task with several NN DMA tasks
This pass spilt DepthToSpaceDMA tasks with several NN DMA tasks, which are functionally equivalent.
Each sub DepthToSpaceDMA will be converted to a NNDMA.
1. if input/output layout is NHWC with model block_first, number of sub DepthToSpaceDMA is same as block_size.
2. if input/output layout is NHWC with model depth_first, number of sub DepthToSpaceDMA is OH * OW / block_size.
block_size is the size of the spatial block. It is an attribution of DepthToSpace.
### `-unroll-expand-dma`: Unroll expand task with several NN DMA tasks
This pass unroll ExpandDMA tasks with several NN DMA tasks, which are functionally equivalent.
Each sub ExpandDMA will be converted to a NNDMA.
### `-unroll-per-axis-tile-dma`: Split PerAxisTileDMA task with several NN DMA tasks
This pass splits PerAxisTileDMA tasks into several NN DMA tasks, which are functionally equivalent.
Each sub PerAxisTileDMA will be converted to a NNDMA.
### `-unroll-permute-to-nndma`: Transform PermuteDMA task with one or several PermuteDMA tasks
This pass unrolls PermuteDMA task to one or several PermuteDMA tasks.
The number of PermuteDMA depend on the number of planes (num_planes <= 256).
1. NCHW -> NHWC: The number of planes is C.
2. NHWC -> NCHW: The number of planes is H * W, and W must <= 256.
### `-unroll-space-to-depth-dma`: Split SpaceToDepthDMA task with several NN DMA tasks
This pass splits SpaceToDepthDMA tasks into several NN DMA tasks, which are functionally equivalent.
Each sub SpaceToDepthDMA will be converted to a NNDMA.
### `-unroll-sw-kernel`: Unroll SwKernel task with several SwKernel.Run
This pass unroll SwKernel task with several SwKernel.Run, which are functionally equivalent.
Each SwkernelRun will be wrapped into a SwKernel task.
### `-unroll-upsampling-dma`: Unroll upsampling task with several NN DMA tasks
This pass unroll UpsamplingDMA tasks with several NN DMA tasks, which are functionally equivalent.
Each sub UpsamplingDMA will be converted to a NNDMA.
### `-upa-profiling`: upa task profiling
This pass allocate required memory in DDR space for UPA profiling and is own profiling output to the network
### `-wrap-into-async-regions`: Wraps layer operations into asynchronous regions
This pass wraps each IERT and VPUIP layer operation into async region preserving linear execution.
### `-wrap-with-permute-as-nndma`: Wrap op and permute operation as dma and fuse unnecessary copy ops
This pass will replace specific op and permute as one DMA and fuse the unnecessary following copy ops
