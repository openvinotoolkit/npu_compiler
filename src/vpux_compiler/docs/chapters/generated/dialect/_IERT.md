<!-- Autogenerated by mlir-tblgen; don't manually edit -->
# 'IERT' Dialect

InferenceEngine RunTime Dialect
The **IERT Dialect** represents bufferized version of **IE Dialect**.

It has the following properties:

* Works with fixed operation set (like **IE Dialect**).
* Represents execution scheduling and memory allocation.
* Works with `MemRefType`.
* Includes transformations and optimizations closer to HW level (memory re-usage, parallel resources usage, etc.).

**TBD:** It operates with `MemRefType`, but in contrast to MLIR uses SSA value semantic (inspired by PlaidML approach).
It combines both memory effects and buffer aliasing for this:

* Each layer operation takes as its operands both input and output buffers.
* The layer marks input buffer as read-only and output buffer as write-only via memory effects inferface.
* The layer returns new buffer Value, which is an alias for output buffer.

```MLIR
#NHWC = affine_map<(n, c, h, w) -> (n, h, w, c)>

func @main(%input: memref<1x3x240x240xf16, #NHWC>, %output: memref<1x3x240x240xf16, #NHWC>) -> memref<1x3x240x240xf16, #NHWC> {
    %1 = IERT.SoftMax(%input, %output) {axisInd = 1} // %1 is an alias for %output
    return %1
}
```

The memory allocation/deallocation is defined as separate operations (dynamic or static).

The **IERT Dialect** uses the following scheme to represent scheduling information:

* Operations order defines scheduling.
* Each IERT operation is assumed as blocking: next operation will not start until previous is finished.
* Concurrent execution is defined as asynchronous regions (**Async Dialect**).

```MLIR
%11_t, %11_f = async.execute { IERT.executor = @NCE }
    [%7_t, %8_9_t](%8_9_f#0 as %8, %8_9_f#1 as %9)
{
    %11_0_t, %11_0_f = async.execute { IERT.executor = @DPU }
    {
        %11_0 = IERT.Convolution(%7, %8, %9) to %10_0 { strides = [1, 1], pads_begin = [1, 1], pads_end = [1, 1] }
        async.yield %11_0
    }

    %11_1_t, %11_1_f = async.execute { IERT.executor = @DPU }
    {
        %11_1 = IERT.Convolution(%7, %8, %9) to %10_1 { strides = [1, 1], pads_begin = [1, 1], pads_end = [1, 1] }
        async.yield %11_1
    }

    %11:2 = async.await %11_0_f, %11_1_f
    %11 = IERT.FakeConcat(%11#0, %11#1) to %10
    async.yield %11
}
```

[./IERT/_ops_interfaces.md]

[TOC]

## Operation definition

### `IERT.Acosh` (vpux::IERT::AcoshOp)

InferenceEngine run-time Acosh layer


Syntax:

```
operation ::= `IERT.Acosh` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Add` (vpux::IERT::AddOp)

InferenceEngine run-time Add layer


Syntax:

```
operation ::= `IERT.Add` attr-dict
              `inputs` `(` $input1 `:` type($input1) `,` $input2 `:` type($input2) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`post_op` | vpux::IE::PostOp | DictionaryAttr with field(s): 'name', 'attrs' (each field having its own constraints)

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input1` | memref of 16-bit float or 32-bit float or QuantizedType values
`input2` | memref of 16-bit float or 32-bit float or QuantizedType values
`output_buff` | memref of 16-bit float or 32-bit float or QuantizedType values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float or QuantizedType values

### `IERT.And` (vpux::IERT::AndOp)

InferenceEngine run-time And layer


Syntax:

```
operation ::= `IERT.And` attr-dict
              `inputs` `(` $input1 `:` type($input1) `,` $input2 `:` type($input2) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`post_op` | vpux::IE::PostOp | DictionaryAttr with field(s): 'name', 'attrs' (each field having its own constraints)

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input1` | memref of 16-bit float or 32-bit float or QuantizedType values
`input2` | memref of 16-bit float or 32-bit float or QuantizedType values
`output_buff` | memref of 16-bit float or 32-bit float or QuantizedType values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float or QuantizedType values

### `IERT.Asinh` (vpux::IERT::AsinhOp)

InferenceEngine run-time Asinh layer


Syntax:

```
operation ::= `IERT.Asinh` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.AvgPool` (vpux::IERT::AvgPoolOp)

InferenceEngine run-time AvgPool layer


Syntax:

```
operation ::= `IERT.AvgPool` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`kernel_size` | ::mlir::ArrayAttr | 64-bit integer array attribute
`strides` | ::mlir::ArrayAttr | 64-bit integer array attribute
`pads_begin` | ::mlir::ArrayAttr | 64-bit integer array attribute
`pads_end` | ::mlir::ArrayAttr | 64-bit integer array attribute
`exclude_pads` | ::mlir::UnitAttr | unit attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Broadcast` (vpux::IERT::BroadcastOp)

InferenceEngine run-time Broadcast layer


Syntax:

```
operation ::= `IERT.Broadcast` attr-dict
              `inputs` `(` $input `:` type($input) `,` $target_shape `:` type($target_shape) (`,` $axes_mapping^ `:` type($axes_mapping))? `)`
              `ouputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`mode` | vpux::IE::BroadcastTypeAttr | Broadcast type that operations support

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of any type values
`target_shape` | memref of 64-bit signed integer or 32-bit signed integer values
`axes_mapping` | memref of 64-bit signed integer or 32-bit signed integer values
`output_buff` | memref of any type values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of any type values

### `IERT.CTCGreedyDecoder` (vpux::IERT::CTCGreedyDecoderOp)

InferenceEngine run-time CTCGreedyDecoder layer


Syntax:

```
operation ::= `IERT.CTCGreedyDecoder` attr-dict
              `inputs` `(` $input `:` type($input) `,` $sequenceLengths `:` type($sequenceLengths) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`mergeRepeated` | ::mlir::UnitAttr | unit attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`sequenceLengths` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.CTCGreedyDecoderSeqLen` (vpux::IERT::CTCGreedyDecoderSeqLenOp)

InferenceEngine run-time CTCGreedyDecoderSeqLen layer


Syntax:

```
operation ::= `IERT.CTCGreedyDecoderSeqLen` attr-dict
              `inputs` `(` $input `:` type($input) `,` $sequenceLength `:` type($sequenceLength) (`,` $blankIndex^ `:` type($blankIndex))? `)`
              `outputs` `(` $output_buff `:` type($output_buff) `,` $outputLength_buff `:` type($outputLength_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`mergeRepeated` | ::mlir::UnitAttr | unit attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`sequenceLength` | memref of 32-bit signed integer values
`blankIndex` | memref of 32-bit signed integer values
`output_buff` | memref of 32-bit signed integer values
`outputLength_buff` | memref of 32-bit signed integer values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 32-bit signed integer values
`outputLength` | memref of 32-bit signed integer values

### `IERT.Ceiling` (vpux::IERT::CeilingOp)

InferenceEngine run-time Ceiling layer


Syntax:

```
operation ::= `IERT.Ceiling` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Clamp` (vpux::IERT::ClampOp)

InferenceEngine run-time Clamp layer


Syntax:

```
operation ::= `IERT.Clamp` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`min` | ::mlir::FloatAttr | 64-bit float attribute
`max` | ::mlir::FloatAttr | 64-bit float attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.ConcatView` (vpux::IERT::ConcatViewOp)

InferenceEngine run-time ConcatView layer. Dummy operation to maintain use-def chains.


Syntax:

```
operation ::= `IERT.ConcatView` attr-dict
              `inputs` `(` $inputs `:` type($inputs) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`inputs` | memref of any type values
`output_buff` | memref of any type values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of any type values

### `IERT.Convert` (vpux::IERT::ConvertOp)

InferenceEngine run-time Convert layer


Syntax:

```
operation ::= `IERT.Convert` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of any type values
`output_buff` | memref of any type values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of any type values

### `IERT.Convolution` (vpux::IERT::ConvolutionOp)

InferenceEngine run-time Convolution layer


Syntax:

```
operation ::= `IERT.Convolution` attr-dict
              `inputs` `(` $input `:` type($input) `,` $filter `:` type($filter) (`,` $bias^ `:` type($bias))? `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`strides` | ::mlir::ArrayAttr | 64-bit integer array attribute
`pads_begin` | ::mlir::ArrayAttr | 64-bit integer array attribute
`pads_end` | ::mlir::ArrayAttr | 64-bit integer array attribute
`dilations` | ::mlir::ArrayAttr | 64-bit integer array attribute
`post_op` | vpux::IE::PostOp | DictionaryAttr with field(s): 'name', 'attrs' (each field having its own constraints)

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float or QuantizedType values
`filter` | memref of 16-bit float or 32-bit float or QuantizedType values
`bias` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float or QuantizedType values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float or QuantizedType values

### `IERT.Copy` (vpux::IERT::CopyOp)

InferenceEngine run-time Copy layer


Syntax:

```
operation ::= `IERT.Copy` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of any type values
`output_buff` | memref of any type values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of any type values

### `IERT.Cosh` (vpux::IERT::CoshOp)

InferenceEngine run-time Cosh layer


Syntax:

```
operation ::= `IERT.Cosh` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.DepthToSpace` (vpux::IERT::DepthToSpaceOp)

InferenceEngine run-time DepthToSpace layer


Syntax:

```
operation ::= `IERT.DepthToSpace` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`block_size` | mlir::IntegerAttr | Integer attribute
`mode` | vpux::IE::DepthToSpaceModeAttr | DepthToSpaceMode that the InferenceEngine supports

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float values
`output_buff` | memref of 16-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float values

### `IERT.Dequantize` (vpux::IERT::DequantizeOp)

InferenceEngine run-time Dequantize layer


Syntax:

```
operation ::= `IERT.Dequantize` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of QuantizedType values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.DetectionOutput` (vpux::IERT::DetectionOutputOp)

InferenceEngine run-time DetectionOutput layer


Syntax:

```
operation ::= `IERT.DetectionOutput` attr-dict
              `inputs` `(` $in_box_logits `:` type($in_box_logits) `,` $in_class_preds `:` type($in_class_preds) `,` $in_proposals `:` type($in_proposals) (`,` $in_additional_preds^ `:` type($in_additional_preds))? (`,` $in_additional_proposals^ `:` type($in_additional_proposals))? `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`attr` | vpux::IE::DetectionOutputAttr | DictionaryAttr with field(s): 'num_classes', 'background_label_id', 'top_k', 'variance_encoded_in_target', 'keep_top_k', 'code_type', 'share_location', 'nms_threshold', 'confidence_threshold', 'clip_after_nms', 'clip_before_nms', 'decrease_label_id', 'normalized', 'input_height', 'input_width', 'objectness_score' (each field having its own constraints)

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`in_box_logits` | memref of floating-point values
`in_class_preds` | memref of floating-point values
`in_proposals` | memref of floating-point values
`in_additional_preds` | memref of floating-point values
`in_additional_proposals` | memref of floating-point values
`output_buff` | memref of floating-point values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of floating-point values

### `IERT.Divide` (vpux::IERT::DivideOp)

InferenceEngine run-time Divide layer


Syntax:

```
operation ::= `IERT.Divide` attr-dict
              `inputs` `(` $input1 `:` type($input1) `,` $input2 `:` type($input2) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input1` | memref of 16-bit float or 32-bit float values
`input2` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Elu` (vpux::IERT::EluOp)

InferenceEngine run-time Elu layer


Syntax:

```
operation ::= `IERT.Elu` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`x` | ::mlir::FloatAttr | 64-bit float attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Equal` (vpux::IERT::EqualOp)

InferenceEngine run-time Equal layer


Syntax:

```
operation ::= `IERT.Equal` attr-dict
              `inputs` `(` $input1 `:` type($input1) `,` $input2 `:` type($input2) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input1` | memref of 16-bit float or 32-bit float values
`input2` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Erf` (vpux::IERT::ErfOp)

InferenceEngie run-time Erf layer


Syntax:

```
operation ::= `IERT.Erf` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Exp` (vpux::IERT::ExpOp)

InferenceEngine run-time Exp layer


Syntax:

```
operation ::= `IERT.Exp` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.FakeQuantize` (vpux::IERT::FakeQuantizeOp)

InferenceEngine FakeQuantize layer


Syntax:

```
operation ::= `IERT.FakeQuantize` attr-dict
              `inputs` `(` $input `:` type($input) `,` $input_low `:` type($input_low) `,` $input_high `:` type($input_high) `,` $output_low `:` type($output_low) `,` $output_high `:` type($output_high) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`levels` | mlir::IntegerAttr | Integer attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`input_low` | memref of 16-bit float or 32-bit float values
`input_high` | memref of 16-bit float or 32-bit float values
`output_low` | memref of 16-bit float or 32-bit float values
`output_high` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.FloorMod` (vpux::IERT::FloorModOp)

InferenceEngine run-time FloorMod layer


Syntax:

```
operation ::= `IERT.FloorMod` attr-dict
              `inputs` `(` $input1 `:` type($input1) `,` $input2 `:` type($input2) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input1` | memref of 16-bit float or 32-bit float values
`input2` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Floor` (vpux::IERT::FloorOp)

InferenceEngine run-time Floor layer


Syntax:

```
operation ::= `IERT.Floor` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.FullyConnected` (vpux::IERT::FullyConnectedOp)

InferenceEngine run-time FullyConnected layer


Syntax:

```
operation ::= `IERT.FullyConnected` attr-dict
              `inputs` `(` $input `:` type($input) `,` $weights `:` type($weights) (`,` $bias^ `:` type($bias))? `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`weights` | memref of 16-bit float or 32-bit float values
`bias` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.GRN` (vpux::IERT::GRNOp)

InferenceEngine run-time GRN layer


Syntax:

```
operation ::= `IERT.GRN` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`bias` | ::mlir::FloatAttr | 64-bit float attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.GatherElements` (vpux::IERT::GatherElementsOp)

InferenceEngine run-time GatherElements layer


Syntax:

```
operation ::= `IERT.GatherElements` attr-dict
              `inputs` `(` $input `:` type($input) `,` $indices `:` type($indices) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`axis` | mlir::IntegerAttr | Integer attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of any type values
`indices` | memref of 64-bit signed integer or 32-bit signed integer values
`output_buff` | memref of any type values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of any type values

### `IERT.Gather` (vpux::IERT::GatherOp)

InferenceEngine run-time Gather layer


Syntax:

```
operation ::= `IERT.Gather` attr-dict
              `inputs` `(` $input `:` type($input) `,` $indices `:` type($indices) (`,` $axis^ `:` type($axis))? `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`axis_value` | mlir::IntegerAttr | Integer attribute
`batch_dims` | mlir::IntegerAttr | Integer attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of any type values
`indices` | memref of 64-bit signed integer or 32-bit signed integer values
`axis` | memref of any type values
`output_buff` | memref of any type values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of any type values

### `IERT.Gelu` (vpux::IERT::GeluOp)

InferenceEngine run-time Gelu layer


Syntax:

```
operation ::= `IERT.Gelu` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.GenericReshape` (vpux::IERT::GenericReshapeOp)

InferenceEngine run-time generic Reshape layer


Syntax:

```
operation ::= `IERT.GenericReshape` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of any type values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of any type values

### `IERT.GreaterEqual` (vpux::IERT::GreaterEqualOp)

InferenceEngine run-time GreaterEqual layer


Syntax:

```
operation ::= `IERT.GreaterEqual` attr-dict
              `inputs` `(` $input1 `:` type($input1) `,` $input2 `:` type($input2) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input1` | memref of 16-bit float or 32-bit float values
`input2` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Greater` (vpux::IERT::GreaterOp)

InferenceEngine run-time Greater layer


Syntax:

```
operation ::= `IERT.Greater` attr-dict
              `inputs` `(` $input1 `:` type($input1) `,` $input2 `:` type($input2) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input1` | memref of 16-bit float or 32-bit float values
`input2` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.GroupConvolution` (vpux::IERT::GroupConvolutionOp)

InferenceEngine run-time GroupConvolution layer


Syntax:

```
operation ::= `IERT.GroupConvolution` attr-dict
              `inputs` `(` $input `:` type($input) `,` $filter `:` type($filter) (`,` $bias^ `:` type($bias))? `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`strides` | ::mlir::ArrayAttr | 64-bit integer array attribute
`pads_begin` | ::mlir::ArrayAttr | 64-bit integer array attribute
`pads_end` | ::mlir::ArrayAttr | 64-bit integer array attribute
`dilations` | ::mlir::ArrayAttr | 64-bit integer array attribute
`groups` | mlir::IntegerAttr | Integer attribute
`post_op` | vpux::IE::PostOp | DictionaryAttr with field(s): 'name', 'attrs' (each field having its own constraints)

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float or QuantizedType values
`filter` | memref of 16-bit float or 32-bit float or QuantizedType values
`bias` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float or QuantizedType values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float or QuantizedType values

### `IERT.HSwish` (vpux::IERT::HSwishOp)

InferenceEngine run-time HSwish layer


Syntax:

```
operation ::= `IERT.HSwish` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Interpolate` (vpux::IERT::InterpolateOp)

InferenceEngine run-time Interpolate layer


Syntax:

```
operation ::= `IERT.Interpolate` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`mode` | vpux::IE::InterpolateModeAttr | Specifies type of interpolation
`coord_mode` | vpux::IE::InterpolateCoordModeAttr | coordinate_transformation_mode specifies how to transform the coordinate.
`nearest_mode` | vpux::IE::InterpolateNearestModeAttr | specifies round mode when mode == nearest
`antialias` | ::mlir::UnitAttr | unit attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.LRN_IE` (vpux::IERT::LRN_IEOp)

InferenceEngine run-time LRN_IE layer


Syntax:

```
operation ::= `IERT.LRN_IE` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `ouputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`alpha` | ::mlir::FloatAttr | 64-bit float attribute
`beta` | ::mlir::FloatAttr | 64-bit float attribute
`bias` | ::mlir::FloatAttr | 64-bit float attribute
`size` | mlir::IntegerAttr | Integer attribute
`region` | vpux::IE::LRN_IERegionAttr | LRN_IE region that operations support

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.LSTMCell` (vpux::IERT::LSTMCellOp)

InferenceEngine run-time LSTMCell layer


Syntax:

```
operation ::= `IERT.LSTMCell` attr-dict
              `inputs` `(` $inputData `:` type($inputData) `,` $initialHiddenState `:` type($initialHiddenState) `,` $initialCellState `:` type($initialCellState)
              `,` $weights `:` type($weights) `,` $biases `:` type($biases) `)`
              `outputs` `(` $outputHiddenState_buff `:` type($outputHiddenState_buff) `,` $outputCellState_buff `:` type($outputCellState_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`hiddenSize` | mlir::IntegerAttr | Integer attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`inputData` | memref of 16-bit float or 32-bit float values
`initialHiddenState` | memref of 16-bit float or 32-bit float values
`initialCellState` | memref of 16-bit float or 32-bit float values
`weights` | memref of 16-bit float or 32-bit float values
`biases` | memref of 16-bit float or 32-bit float values
`outputHiddenState_buff` | memref of 16-bit float or 32-bit float values
`outputCellState_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`outputHiddenState` | memref of 16-bit float or 32-bit float values
`outputCellState` | memref of 16-bit float or 32-bit float values

### `IERT.LSTMSequence` (vpux::IERT::LSTMSequenceOp)

InferenceEngine run-time LSTMSequence layer


Syntax:

```
operation ::= `IERT.LSTMSequence` attr-dict
              `inputs` `(` $inputData `:` type($inputData) `,` $initialHiddenState `:` type($initialHiddenState) `,` $initialCellState `:` type($initialCellState)
              `,` $weights `:` type($weights) `,` $biases `:` type($biases) `)`
              `outputs` `(` $outputHiddenValues_buff `:` type($outputHiddenValues_buff) `,`
              $outputHiddenState_buff `:` type($outputHiddenState_buff) `,`
              $outputCellState_buff `:` type($outputCellState_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`sequenceLength` | mlir::IntegerAttr | Integer attribute
`direction` | vpux::IE::RNNSequenceDirectionAttr | RNNSequenceDirection that the InferenceEngine supports

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`inputData` | memref of 16-bit float or 32-bit float values
`initialHiddenState` | memref of 16-bit float or 32-bit float values
`initialCellState` | memref of 16-bit float or 32-bit float values
`weights` | memref of 16-bit float or 32-bit float values
`biases` | memref of 16-bit float or 32-bit float values
`outputHiddenValues_buff` | memref of 16-bit float or 32-bit float values
`outputHiddenState_buff` | memref of 16-bit float or 32-bit float values
`outputCellState_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`outputHiddenValues` | memref of 16-bit float or 32-bit float values
`outputHiddenState` | memref of 16-bit float or 32-bit float values
`outputCellState` | memref of 16-bit float or 32-bit float values

### `IERT.LeakyRelu` (vpux::IERT::LeakyReluOp)

InferenceEngine run-time LeakyRelu layer


Syntax:

```
operation ::= `IERT.LeakyRelu` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`negative_slope` | ::mlir::FloatAttr | 64-bit float attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.LessEqual` (vpux::IERT::LessEqualOp)

InferenceEngine run-time LessEqual layer


Syntax:

```
operation ::= `IERT.LessEqual` attr-dict
              `inputs` `(` $input1 `:` type($input1) `,` $input2 `:` type($input2) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input1` | memref of 16-bit float or 32-bit float values
`input2` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Less` (vpux::IERT::LessOp)

InferenceEngine run-time Less layer


Syntax:

```
operation ::= `IERT.Less` attr-dict
              `inputs` `(` $input1 `:` type($input1) `,` $input2 `:` type($input2) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input1` | memref of 16-bit float or 32-bit float values
`input2` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Log` (vpux::IERT::LogOp)

InferenceEngine run-time Log layer


Syntax:

```
operation ::= `IERT.Log` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.LogicalOr` (vpux::IERT::LogicalOrOp)

InferenceEngine run-time LogicalOr layer


Syntax:

```
operation ::= `IERT.LogicalOr` attr-dict
              `inputs` `(` $input1 `:` type($input1) `,` $input2 `:` type($input2) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input1` | memref of 16-bit float or 32-bit float values
`input2` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.LogicalXor` (vpux::IERT::LogicalXorOp)

InferenceEngine run-time LogicalXor layer


Syntax:

```
operation ::= `IERT.LogicalXor` attr-dict
              `inputs` `(` $input1 `:` type($input1) `,` $input2 `:` type($input2) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input1` | memref of 16-bit float or 32-bit float values
`input2` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.MVN` (vpux::IERT::MVNOp)

InferenceEngine Run-Time MVN layer


Syntax:

```
operation ::= `IERT.MVN` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`across_channels` | ::mlir::BoolAttr | bool attribute
`normalize_variance` | ::mlir::BoolAttr | bool attribute
`eps` | ::mlir::FloatAttr | 64-bit float attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of any type values
`output_buff` | memref of any type values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of any type values

### `IERT.MaxPool` (vpux::IERT::MaxPoolOp)

InferenceEngine run-time MaxPool layer


Syntax:

```
operation ::= `IERT.MaxPool` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`kernel_size` | ::mlir::ArrayAttr | 64-bit integer array attribute
`strides` | ::mlir::ArrayAttr | 64-bit integer array attribute
`pads_begin` | ::mlir::ArrayAttr | 64-bit integer array attribute
`pads_end` | ::mlir::ArrayAttr | 64-bit integer array attribute
`post_op` | vpux::IE::PostOp | DictionaryAttr with field(s): 'name', 'attrs' (each field having its own constraints)

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float or QuantizedType values
`output_buff` | memref of 16-bit float or 32-bit float or QuantizedType values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float or QuantizedType values

### `IERT.Maximum` (vpux::IERT::MaximumOp)

InferenceEngine run-time Maximum layer


Syntax:

```
operation ::= `IERT.Maximum` attr-dict
              `inputs` `(` $input1 `:` type($input1) `,` $input2 `:` type($input2) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input1` | memref of 16-bit float or 32-bit float values
`input2` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.MemPermute` (vpux::IERT::MemPermuteOp)

InferenceEngine run-time MemPermute layer


Syntax:

```
operation ::= `IERT.MemPermute` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`mem_perm` | ::mlir::AffineMapAttr | AffineMap attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of any type values
`output_buff` | memref of any type values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of any type values

### `IERT.Minimum` (vpux::IERT::MinimumOp)

InferenceEngine run-time Minimum layer


Syntax:

```
operation ::= `IERT.Minimum` attr-dict
              `inputs` `(` $input1 `:` type($input1) `,` $input2 `:` type($input2) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input1` | memref of 16-bit float or 32-bit float values
`input2` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Mish` (vpux::IERT::MishOp)

InferenceEngine run-time Mish layer


Syntax:

```
operation ::= `IERT.Mish` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Multiply` (vpux::IERT::MultiplyOp)

InferenceEngine run-time Multiply layer


Syntax:

```
operation ::= `IERT.Multiply` attr-dict
              `inputs` `(` $input1 `:` type($input1) `,` $input2 `:` type($input2) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`post_op` | vpux::IE::PostOp | DictionaryAttr with field(s): 'name', 'attrs' (each field having its own constraints)

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input1` | memref of 16-bit float or 32-bit float or QuantizedType values
`input2` | memref of 16-bit float or 32-bit float or QuantizedType values
`output_buff` | memref of 16-bit float or 32-bit float or QuantizedType values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float or QuantizedType values

### `IERT.Negative` (vpux::IERT::NegativeOp)

InferenceEngine run-time Negative layer


Syntax:

```
operation ::= `IERT.Negative` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.NormalizeIE` (vpux::IERT::NormalizeIEOp)

InferenceEngine run-time NormalizeIE layer


Syntax:

```
operation ::= `IERT.NormalizeIE` attr-dict
              `inputs` `(` $data `:` type($data) `,` $weights `:` type($weights) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`eps` | ::mlir::FloatAttr | 64-bit float attribute
`across_spatial` | ::mlir::BoolAttr | bool attribute
`channel_shared` | ::mlir::BoolAttr | bool attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`data` | memref of 16-bit float or 32-bit float values
`weights` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.NotEqual` (vpux::IERT::NotEqualOp)

InferenceEngine run-time NotEqual layer


Syntax:

```
operation ::= `IERT.NotEqual` attr-dict
              `inputs` `(` $input1 `:` type($input1) `,` $input2 `:` type($input2) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input1` | memref of 16-bit float or 32-bit float values
`input2` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.PRelu` (vpux::IERT::PReluOp)

InferenceEngine run-time PRelu layer


Syntax:

```
operation ::= `IERT.PRelu` attr-dict
              `inputs` `(` $input `:` type($input) `,` $negative_slope `:` type($negative_slope) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`negative_slope` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Pad` (vpux::IERT::PadOp)

InferenceEngine run-time Pad layer


Syntax:

```
operation ::= `IERT.Pad` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`pads_begin` | ::mlir::ArrayAttr | 64-bit integer array attribute
`pads_end` | ::mlir::ArrayAttr | 64-bit integer array attribute
`pad_value` | ::mlir::FloatAttr | 64-bit float attribute
`mode` | vpux::IE::PadModeAttr | TPadMode that the InferenceEngine supports

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.PerAxisTile` (vpux::IERT::PerAxisTileOp)

InferenceEngine run-time per axis Tile layer


Syntax:

```
operation ::= `IERT.PerAxisTile` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`axis` | mlir::IntegerAttr | Integer attribute
`tiles` | mlir::IntegerAttr | Integer attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.PermuteCast` (vpux::IERT::PermuteCastOp)

Compile-time PermuteCast layer


Syntax:

```
operation ::= `IERT.PermuteCast` attr-dict
              `inputs` `(` $source `:` type($source) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`dst_order` | ::mlir::AffineMapAttr | AffineMap attribute
`mem_perm` | ::mlir::AffineMapAttr | AffineMap attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`source` | memref of any type values

#### Results:

| Result | Description |
| :----: | ----------- |
`result` | memref of any type values

### `IERT.Power` (vpux::IERT::PowerOp)

InferenceEngine run-time Power layer


Syntax:

```
operation ::= `IERT.Power` attr-dict
              `inputs` `(` $input1 `:` type($input1) `,` $input2 `:` type($input2) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input1` | memref of 16-bit float or 32-bit float values
`input2` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Proposal` (vpux::IERT::ProposalOp)

InferenceEngine run-time Proposal layer


Syntax:

```
operation ::= `IERT.Proposal` attr-dict
              `inputs` `(` $class_probs `:` type($class_probs) `,` $bbox_deltas `:` type($bbox_deltas) `,` $image_shape `:` type($image_shape) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`proposal_attrs` | vpux::IE::ProposalAttr | DictionaryAttr with field(s): 'baseSize', 'preNmsTopN', 'postNmsTopN', 'nmsThresh', 'featStride', 'minSize', 'ratio', 'scale', 'clipBeforeNms', 'clipAfterNms', 'normalize', 'boxSizeScale', 'boxCoordinateScale', 'framework', 'inferProbs' (each field having its own constraints)

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`class_probs` | memref of 16-bit float or 32-bit float values
`bbox_deltas` | memref of 16-bit float or 32-bit float values
`image_shape` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.QuantizeCast` (vpux::IERT::QuantizeCastOp)

InferenceEngine run-time Quantize Cast layer


Syntax:

```
operation ::= `IERT.QuantizeCast` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 8-bit signed integer or 8-bit unsigned integer or QuantizedType values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of QuantizedType values

### `IERT.Quantize` (vpux::IERT::QuantizeOp)

InferenceEngine run-time Quantize layer


Syntax:

```
operation ::= `IERT.Quantize` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of QuantizedType values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of QuantizedType values

### `IERT.ROIAlign` (vpux::IERT::ROIAlignOp)

InferenceEngine run-time ROIAlign layer


Syntax:

```
operation ::= `IERT.ROIAlign` attr-dict
              `inputs` `(` $input `:` type($input) `,` $coords `:` type($coords) `,` $roisIdx `:` type($roisIdx) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`pooled_h` | mlir::IntegerAttr | Integer attribute
`pooled_w` | mlir::IntegerAttr | Integer attribute
`sampling_ratio` | mlir::IntegerAttr | Integer attribute
`spatial_scale` | ::mlir::FloatAttr | 64-bit float attribute
`poolingMode` | vpux::IE::ROIAlignMethodAttr | ROIAlignMethod that the InferenceEngine supports

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`coords` | memref of 16-bit float or 32-bit float values
`roisIdx` | memref of integer values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.ROIPooling` (vpux::IERT::ROIPoolingOp)

InferenceEngine run-time ROIPooling layer


Syntax:

```
operation ::= `IERT.ROIPooling` attr-dict
              `inputs` `(` $input `:` type($input) `,` $coords `:` type($coords) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`output_size` | ::mlir::ArrayAttr | 64-bit integer array attribute
`spatial_scale` | ::mlir::FloatAttr | 64-bit float attribute
`method` | vpux::IE::ROIPoolingMethodAttr | ROIPoolingMethod that the InferenceEngine supports

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`coords` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.ReLU` (vpux::IERT::ReLUOp)

InferenceEngine run-time ReLU layer


Syntax:

```
operation ::= `IERT.ReLU` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.ReduceMax` (vpux::IERT::ReduceMaxOp)

InferenceEngine run-time reduceMax layer


Syntax:

```
operation ::= `IERT.ReduceMax` attr-dict
              `inputs` `(` $input `:` type($input) `,` $axes `:` type($axes) `)`
              `ouputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`keep_dims` | ::mlir::UnitAttr | unit attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of any type values
`axes` | memref of 64-bit signed integer or 32-bit signed integer values
`output_buff` | memref of any type values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of any type values

### `IERT.ReduceMean` (vpux::IERT::ReduceMeanOp)

InferenceEngine run-time ReduceMean layer


Syntax:

```
operation ::= `IERT.ReduceMean` attr-dict
              `inputs` `(` $input `:` type($input) `,` $axes `:` type($axes) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`keep_dims` | ::mlir::UnitAttr | unit attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of any type values
`axes` | memref of 32-bit signed integer or 64-bit signed integer values
`output_buff` | memref of any type values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of any type values

### `IERT.ReduceSum` (vpux::IERT::ReduceSumOp)

InferenceEngine run-time ReduceSum layer


Syntax:

```
operation ::= `IERT.ReduceSum` attr-dict
              `inputs` `(` $input `:` type($input) `,` $axes `:` type($axes) `)`
              `ouputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`keep_dims` | ::mlir::UnitAttr | unit attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of any type values
`axes` | memref of 64-bit signed integer or 32-bit signed integer values
`output_buff` | memref of any type values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of any type values

### `IERT.RegionYolo` (vpux::IERT::RegionYoloOp)

InferenceEngine run-time RegionYolo layer


Syntax:

```
operation ::= `IERT.RegionYolo` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`coords` | mlir::IntegerAttr | Integer attribute
`classes` | mlir::IntegerAttr | Integer attribute
`regions` | mlir::IntegerAttr | Integer attribute
`do_softmax` | ::mlir::BoolAttr | bool attribute
`mask` | ::mlir::ArrayAttr | 64-bit integer array attribute
`axis` | mlir::IntegerAttr | Integer attribute
`end_axis` | mlir::IntegerAttr | Integer attribute
`anchors` | ::mlir::ArrayAttr | 64-bit float array attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.ReverseSequence` (vpux::IERT::ReverseSequenceOp)

InferenceEngine Run-Time ReverseSequence layer


Syntax:

```
operation ::= `IERT.ReverseSequence` attr-dict
              `inputs` `(` $data `:` type($data) `,` $seq_length `:` type($seq_length) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`seq_axis` | mlir::IntegerAttr | Integer attribute
`batch_axis` | mlir::IntegerAttr | Integer attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`data` | memref of 16-bit float values
`seq_length` | memref of 16-bit float values
`output_buff` | memref of 16-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float values

### `IERT.Round` (vpux::IERT::RoundOp)

InferenceEngine run-time Round layer


Syntax:

```
operation ::= `IERT.Round` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`mode` | vpux::IE::RoundModeAttr | RoundMode that the InferenceEngine supports

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.ScaleShift` (vpux::IERT::ScaleShiftOp)

InferenceEngine run-time ScaleShift layer


Syntax:

```
operation ::= `IERT.ScaleShift` attr-dict
              `inputs` `(` $input `:` type($input) (`,` $weights^ `:` type($weights))? (`,` $biases^ `:` type($biases))? `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`weights` | memref of 16-bit float or 32-bit float values
`biases` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.ScatterNDUpdate` (vpux::IERT::ScatterNDUpdateOp)

InferenceEngine run-time ScatterNDUpdate layer


Syntax:

```
operation ::= `IERT.ScatterNDUpdate` attr-dict
              `inputs` `(` $input `:` type($input) `,` $indices `:` type($indices) `,` $updates `:` type($updates) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of any type values
`indices` | memref of 64-bit signed integer or 32-bit signed integer values
`updates` | memref of any type values
`output_buff` | memref of any type values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of any type values

### `IERT.Sigmoid` (vpux::IERT::SigmoidOp)

InferenceEngine run-time Sigmoid layer


Syntax:

```
operation ::= `IERT.Sigmoid` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Sign` (vpux::IERT::SignOp)

InferenceEngine run-time Sign layer


Syntax:

```
operation ::= `IERT.Sign` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Sinh` (vpux::IERT::SinhOp)

InferenceEngine run-time Sinh layer


Syntax:

```
operation ::= `IERT.Sinh` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.SoftMax` (vpux::IERT::SoftMaxOp)

InferenceEngine run-time SoftMax layer


Syntax:

```
operation ::= `IERT.SoftMax` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`axisInd` | mlir::IntegerAttr | Integer attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.SoftPlus` (vpux::IERT::SoftPlusOp)

InferenceEngine run-time SoftPlus layer


Syntax:

```
operation ::= `IERT.SoftPlus` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.SpaceToDepth` (vpux::IERT::SpaceToDepthOp)

InferenceEngine Run-Time SpaceToDepth layer


Syntax:

```
operation ::= `IERT.SpaceToDepth` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`block_size` | mlir::IntegerAttr | Integer attribute
`mode` | vpux::IE::SpaceToDepthModeAttr | SpaceToDepthMode that the InferenceEngine supports

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float values
`output_buff` | memref of 16-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float values

### `IERT.Sqrt` (vpux::IERT::SqrtOp)

InferenceEngine run-time Sqrt layer


Syntax:

```
operation ::= `IERT.Sqrt` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.SquaredDifference` (vpux::IERT::SquaredDifferenceOp)

InferenceEngine run-time SquaredDifference layer


Syntax:

```
operation ::= `IERT.SquaredDifference` attr-dict
              `inputs` `(` $input1 `:` type($input1) `,` $input2 `:` type($input2) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input1` | memref of 16-bit float or 32-bit float values
`input2` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.StaticAlloc` (vpux::IERT::StaticAllocOp)

InferenceEngine run-time static buffer allocation


Syntax:

```
operation ::= `IERT.StaticAlloc` `<` $offset `>` attr-dict `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`offset` | mlir::IntegerAttr | Integer attribute

#### Results:

| Result | Description |
| :----: | ----------- |
`memory` | memref of any type values

### `IERT.StridedSlice` (vpux::IERT::StridedSliceOp)

InferenceEngine run-time StridedSlice layer


Syntax:

```
operation ::= `IERT.StridedSlice` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`begins` | ::mlir::ArrayAttr | 64-bit integer array attribute
`ends` | ::mlir::ArrayAttr | 64-bit integer array attribute
`strides` | ::mlir::ArrayAttr | 64-bit integer array attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of any type values
`output_buff` | memref of any type values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of any type values

### `IERT.SubView` (vpux::IERT::SubViewOp)

Extract single subview from buffer


Syntax:

```
operation ::= `IERT.SubView` $source $static_offsets $static_sizes ($static_strides^)?
              attr-dict `:` type($source) `to` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`static_offsets` | ::mlir::ArrayAttr | 64-bit integer array attribute
`static_sizes` | ::mlir::ArrayAttr | 64-bit integer array attribute
`static_strides` | ::mlir::ArrayAttr | 64-bit integer array attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`source` | memref of any type values

#### Results:

| Result | Description |
| :----: | ----------- |
`result` | memref of any type values

### `IERT.Subtract` (vpux::IERT::SubtractOp)

InferenceEngine run-time Subtract layer


Syntax:

```
operation ::= `IERT.Subtract` attr-dict
              `inputs` `(` $input1 `:` type($input1) `,` $input2 `:` type($input2) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`post_op` | vpux::IE::PostOp | DictionaryAttr with field(s): 'name', 'attrs' (each field having its own constraints)

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input1` | memref of 16-bit float or 32-bit float values
`input2` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Swish` (vpux::IERT::SwishOp)

InferenceEngine run-time Swish layer


Syntax:

```
operation ::= `IERT.Swish` attr-dict
              `inputs` `(` $input `:` type($input) (`,` $beta^ `:` type($beta))? `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`beta_value` | ::mlir::FloatAttr | 64-bit float attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`beta` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Tanh` (vpux::IERT::TanhOp)

InferenceEngine run-time Tanh layer


Syntax:

```
operation ::= `IERT.Tanh` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Tile` (vpux::IERT::TileOp)

InferenceEngine run-time Tile layer


Syntax:

```
operation ::= `IERT.Tile` attr-dict
              `inputs` `(` $input `:` type($input) `,` $repeats `:` type($repeats) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`repeats` | memref of 64-bit signed integer values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Timestamp` (vpux::IERT::TimestampOp)

Get timer timestamp operation


Syntax:

```
operation ::= `IERT.Timestamp` attr-dict
              `(` $output_buff `:` type($output_buff) `)`
              `->` type($output)
```

Get timer timestamp operation

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`output_buff` | memref of 32-bit unsigned integer or 64-bit unsigned integer values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 32-bit unsigned integer or 64-bit unsigned integer values

### `IERT.TopK` (vpux::IERT::TopKOp)

InferenceEngine run-time TopK layer


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`axis` | mlir::IntegerAttr | Integer attribute
`mode` | vpux::IE::TopKModeAttr | TopKMode that the InferenceEngine supports
`sort` | vpux::IE::TopKSortTypeAttr | TopKSortType that the InferenceEngine supports
`element_type` | ::mlir::TypeAttr | any type attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float values
`k` | memref of 32-bit signed integer values
`output_values_buff` | memref of 16-bit float values
`target_shape_buff` | memref of 32-bit signed integer values

#### Results:

| Result | Description |
| :----: | ----------- |
`output_values` | memref of 16-bit float values
`target_shape` | memref of 32-bit signed integer values

### `IERT.Upsampling` (vpux::IERT::UpsamplingOp)

InferenceEngine run-time Upsampling layer


Syntax:

```
operation ::= `IERT.Upsampling` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`upsampling_factor` | ::mlir::ArrayAttr | 64-bit integer array attribute
`pad_l` | ::mlir::ArrayAttr | 64-bit integer array attribute
`pad_r` | ::mlir::ArrayAttr | 64-bit integer array attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.YuvToRgb` (vpux::IERT::YuvToRgbOp)

InferenceEngine run-time YUV-to-RGB layer


Syntax:

```
operation ::= `IERT.YuvToRgb` attr-dict
              `inputs` `(` $input1 `:` type($input1) (`,` $input2^ `:` type($input2))? (`,` $input3^ `:` type($input3))? `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`inFmt` | vpux::IE::ColorFmtAttr | YUV, RGB color formats
`outFmt` | vpux::IE::ColorFmtAttr | YUV, RGB color formats

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input1` | memref of 8-bit signless integer or 16-bit float or 32-bit float values
`input2` | memref of 8-bit signless integer or 16-bit float or 32-bit float values
`input3` | memref of 8-bit signless integer or 16-bit float or 32-bit float values
`output_buff` | memref of 8-bit signless integer or 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 8-bit signless integer or 16-bit float or 32-bit float values

### `IERT.ExtractImagePatches` (vpux::IERT::ExtractImagePatchesOp)

InferenceEngine run-time ExtractImagePatches layer


Syntax:

```
operation ::= `IERT.ExtractImagePatches` attr-dict
              `inputs` `(` $data `:` type($data) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`sizes` | ::mlir::ArrayAttr | 64-bit integer array attribute
`strides` | ::mlir::ArrayAttr | 64-bit integer array attribute
`rates` | ::mlir::ArrayAttr | 64-bit integer array attribute
`paddingType` | vpux::IE::ExtractImagePatchesAutoPadTypeAttr | ExtractImagePatchesAutoPadType that the InferenceEngine supports

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`data` | memref of 4D tensor of any type values
`output_buff` | memref of 4D tensor of any type values 

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 4D tensor of any type values 

