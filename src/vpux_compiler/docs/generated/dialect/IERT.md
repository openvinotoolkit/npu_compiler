<!-- Autogenerated by mlir-tblgen; don't manually edit -->
# 'IERT' Dialect

InferenceEngine RunTime Dialect
The **IERT Dialect** represents bufferized version of **IE Dialect**.

It has the following properties:

* Works with fixed operation set (like **IE Dialect**).
* Represents execution scheduling and memory allocation.
* Works with `MemRefType`.
* Includes transformations and optimizations closer to HW level (memory re-usage, parallel resources usage, etc.).

**TBD:** It operates with `MemRefType`, but in contrast to MLIR uses SSA value semantic (inspired by PlaidML approach).
It combines both memory effects and buffer aliasing for this:

* Each layer operation takes as its operands both input and output buffers.
* The layer marks input buffer as read-only and output buffer as write-only via memory effects inferface.
* The layer returns new buffer Value, which is an alias for output buffer.

```MLIR
#NHWC = affine_map<(n, c, h, w) -> (n, h, w, c)>

func @main(%input: memref<1x3x240x240xf16, #NHWC>, %output: memref<1x3x240x240xf16, #NHWC>) -> memref<1x3x240x240xf16, #NHWC> {
    %1 = IERT.SoftMax(%input, %output) {axisInd = 1 : i32} // %1 is an alias for %output
    return %1
}
```

The memory allocation/deallocation is defined as separate operations (dynamic or static).

The **IERT Dialect** uses the following scheme to represent scheduling information:

* Operations order defines scheduling.
* Each IERT operation is assumed as blocking: next operation will not start until previous is finished.
* Concurrent execution is defined as asynchronous regions (**Async Dialect**).

```MLIR
%11_t, %11_f = async.execute { IERT.executor = "NCE_Cluster" }
    [%7_t, %8_9_t](%8_9_f#0 as %8, %8_9_f#1 as %9)
{
    %11_0_t, %11_0_f = async.execute { IERT.executor = "DPU" }
    {
        %11_0 = IERT.Convolution(%7, %8, %9) to %10_0 { strides = [1, 1], pads_begin = [1, 1], pads_end = [1, 1] }
        async.yield %11_0
    }

    %11_1_t, %11_1_f = async.execute { IERT.executor = "DPU" }
    {
        %11_1 = IERT.Convolution(%7, %8, %9) to %10_1 { strides = [1, 1], pads_begin = [1, 1], pads_end = [1, 1] }
        async.yield %11_1
    }

    %11:2 = async.await %11_0_f, %11_1_f
    %11 = IERT.FakeConcat(%11#0, %11#1) to %10
    async.yield %11
}
```

The **IERT Dialect** provides separate Operation to describe the available and used run-time resources.
It deals with the following resource types:

* Memory space.
* Executor (CPU, HW module, DMA).

```MLIR
IERT.RunTimeResources
    availableMemory : {
        IERT.MemoryResource 1073741824 bytes
        IERT.MemoryResource 31457280 bytes of "DDR" {VPUIP.bandwidth = 8 : i64, VPUIP.derateFactor = 6.000000e-01 : f64}
        IERT.MemoryResource 4194304 bytes of "CMX_UPA" {VPUIP.bandwidth = 16 : i64, VPUIP.derateFactor = 8.500000e-01 : f64}
        IERT.MemoryResource 1048576 bytes of "CMX_NN" {VPUIP.bandwidth = 32 : i64, VPUIP.derateFactor = 1.000000e+00 : f64}
    }
    usedMemory : {
        IERT.MemoryResource 2048 bytes of "DDR"
        IERT.MemoryResource 1048576 bytes of "CMX_NN"
    }
    executors : {
        IERT.ExecutorResource 1 of "Leon_RT"
        IERT.ExecutorResource 1 of "Leon_NN"
        IERT.ExecutorResource 16 of "SHAVE_UPA"
        IERT.ExecutorResource 20 of "SHAVE_NN"
        IERT.ExecutorResource 4 of "NCE_Cluster" {
            IERT.ExecutorResource 5 of "NCE_PerClusterDPU"
        }
        IERT.ExecutorResource 1 of "DMA_UPA"
        IERT.ExecutorResource 1 of "DMA_NN"
    }
```

The `IERT.RunTimeResources` is filled by underlying low-level dialect to provide information about HW-specific resources.

[TOC]

## Operation definition

### `IERT.Add` (vpux::IERT::AddOp)

InferenceEngine run-time Add layer


Syntax:

```
operation ::= `IERT.Add` attr-dict
              `inputs` `(` $input1 `:` type($input1) `,` $input2 `:` type($input2) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input1` | memref of 16-bit float or 32-bit float values
`input2` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.AvgPool` (vpux::IERT::AvgPoolOp)

InferenceEngine run-time AvgPool layer


Syntax:

```
operation ::= `IERT.AvgPool` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`kernel_size` | ::mlir::ArrayAttr | 32-bit integer array attribute
`strides` | ::mlir::ArrayAttr | 32-bit integer array attribute
`pads_begin` | ::mlir::ArrayAttr | 32-bit integer array attribute
`pads_end` | ::mlir::ArrayAttr | 32-bit integer array attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.CTCGreedyDecoder` (vpux::IERT::CTCGreedyDecoderOp)

InferenceEngine run-time CTCGreedyDecoder layer


Syntax:

```
operation ::= `IERT.CTCGreedyDecoder` attr-dict
              `inputs` `(` $input `:` type($input) `,` $sequenceLengths `:` type($sequenceLengths) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`mergeRepeated` | ::mlir::UnitAttr | unit attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`sequenceLengths` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.CTCGreedyDecoderSeqLen` (vpux::IERT::CTCGreedyDecoderSeqLenOp)

InferenceEngine run-time CTCGreedyDecoderSeqLen layer


Syntax:

```
operation ::= `IERT.CTCGreedyDecoderSeqLen` attr-dict
              `inputs` `(` $input `:` type($input) `,` $sequenceLength `:` type($sequenceLength) (`,` $blankIndex^ `:` type($blankIndex))? `)`
              `outputs` `(` $output_buff `:` type($output_buff) `,` $outputLength_buff `:` type($outputLength_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`mergeRepeated` | ::mlir::UnitAttr | unit attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`sequenceLength` | memref of 32-bit signed integer values
`blankIndex` | memref of 32-bit signed integer values
`output_buff` | memref of 32-bit signed integer values
`outputLength_buff` | memref of 32-bit signed integer values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 32-bit signed integer values
`outputLength` | memref of 32-bit signed integer values

### `IERT.Clamp` (vpux::IERT::ClampOp)

InferenceEngine run-time Clamp layer


Syntax:

```
operation ::= `IERT.Clamp` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`min` | ::mlir::FloatAttr | 32-bit float attribute
`max` | ::mlir::FloatAttr | 32-bit float attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.ConcatView` (vpux::IERT::ConcatViewOp)

InferenceEngine run-time ConcatView layer. Dummy operation to maintain use-def chains.


Syntax:

```
operation ::= `IERT.ConcatView` attr-dict
              `inputs` `(` $inputs `:` type($inputs) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`inputs` | memref of any type values
`output_buff` | memref of any type values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of any type values

### `IERT.Convert` (vpux::IERT::ConvertOp)

InferenceEngine run-time Convert layer


Syntax:

```
operation ::= `IERT.Convert` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of any type values
`output_buff` | memref of any type values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of any type values

### `IERT.Convolution` (vpux::IERT::ConvolutionOp)

InferenceEngine run-time Convolution layer


Syntax:

```
operation ::= `IERT.Convolution` attr-dict
              `inputs` `(` $input `:` type($input) `,` $filter `:` type($filter) (`,` $bias^ `:` type($bias))? `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`strides` | ::mlir::ArrayAttr | 32-bit integer array attribute
`pads_begin` | ::mlir::ArrayAttr | 32-bit integer array attribute
`pads_end` | ::mlir::ArrayAttr | 32-bit integer array attribute
`dilations` | ::mlir::ArrayAttr | 32-bit integer array attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`filter` | memref of 16-bit float or 32-bit float values
`bias` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Copy` (vpux::IERT::CopyOp)

InferenceEngine run-time Copy layer


Syntax:

```
operation ::= `IERT.Copy` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of any type values
`output_buff` | memref of any type values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of any type values

### `IERT.Dequantize` (vpux::IERT::DequantizeOp)

InferenceEngine run-time Dequantize layer


Syntax:

```
operation ::= `IERT.Dequantize` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of QuantizedType values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.DetectionOutput` (vpux::IERT::DetectionOutputOp)

InferenceEngine run-time DetectionOutput layer


Syntax:

```
operation ::= `IERT.DetectionOutput` attr-dict
              `inputs` `(` $in_box_logits `:` type($in_box_logits) `,` $in_class_preds `:` type($in_class_preds) `,` $in_proposals `:` type($in_proposals) (`,` $in_additional_preds^ `:` type($in_additional_preds))? (`,` $in_additional_proposals^ `:` type($in_additional_proposals))? `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`attr` | vpux::IE::DetectionOutputAttr | DictionaryAttr with field(s): 'num_classes', 'background_label_id', 'top_k', 'variance_encoded_in_target', 'keep_top_k', 'code_type', 'share_location', 'nms_threshold', 'confidence_threshold', 'clip_after_nms', 'clip_before_nms', 'decrease_label_id', 'normalized', 'input_height', 'input_width', 'objectness_score' (each field having its own constraints)

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`in_box_logits` | memref of floating-point values
`in_class_preds` | memref of floating-point values
`in_proposals` | memref of floating-point values
`in_additional_preds` | memref of floating-point values
`in_additional_proposals` | memref of floating-point values
`output_buff` | memref of floating-point values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of floating-point values

### `IERT.Divide` (vpux::IERT::DivideOp)

InferenceEngine run-time Divide layer


Syntax:

```
operation ::= `IERT.Divide` attr-dict
              `inputs` `(` $input1 `:` type($input1) `,` $input2 `:` type($input2) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input1` | memref of 16-bit float or 32-bit float values
`input2` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Elu` (vpux::IERT::EluOp)

InferenceEngine run-time Elu layer


Syntax:

```
operation ::= `IERT.Elu` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`x` | ::mlir::FloatAttr | 32-bit float attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.ExecutorResource` (vpux::IERT::ExecutorResourceOp)

Information about executor resource


Syntax:

```
operation ::= `IERT.ExecutorResource` attr-dict
              $count `of` $kind
              $subExecutors
```

The executor resource is defined by the following attributes:

  * Kind - optional kind of the executor.
  * Count - number of executor units.

#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`kind` | ::mlir::Attribute | any attribute
`count` | ::mlir::IntegerAttr | 32-bit signless integer attribute

### `IERT.Exp` (vpux::IERT::ExpOp)

InferenceEngine run-time Exp layer


Syntax:

```
operation ::= `IERT.Exp` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.FakeQuantize` (vpux::IERT::FakeQuantizeOp)

InferenceEngine FakeQuantize layer


Syntax:

```
operation ::= `IERT.FakeQuantize` attr-dict
              `inputs` `(` $input `:` type($input) `,` $input_low `:` type($input_low) `,` $input_high `:` type($input_high) `,` $output_low `:` type($output_low) `,` $output_high `:` type($output_high) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`levels` | ::mlir::IntegerAttr | 32-bit signless integer attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`input_low` | memref of 16-bit float or 32-bit float values
`input_high` | memref of 16-bit float or 32-bit float values
`output_low` | memref of 16-bit float or 32-bit float values
`output_high` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.FloorMod` (vpux::IERT::FloorModOp)

InferenceEngine run-time FloorMod layer


Syntax:

```
operation ::= `IERT.FloorMod` attr-dict
              `inputs` `(` $input1 `:` type($input1) `,` $input2 `:` type($input2) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input1` | memref of 16-bit float or 32-bit float values
`input2` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.FullyConnected` (vpux::IERT::FullyConnectedOp)

InferenceEngine run-time FullyConnected layer


Syntax:

```
operation ::= `IERT.FullyConnected` attr-dict
              `inputs` `(` $input `:` type($input) `,` $weights `:` type($weights) (`,` $bias^ `:` type($bias))? `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`weights` | memref of 16-bit float or 32-bit float values
`bias` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.GRN` (vpux::IERT::GRNOp)

InferenceEngine run-time GRN layer


Syntax:

```
operation ::= `IERT.GRN` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`bias` | ::mlir::FloatAttr | 32-bit float attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.GenericReshape` (vpux::IERT::GenericReshapeOp)

InferenceEngine run-time generic Reshape layer


Syntax:

```
operation ::= `IERT.GenericReshape` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | strided memref of any type values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | strided memref of any type values

### `IERT.GroupConvolution` (vpux::IERT::GroupConvolutionOp)

InferenceEngine run-time GroupConvolution layer


Syntax:

```
operation ::= `IERT.GroupConvolution` attr-dict
              `inputs` `(` $input `:` type($input) `,` $filter `:` type($filter) (`,` $bias^ `:` type($bias))? `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`strides` | ::mlir::ArrayAttr | 32-bit integer array attribute
`pads_begin` | ::mlir::ArrayAttr | 32-bit integer array attribute
`pads_end` | ::mlir::ArrayAttr | 32-bit integer array attribute
`dilations` | ::mlir::ArrayAttr | 32-bit integer array attribute
`groups` | ::mlir::IntegerAttr | 32-bit signless integer attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`filter` | memref of 16-bit float or 32-bit float values
`bias` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.HSwish` (vpux::IERT::HSwishOp)

InferenceEngine run-time HSwish layer


Syntax:

```
operation ::= `IERT.HSwish` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Interpolate` (vpux::IERT::InterpolateOp)

InferenceEngine run-time Interpolate layer


Syntax:

```
operation ::= `IERT.Interpolate` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`mode` | vpux::IE::InterpolateModeAttr | Specifies type of interpolation
`coord_mode` | vpux::IE::InterpolateCoordModeAttr | coordinate_transformation_mode specifies how to transform the coordinate.
`nearest_mode` | vpux::IE::InterpolateNearestModeAttr | specifies round mode when mode == nearest
`antialias` | ::mlir::UnitAttr | unit attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.LeakyRelu` (vpux::IERT::LeakyReluOp)

InferenceEngine run-time LeakyRelu layer


Syntax:

```
operation ::= `IERT.LeakyRelu` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`negative_slope` | ::mlir::FloatAttr | 32-bit float attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.MaxPool` (vpux::IERT::MaxPoolOp)

InferenceEngine run-time MaxPool layer


Syntax:

```
operation ::= `IERT.MaxPool` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`kernel_size` | ::mlir::ArrayAttr | 32-bit integer array attribute
`strides` | ::mlir::ArrayAttr | 32-bit integer array attribute
`pads_begin` | ::mlir::ArrayAttr | 32-bit integer array attribute
`pads_end` | ::mlir::ArrayAttr | 32-bit integer array attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Maximum` (vpux::IERT::MaximumOp)

InferenceEngine run-time Maximum layer


Syntax:

```
operation ::= `IERT.Maximum` attr-dict
              `inputs` `(` $input1 `:` type($input1) `,` $input2 `:` type($input2) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input1` | memref of 16-bit float or 32-bit float values
`input2` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.MemoryResource` (vpux::IERT::MemoryResourceOp)

Information about memory resource


Syntax:

```
operation ::= `IERT.MemoryResource` $byteSize `bytes` (`of` $kind^)?
              attr-dict
```

The memory resource is defined by the following attributes:

  * Kind - optional kind of memory space.
  * Size - size in bytes of memory space.

#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`kind` | ::mlir::Attribute | any attribute
`byteSize` | ::mlir::IntegerAttr | 64-bit signless integer attribute

### `IERT.Minimum` (vpux::IERT::MinimumOp)

InferenceEngine run-time Minimum layer


Syntax:

```
operation ::= `IERT.Minimum` attr-dict
              `inputs` `(` $input1 `:` type($input1) `,` $input2 `:` type($input2) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input1` | memref of 16-bit float or 32-bit float values
`input2` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Multiply` (vpux::IERT::MultiplyOp)

InferenceEngine run-time Multiply layer


Syntax:

```
operation ::= `IERT.Multiply` attr-dict
              `inputs` `(` $input1 `:` type($input1) `,` $input2 `:` type($input2) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input1` | memref of 16-bit float or 32-bit float values
`input2` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Negative` (vpux::IERT::NegativeOp)

InferenceEngine run-time Negative layer


Syntax:

```
operation ::= `IERT.Negative` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.PRelu` (vpux::IERT::PReluOp)

InferenceEngine run-time PRelu layer


Syntax:

```
operation ::= `IERT.PRelu` attr-dict
              `inputs` `(` $input `:` type($input) `,` $negative_slope `:` type($negative_slope) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`negative_slope` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Pad` (vpux::IERT::PadOp)

InferenceEngine run-time Pad layer


Syntax:

```
operation ::= `IERT.Pad` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`pads_begin` | ::mlir::ArrayAttr | 32-bit integer array attribute
`pads_end` | ::mlir::ArrayAttr | 32-bit integer array attribute
`pad_value` | ::mlir::FloatAttr | 32-bit float attribute
`mode` | vpux::IE::PadModeAttr | TPadMode that the InferenceEngine supports

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.PerAxisTile` (vpux::IERT::PerAxisTileOp)

InferenceEngine run-time per axis Tile layer


Syntax:

```
operation ::= `IERT.PerAxisTile` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`axis` | ::mlir::IntegerAttr | 32-bit signless integer attribute
`tiles` | ::mlir::IntegerAttr | 32-bit signless integer attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Power` (vpux::IERT::PowerOp)

InferenceEngine run-time Power layer


Syntax:

```
operation ::= `IERT.Power` attr-dict
              `inputs` `(` $input1 `:` type($input1) `,` $input2 `:` type($input2) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input1` | memref of 16-bit float or 32-bit float values
`input2` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Quantize` (vpux::IERT::QuantizeOp)

InferenceEngine run-time Quantize layer


Syntax:

```
operation ::= `IERT.Quantize` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of QuantizedType values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of QuantizedType values

### `IERT.ROIPooling` (vpux::IERT::ROIPoolingOp)

InferenceEngine run-time ROIPooling layer


Syntax:

```
operation ::= `IERT.ROIPooling` attr-dict
              `inputs` `(` $input `:` type($input) `,` $coords `:` type($coords) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`output_size` | ::mlir::ArrayAttr | 32-bit integer array attribute
`spatial_scale` | ::mlir::FloatAttr | 32-bit float attribute
`method` | vpux::IE::ROIPoolingMethodAttr | ROIPoolingMethod that the InferenceEngine supports

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`coords` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.ReLU` (vpux::IERT::ReLUOp)

InferenceEngine run-time ReLU layer


Syntax:

```
operation ::= `IERT.ReLU` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Reorder` (vpux::IERT::ReorderOp)

InferenceEngine run-time Reorder layer


Syntax:

```
operation ::= `IERT.Reorder` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of any type values
`output_buff` | memref of any type values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of any type values

### `IERT.RunTimeResources` (vpux::IERT::RunTimeResourcesOp)

Definition of run-time resources


Syntax:

```
operation ::= `IERT.RunTimeResources` attr-dict
              `availableMemory` `:` $availableMemory
              `usedMemory` `:` $usedMemory
              `executors` `:` $executors
```

This operation defines various resources consumed at run-time:

  * Available memory spaces for interal buffers.
  * Used memory spaces for interal buffers.
  * Executors for asynchronous calls.

### `IERT.ScaleShift` (vpux::IERT::ScaleShiftOp)

InferenceEngine run-time ScaleShift layer


Syntax:

```
operation ::= `IERT.ScaleShift` attr-dict
              `inputs` `(` $input `:` type($input) (`,` $weights^ `:` type($weights))? (`,` $biases^ `:` type($biases))? `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`weights` | memref of 16-bit float or 32-bit float values
`biases` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Sigmoid` (vpux::IERT::SigmoidOp)

InferenceEngine run-time Sigmoid layer


Syntax:

```
operation ::= `IERT.Sigmoid` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.SoftMax` (vpux::IERT::SoftMaxOp)

InferenceEngine run-time SoftMax layer


Syntax:

```
operation ::= `IERT.SoftMax` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`axisInd` | ::mlir::IntegerAttr | 32-bit signless integer attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.SquaredDifference` (vpux::IERT::SquaredDifferenceOp)

InferenceEngine run-time SquaredDifference layer


Syntax:

```
operation ::= `IERT.SquaredDifference` attr-dict
              `inputs` `(` $input1 `:` type($input1) `,` $input2 `:` type($input2) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input1` | memref of 16-bit float or 32-bit float values
`input2` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.StaticAlloc` (vpux::IERT::StaticAllocOp)

InferenceEngine run-time static buffer allocation


Syntax:

```
operation ::= `IERT.StaticAlloc` `<` $offset `>` attr-dict `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`offset` | ::mlir::IntegerAttr | 64-bit signless integer attribute

#### Results:

| Result | Description |
| :----: | ----------- |
`memory` | memref of any type values

### `IERT.StridedSlice` (vpux::IERT::StridedSliceOp)

InferenceEngine run-time StridedSlice layer


Syntax:

```
operation ::= `IERT.StridedSlice` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`begins` | ::mlir::ArrayAttr | 64-bit integer array attribute
`ends` | ::mlir::ArrayAttr | 64-bit integer array attribute
`strides` | ::mlir::ArrayAttr | 64-bit integer array attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of any type values
`output_buff` | memref of any type values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of any type values

### `IERT.Swish` (vpux::IERT::SwishOp)

InferenceEngine run-time Swish layer


Syntax:

```
operation ::= `IERT.Swish` attr-dict
              `inputs` `(` $input `:` type($input) (`,` $beta^ `:` type($beta))? `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`beta_value` | ::mlir::FloatAttr | 32-bit float attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`beta` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Tanh` (vpux::IERT::TanhOp)

InferenceEngine run-time Tanh layer


Syntax:

```
operation ::= `IERT.Tanh` attr-dict
              `inputs` `(` $input `:` type($input) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Tile` (vpux::IERT::TileOp)

InferenceEngine run-time Tile layer


Syntax:

```
operation ::= `IERT.Tile` attr-dict
              `inputs` `(` $input `:` type($input) `,` $repeats `:` type($repeats) `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`repeats` | memref of 64-bit signed integer values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

### `IERT.Transpose` (vpux::IERT::TransposeOp)

InferenceEngine run-time Transpose layer


Syntax:

```
operation ::= `IERT.Transpose` attr-dict
              `inputs` `(` $input `:` type($input) (`,` $order^ `:` type($order))? `)`
              `outputs` `(` $output_buff `:` type($output_buff) `)`
              `->` type(results)
```


#### Attributes:

| Attribute | MLIR Type | Description |
| :-------: | :-------: | ----------- |
`order_value` | ::mlir::AffineMapAttr | AffineMap attribute

#### Operands:

| Operand | Description |
| :-----: | ----------- |
`input` | memref of 16-bit float or 32-bit float values
`order` | memref of 64-bit signed integer values
`output_buff` | memref of 16-bit float or 32-bit float values

#### Results:

| Result | Description |
| :----: | ----------- |
`output` | memref of 16-bit float or 32-bit float values

