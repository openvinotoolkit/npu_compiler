//
// Copyright Intel Corporation.
//
// LEGAL NOTICE: Your use of this software and any required dependent software
// (the "Software Package") is subject to the terms and conditions of
// the Intel(R) OpenVINO(TM) Distribution License for the Software Package,
// which may also include notices, disclaimers, or license terms for
// third party or open source software included in or with the Software Package,
// and your use indicates your acceptance of all such terms. Please refer
// to the "third-party-programs.txt" or other similarly-named text file
// included with the Software Package for additional details.
//

#include "vpux/compiler/core/feasible_memory_scheduler_control_edges.hpp"

#include "vpux/compiler/utils/analysis.hpp"
#include "vpux/compiler/utils/rewriter.hpp"

#include "vpux/compiler/core/control_edge_generator.hpp"
#include "vpux/compiler/core/feasible_scheduler_utils.hpp"

#include <iostream>

using namespace vpux;

//
// Feasible Memory Scheduler Control Edges support
//

FeasibleMemorySchedulerControlEdges::FeasibleMemorySchedulerControlEdges(
        mlir::Attribute memSpace, AsyncDepsInfo& depsInfo, AliasesInfo& aliasInfo, Logger log,
        LinearScan<mlir::Value, LinearScanHandler>& scan)
        : _log(log), _memSpace(memSpace), _depsInfo(depsInfo), _aliasInfo(aliasInfo), _scan(scan) {
    _log.setName("feasible-memory-scheduler-control-edges");
}

// This method will update all AsyncExecOp token dependencies so that resulting
// execution is aligned with order generated by list-scheduler
void FeasibleMemorySchedulerControlEdges::insertDependenciesBasic(
        ArrayRef<FeasibleMemoryScheduler::ScheduledOpInfo> scheduledOps) {
    // Go through all the tasks and add token dependencies between
    // all tasks with start time t to all tasks with time t+1
    _log.trace("Get dependencies based on scheduler time decisions");
    _log = _log.nest();
    for (auto opIt = scheduledOps.begin(); opIt != scheduledOps.end(); opIt++) {
        if (!opIt->isOriginalOp()) {
            continue;
        }

        size_t nextTimeDiff = 0;
        for (auto nextTimeOpIt = opIt; nextTimeOpIt != scheduledOps.end(); nextTimeOpIt++) {
            if (!nextTimeOpIt->isOriginalOp()) {
                continue;
            } else if (nextTimeDiff == 0 && nextTimeOpIt->time_ > opIt->time_) {
                nextTimeDiff = nextTimeOpIt->time_ - opIt->time_;
            }

            if (nextTimeDiff != 0) {
                if (nextTimeOpIt->time_ == opIt->time_ + nextTimeDiff) {
                    // Insert dependency between op at time t to op at
                    // time t+1
                    auto srcAsyncOp = _depsInfo.getExecuteOpAtIndex(opIt->op_);
                    auto dstAsyncOp = _depsInfo.getExecuteOpAtIndex(nextTimeOpIt->op_);
                    _log.trace("Dep: {0} -> {1}", opIt->op_, nextTimeOpIt->op_);
                    VPUX_THROW_UNLESS((srcAsyncOp != nullptr) && (dstAsyncOp != nullptr),
                                      "srcAsyncOp/dstAsyncOp not located based on index");
                    _depsInfo.addDependency(srcAsyncOp, dstAsyncOp);
                } else if (nextTimeOpIt->time_ > (opIt->time_ + nextTimeDiff)) {
                    break;
                }
            }
        }
    }
    _log = _log.unnest();
}

// This method will update all AsyncExecOp token dependencies for a given executor type
// so that resulting execution is aligned with order generated by list-scheduler
void FeasibleMemorySchedulerControlEdges::insertScheduleOrderDepsForExecutor(
        ArrayRef<FeasibleMemoryScheduler::ScheduledOpInfo> scheduledOps, VPU::ExecutorKind executorKind) {
    // Go through all the tasks with given executor type
    _log.trace("Insert control edges aligned with schedule order for provided executor");

    auto isRightExecutor = [executorKind](mlir::async::ExecuteOp execOp) {
        if (!execOp->hasAttr(IERT::IERTDialect::getExecutorAttrName())) {
            return false;
        }

        const auto executor = IERT::IERTDialect::getExecutor(execOp);
        if (executor.getLeafNameAttr() != VPU::ExecutorKindAttr::get(execOp->getContext(), executorKind)) {
            return false;
        }
        return true;
    };

    _log = _log.nest();
    for (auto opIt = scheduledOps.begin(); opIt != scheduledOps.end(); opIt++) {
        if (!opIt->isOriginalOp()) {
            continue;
        }

        auto srcAsyncOp = _depsInfo.getExecuteOpAtIndex(opIt->op_);

        if (!isRightExecutor(srcAsyncOp)) {
            continue;
        }

        size_t nextTimeDiff = 0;
        for (auto nextTimeOpIt = opIt; nextTimeOpIt != scheduledOps.end(); nextTimeOpIt++) {
            if (!nextTimeOpIt->isOriginalOp()) {
                continue;
            }

            auto dstAsyncOp = _depsInfo.getExecuteOpAtIndex(nextTimeOpIt->op_);

            if (!isRightExecutor(dstAsyncOp)) {
                continue;
            }

            if (nextTimeDiff == 0 && nextTimeOpIt->time_ > opIt->time_) {
                nextTimeDiff = nextTimeOpIt->time_ - opIt->time_;
            }

            if (nextTimeDiff != 0) {
                if (nextTimeOpIt->time_ == opIt->time_ + nextTimeDiff) {
                    // Insert dependency between op at time t to op at
                    // time t+1
                    auto dstAsyncOp = _depsInfo.getExecuteOpAtIndex(nextTimeOpIt->op_);
                    _log.trace("Dep: {0} -> {1}", opIt->op_, nextTimeOpIt->op_);
                    VPUX_THROW_UNLESS((srcAsyncOp != nullptr) && (dstAsyncOp != nullptr),
                                      "srcAsyncOp/dstAsyncOp not located based on index");
                    _depsInfo.addDependency(srcAsyncOp, dstAsyncOp);
                } else if (nextTimeOpIt->time_ > (opIt->time_ + nextTimeDiff)) {
                    break;
                }
            }
        }
    }
    _log = _log.unnest();
}

// Insert control flow for overlapping memory regions
void FeasibleMemorySchedulerControlEdges::insertMemoryControlEdges(
        ArrayRef<FeasibleMemoryScheduler::ScheduledOpInfo> scheduledOps) {
    std::list<ScheduledOpOneResource> scheduledOpsResources;

    _log.trace("Insert control edges for overlapping memory resources");

    // Analyze output from feasible scheduler and prepare list of scheduled
    // operations with their resource and time as needed by control edge
    // generation algorithm
    for (auto& scheduledOp : scheduledOps) {
        VPUX_THROW_UNLESS(scheduledOp.isOriginalOp(), "Invalid operation identified for control edge insertion");

        // buffers used by operation, both inputs and outputs
        mlir::DenseSet<mlir::Value> inputBuffers;
        mlir::DenseSet<mlir::Value> outputBuffers;

        // Get operation buffers for all operands. Go through each layer op and
        // store in a set all root buffers
        auto execOp = _depsInfo.getExecuteOpAtIndex(scheduledOp.op_);
        auto* bodyBlock = &execOp.body().front();
        for (auto& innerOp : bodyBlock->getOperations()) {
            if (!mlir::isa<IERT::LayerOpInterface>(innerOp)) {
                continue;
            }

            auto inputs = mlir::dyn_cast<IERT::LayerOpInterface>(innerOp).getInputs();
            for (const auto& input : inputs) {
                const auto type = input.getType().dyn_cast<vpux::NDTypeInterface>();
                if (type == nullptr || type.getMemSpace() != _memSpace) {
                    continue;
                }
                auto rootBuffers = _aliasInfo.getRoots(input);
                VPUX_THROW_UNLESS(rootBuffers.size() == 1, "Value '{0}' expected to have only one root. Got {1}", input,
                                  rootBuffers.size());
                auto rootBuffer = *rootBuffers.begin();
                inputBuffers.insert(rootBuffer);
            }

            auto outputs = mlir::dyn_cast<IERT::LayerOpInterface>(innerOp).getOutputs();
            for (const auto& output : outputs) {
                const auto type = output.getType().dyn_cast<vpux::NDTypeInterface>();
                if (type == nullptr || type.getMemSpace() != _memSpace) {
                    continue;
                }
                auto rootBuffers = _aliasInfo.getRoots(output);
                VPUX_THROW_UNLESS(rootBuffers.size() == 1, "Value '{0}' expected to have only one root. Got {1}",
                                  output, rootBuffers.size());
                auto rootBuffer = *rootBuffers.begin();
                outputBuffers.insert(rootBuffer);
            }
        }

        // For all identified buffers used by operation create separate entries with information
        // about memory ranges to properly identify range producer and consumers at a given time
        for (auto& buf : inputBuffers) {
            if (!isBufAllocOp(buf.getDefiningOp())) {
                continue;
            }
            auto addressStart = _scan.handler().getAddress(buf);
            auto bufSize = _scan.handler().getSize(buf);
            if (bufSize == 0) {
                continue;
            }
            auto addressEnd = addressStart + bufSize - 1;
            _log.trace("op = '{0}'\t time = '{1}'\t input = [{2} - {3}]", scheduledOp.op_, scheduledOp.time_,
                       addressStart, addressEnd);
            scheduledOpsResources.push_back(ScheduledOpOneResource(scheduledOp.op_, addressStart, addressEnd,
                                                                   ScheduledOpOneResource::EResRelation::CONSUMER));
        }
        for (auto& buf : outputBuffers) {
            if (!isBufAllocOp(buf.getDefiningOp())) {
                continue;
            }
            auto addressStart = _scan.handler().getAddress(buf);
            auto bufSize = _scan.handler().getSize(buf);
            if (bufSize == 0) {
                continue;
            }
            auto addressEnd = addressStart + bufSize - 1;
            _log.trace("op = '{0}'\t time = '{1}'\t output = [{2} - {3}]", scheduledOp.op_, scheduledOp.time_,
                       addressStart, addressEnd);
            scheduledOpsResources.push_back(ScheduledOpOneResource(scheduledOp.op_, addressStart, addressEnd,
                                                                   ScheduledOpOneResource::EResRelation::PRODUCER));
        }
    }

    ControlEdgeSet controlEdges;
    ControlEdgeGenerator<ScheduledOpOneResource> controlEdgeGenerator;
    // Generate control edges for overlapping memory regions
    controlEdgeGenerator.generateControlEdges(scheduledOpsResources.begin(), scheduledOpsResources.end(), controlEdges);

    // Apply dependencies from controlEdges set in depsInfo and
    // later transfer this to token based dependencies between AsyncExecuteOp
    _log = _log.nest();
    for (auto itr = controlEdges.begin(); itr != controlEdges.end(); ++itr) {
        if (itr->_source == itr->_sink) {
            continue;
        }
        _log.trace("Dep: {0} -> {1}", itr->_source, itr->_sink);
        auto sourceOp = _depsInfo.getExecuteOpAtIndex(itr->_source);
        auto sinkOp = _depsInfo.getExecuteOpAtIndex(itr->_sink);
        _depsInfo.addDependency(sourceOp, sinkOp);
    }
    _log = _log.unnest();
}

// After all new dependencies have been prepared call this function to make actual changes in IR
void FeasibleMemorySchedulerControlEdges::updateDependenciesInIR() {
    _log.trace("Update token dependencies in IR");
    _depsInfo.updateTokenDependencies();
}
