// automatically generated by the FlatBuffers compiler, do not modify


#ifndef FLATBUFFERS_GENERATED_FILEHEADER_MVCNN_H_
#define FLATBUFFERS_GENERATED_FILEHEADER_MVCNN_H_

#include "flatbuffers/flatbuffers.h"

#include "device_generated.h"
#include "memoryManagement_generated.h"
#include "structure_generated.h"

namespace MVCNN {

struct Version;
struct VersionBuilder;
struct VersionT;

struct Resources;
struct ResourcesBuilder;
struct ResourcesT;

struct SummaryHeader;
struct SummaryHeaderBuilder;
struct SummaryHeaderT;

enum ExecutionFlag {
  ExecutionFlag_INVALID = 0,
  ExecutionFlag_DynamicBarriers = 1,
  ExecutionFlag_MIN = ExecutionFlag_INVALID,
  ExecutionFlag_MAX = ExecutionFlag_DynamicBarriers
};

inline const ExecutionFlag (&EnumValuesExecutionFlag())[2] {
  static const ExecutionFlag values[] = {
    ExecutionFlag_INVALID,
    ExecutionFlag_DynamicBarriers
  };
  return values;
}

inline const char * const *EnumNamesExecutionFlag() {
  static const char * const names[3] = {
    "INVALID",
    "DynamicBarriers",
    nullptr
  };
  return names;
}

inline const char *EnumNameExecutionFlag(ExecutionFlag e) {
  if (flatbuffers::IsOutRange(e, ExecutionFlag_INVALID, ExecutionFlag_DynamicBarriers)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesExecutionFlag()[index];
}

struct VersionT : public flatbuffers::NativeTable {
  typedef Version TableType;
  uint32_t majorV;
  uint32_t minorV;
  uint32_t patchV;
  std::string hash;
  std::string context;
  VersionT()
      : majorV(0),
        minorV(0),
        patchV(0) {
  }
};

struct Version FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef VersionT NativeTableType;
  typedef VersionBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_MAJORV = 4,
    VT_MINORV = 6,
    VT_PATCHV = 8,
    VT_HASH = 10,
    VT_CONTEXT = 12
  };
  /// Version of the schema that the graphfile was generated with.
  /// Major Version: Sigificant Architectural Change (This will probably require design documentation and such)
  /// Minor Verson: Regular Release of Graphfile Schema.
  /// Patch Version: Hot-Fixes and Patches if needed.
  uint32_t majorV() const {
    return GetField<uint32_t>(VT_MAJORV, 0);
  }
  uint32_t minorV() const {
    return GetField<uint32_t>(VT_MINORV, 0);
  }
  uint32_t patchV() const {
    return GetField<uint32_t>(VT_PATCHV, 0);
  }
  /// You can provide a string to pin-point the exact commit hash or tag a graphfile came from.
  /// This can be used for other types of labelling if desired.
  const flatbuffers::String *hash() const {
    return GetPointer<const flatbuffers::String *>(VT_HASH);
  }
  const flatbuffers::String *context() const {
    return GetPointer<const flatbuffers::String *>(VT_CONTEXT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint32_t>(verifier, VT_MAJORV) &&
           VerifyField<uint32_t>(verifier, VT_MINORV) &&
           VerifyField<uint32_t>(verifier, VT_PATCHV) &&
           VerifyOffset(verifier, VT_HASH) &&
           verifier.VerifyString(hash()) &&
           VerifyOffset(verifier, VT_CONTEXT) &&
           verifier.VerifyString(context()) &&
           verifier.EndTable();
  }
  VersionT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(VersionT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<Version> Pack(flatbuffers::FlatBufferBuilder &_fbb, const VersionT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct VersionBuilder {
  typedef Version Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_majorV(uint32_t majorV) {
    fbb_.AddElement<uint32_t>(Version::VT_MAJORV, majorV, 0);
  }
  void add_minorV(uint32_t minorV) {
    fbb_.AddElement<uint32_t>(Version::VT_MINORV, minorV, 0);
  }
  void add_patchV(uint32_t patchV) {
    fbb_.AddElement<uint32_t>(Version::VT_PATCHV, patchV, 0);
  }
  void add_hash(flatbuffers::Offset<flatbuffers::String> hash) {
    fbb_.AddOffset(Version::VT_HASH, hash);
  }
  void add_context(flatbuffers::Offset<flatbuffers::String> context) {
    fbb_.AddOffset(Version::VT_CONTEXT, context);
  }
  explicit VersionBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  VersionBuilder &operator=(const VersionBuilder &);
  flatbuffers::Offset<Version> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Version>(end);
    return o;
  }
};

inline flatbuffers::Offset<Version> CreateVersion(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint32_t majorV = 0,
    uint32_t minorV = 0,
    uint32_t patchV = 0,
    flatbuffers::Offset<flatbuffers::String> hash = 0,
    flatbuffers::Offset<flatbuffers::String> context = 0) {
  VersionBuilder builder_(_fbb);
  builder_.add_context(context);
  builder_.add_hash(hash);
  builder_.add_patchV(patchV);
  builder_.add_minorV(minorV);
  builder_.add_majorV(majorV);
  return builder_.Finish();
}

inline flatbuffers::Offset<Version> CreateVersionDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint32_t majorV = 0,
    uint32_t minorV = 0,
    uint32_t patchV = 0,
    const char *hash = nullptr,
    const char *context = nullptr) {
  auto hash__ = hash ? _fbb.CreateString(hash) : 0;
  auto context__ = context ? _fbb.CreateString(context) : 0;
  return MVCNN::CreateVersion(
      _fbb,
      majorV,
      minorV,
      patchV,
      hash__,
      context__);
}

flatbuffers::Offset<Version> CreateVersion(flatbuffers::FlatBufferBuilder &_fbb, const VersionT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct ResourcesT : public flatbuffers::NativeTable {
  typedef Resources TableType;
  std::vector<std::unique_ptr<MVCNN::ProcessorMappingT>> processor_allocation;
  std::vector<std::unique_ptr<MVCNN::ProcessorMappingT>> processor_frequencies;
  std::vector<std::unique_ptr<MVCNN::MemoryMappingT>> memory_sizes;
  std::vector<std::unique_ptr<MVCNN::MemoryRelationshipMappingT>> memory_bandwidth;
  ResourcesT() {
  }
};

struct Resources FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef ResourcesT NativeTableType;
  typedef ResourcesBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_PROCESSOR_ALLOCATION = 4,
    VT_PROCESSOR_FREQUENCIES = 6,
    VT_MEMORY_SIZES = 8,
    VT_MEMORY_BANDWIDTH = 10
  };
  const flatbuffers::Vector<flatbuffers::Offset<MVCNN::ProcessorMapping>> *processor_allocation() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MVCNN::ProcessorMapping>> *>(VT_PROCESSOR_ALLOCATION);
  }
  const flatbuffers::Vector<flatbuffers::Offset<MVCNN::ProcessorMapping>> *processor_frequencies() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MVCNN::ProcessorMapping>> *>(VT_PROCESSOR_FREQUENCIES);
  }
  const flatbuffers::Vector<flatbuffers::Offset<MVCNN::MemoryMapping>> *memory_sizes() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MVCNN::MemoryMapping>> *>(VT_MEMORY_SIZES);
  }
  const flatbuffers::Vector<flatbuffers::Offset<MVCNN::MemoryRelationshipMapping>> *memory_bandwidth() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MVCNN::MemoryRelationshipMapping>> *>(VT_MEMORY_BANDWIDTH);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_PROCESSOR_ALLOCATION) &&
           verifier.VerifyVector(processor_allocation()) &&
           verifier.VerifyVectorOfTables(processor_allocation()) &&
           VerifyOffset(verifier, VT_PROCESSOR_FREQUENCIES) &&
           verifier.VerifyVector(processor_frequencies()) &&
           verifier.VerifyVectorOfTables(processor_frequencies()) &&
           VerifyOffset(verifier, VT_MEMORY_SIZES) &&
           verifier.VerifyVector(memory_sizes()) &&
           verifier.VerifyVectorOfTables(memory_sizes()) &&
           VerifyOffset(verifier, VT_MEMORY_BANDWIDTH) &&
           verifier.VerifyVector(memory_bandwidth()) &&
           verifier.VerifyVectorOfTables(memory_bandwidth()) &&
           verifier.EndTable();
  }
  ResourcesT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(ResourcesT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<Resources> Pack(flatbuffers::FlatBufferBuilder &_fbb, const ResourcesT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct ResourcesBuilder {
  typedef Resources Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_processor_allocation(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MVCNN::ProcessorMapping>>> processor_allocation) {
    fbb_.AddOffset(Resources::VT_PROCESSOR_ALLOCATION, processor_allocation);
  }
  void add_processor_frequencies(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MVCNN::ProcessorMapping>>> processor_frequencies) {
    fbb_.AddOffset(Resources::VT_PROCESSOR_FREQUENCIES, processor_frequencies);
  }
  void add_memory_sizes(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MVCNN::MemoryMapping>>> memory_sizes) {
    fbb_.AddOffset(Resources::VT_MEMORY_SIZES, memory_sizes);
  }
  void add_memory_bandwidth(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MVCNN::MemoryRelationshipMapping>>> memory_bandwidth) {
    fbb_.AddOffset(Resources::VT_MEMORY_BANDWIDTH, memory_bandwidth);
  }
  explicit ResourcesBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  ResourcesBuilder &operator=(const ResourcesBuilder &);
  flatbuffers::Offset<Resources> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Resources>(end);
    return o;
  }
};

inline flatbuffers::Offset<Resources> CreateResources(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MVCNN::ProcessorMapping>>> processor_allocation = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MVCNN::ProcessorMapping>>> processor_frequencies = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MVCNN::MemoryMapping>>> memory_sizes = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MVCNN::MemoryRelationshipMapping>>> memory_bandwidth = 0) {
  ResourcesBuilder builder_(_fbb);
  builder_.add_memory_bandwidth(memory_bandwidth);
  builder_.add_memory_sizes(memory_sizes);
  builder_.add_processor_frequencies(processor_frequencies);
  builder_.add_processor_allocation(processor_allocation);
  return builder_.Finish();
}

inline flatbuffers::Offset<Resources> CreateResourcesDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const std::vector<flatbuffers::Offset<MVCNN::ProcessorMapping>> *processor_allocation = nullptr,
    const std::vector<flatbuffers::Offset<MVCNN::ProcessorMapping>> *processor_frequencies = nullptr,
    const std::vector<flatbuffers::Offset<MVCNN::MemoryMapping>> *memory_sizes = nullptr,
    const std::vector<flatbuffers::Offset<MVCNN::MemoryRelationshipMapping>> *memory_bandwidth = nullptr) {
  auto processor_allocation__ = processor_allocation ? _fbb.CreateVector<flatbuffers::Offset<MVCNN::ProcessorMapping>>(*processor_allocation) : 0;
  auto processor_frequencies__ = processor_frequencies ? _fbb.CreateVector<flatbuffers::Offset<MVCNN::ProcessorMapping>>(*processor_frequencies) : 0;
  auto memory_sizes__ = memory_sizes ? _fbb.CreateVector<flatbuffers::Offset<MVCNN::MemoryMapping>>(*memory_sizes) : 0;
  auto memory_bandwidth__ = memory_bandwidth ? _fbb.CreateVector<flatbuffers::Offset<MVCNN::MemoryRelationshipMapping>>(*memory_bandwidth) : 0;
  return MVCNN::CreateResources(
      _fbb,
      processor_allocation__,
      processor_frequencies__,
      memory_sizes__,
      memory_bandwidth__);
}

flatbuffers::Offset<Resources> CreateResources(flatbuffers::FlatBufferBuilder &_fbb, const ResourcesT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct SummaryHeaderT : public flatbuffers::NativeTable {
  typedef SummaryHeader TableType;
  std::unique_ptr<MVCNN::VersionT> version;
  std::string identifier;
  std::vector<std::unique_ptr<MVCNN::TensorReferenceT>> net_input;
  std::vector<std::unique_ptr<MVCNN::TensorReferenceT>> net_output;
  uint32_t task_count;
  uint32_t layer_count;
  std::vector<MVCNN::ExecutionFlag> options;
  std::unique_ptr<MVCNN::ResourcesT> resources;
  std::unique_ptr<MVCNN::SourceStructureT> original_structure;
  std::vector<std::unique_ptr<MVCNN::TensorReferenceT>> in_tensor_desc;
  std::vector<std::unique_ptr<MVCNN::TensorReferenceT>> out_tensor_desc;
  SummaryHeaderT()
      : task_count(0),
        layer_count(0) {
  }
};

struct SummaryHeader FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef SummaryHeaderT NativeTableType;
  typedef SummaryHeaderBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VERSION = 4,
    VT_IDENTIFIER = 6,
    VT_NET_INPUT = 8,
    VT_NET_OUTPUT = 10,
    VT_TASK_COUNT = 12,
    VT_LAYER_COUNT = 14,
    VT_OPTIONS = 16,
    VT_RESOURCES = 18,
    VT_ORIGINAL_STRUCTURE = 20,
    VT_IN_TENSOR_DESC = 22,
    VT_OUT_TENSOR_DESC = 24
  };
  const MVCNN::Version *version() const {
    return GetPointer<const MVCNN::Version *>(VT_VERSION);
  }
  const flatbuffers::String *identifier() const {
    return GetPointer<const flatbuffers::String *>(VT_IDENTIFIER);
  }
  const flatbuffers::Vector<flatbuffers::Offset<MVCNN::TensorReference>> *net_input() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MVCNN::TensorReference>> *>(VT_NET_INPUT);
  }
  const flatbuffers::Vector<flatbuffers::Offset<MVCNN::TensorReference>> *net_output() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MVCNN::TensorReference>> *>(VT_NET_OUTPUT);
  }
  uint32_t task_count() const {
    return GetField<uint32_t>(VT_TASK_COUNT, 0);
  }
  uint32_t layer_count() const {
    return GetField<uint32_t>(VT_LAYER_COUNT, 0);
  }
  const flatbuffers::Vector<int8_t> *options() const {
    return GetPointer<const flatbuffers::Vector<int8_t> *>(VT_OPTIONS);
  }
  const MVCNN::Resources *resources() const {
    return GetPointer<const MVCNN::Resources *>(VT_RESOURCES);
  }
  const MVCNN::SourceStructure *original_structure() const {
    return GetPointer<const MVCNN::SourceStructure *>(VT_ORIGINAL_STRUCTURE);
  }
  const flatbuffers::Vector<flatbuffers::Offset<MVCNN::TensorReference>> *in_tensor_desc() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MVCNN::TensorReference>> *>(VT_IN_TENSOR_DESC);
  }
  const flatbuffers::Vector<flatbuffers::Offset<MVCNN::TensorReference>> *out_tensor_desc() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MVCNN::TensorReference>> *>(VT_OUT_TENSOR_DESC);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_VERSION) &&
           verifier.VerifyTable(version()) &&
           VerifyOffset(verifier, VT_IDENTIFIER) &&
           verifier.VerifyString(identifier()) &&
           VerifyOffset(verifier, VT_NET_INPUT) &&
           verifier.VerifyVector(net_input()) &&
           verifier.VerifyVectorOfTables(net_input()) &&
           VerifyOffset(verifier, VT_NET_OUTPUT) &&
           verifier.VerifyVector(net_output()) &&
           verifier.VerifyVectorOfTables(net_output()) &&
           VerifyField<uint32_t>(verifier, VT_TASK_COUNT) &&
           VerifyField<uint32_t>(verifier, VT_LAYER_COUNT) &&
           VerifyOffset(verifier, VT_OPTIONS) &&
           verifier.VerifyVector(options()) &&
           VerifyOffset(verifier, VT_RESOURCES) &&
           verifier.VerifyTable(resources()) &&
           VerifyOffset(verifier, VT_ORIGINAL_STRUCTURE) &&
           verifier.VerifyTable(original_structure()) &&
           VerifyOffset(verifier, VT_IN_TENSOR_DESC) &&
           verifier.VerifyVector(in_tensor_desc()) &&
           verifier.VerifyVectorOfTables(in_tensor_desc()) &&
           VerifyOffset(verifier, VT_OUT_TENSOR_DESC) &&
           verifier.VerifyVector(out_tensor_desc()) &&
           verifier.VerifyVectorOfTables(out_tensor_desc()) &&
           verifier.EndTable();
  }
  SummaryHeaderT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(SummaryHeaderT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<SummaryHeader> Pack(flatbuffers::FlatBufferBuilder &_fbb, const SummaryHeaderT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct SummaryHeaderBuilder {
  typedef SummaryHeader Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_version(flatbuffers::Offset<MVCNN::Version> version) {
    fbb_.AddOffset(SummaryHeader::VT_VERSION, version);
  }
  void add_identifier(flatbuffers::Offset<flatbuffers::String> identifier) {
    fbb_.AddOffset(SummaryHeader::VT_IDENTIFIER, identifier);
  }
  void add_net_input(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MVCNN::TensorReference>>> net_input) {
    fbb_.AddOffset(SummaryHeader::VT_NET_INPUT, net_input);
  }
  void add_net_output(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MVCNN::TensorReference>>> net_output) {
    fbb_.AddOffset(SummaryHeader::VT_NET_OUTPUT, net_output);
  }
  void add_task_count(uint32_t task_count) {
    fbb_.AddElement<uint32_t>(SummaryHeader::VT_TASK_COUNT, task_count, 0);
  }
  void add_layer_count(uint32_t layer_count) {
    fbb_.AddElement<uint32_t>(SummaryHeader::VT_LAYER_COUNT, layer_count, 0);
  }
  void add_options(flatbuffers::Offset<flatbuffers::Vector<int8_t>> options) {
    fbb_.AddOffset(SummaryHeader::VT_OPTIONS, options);
  }
  void add_resources(flatbuffers::Offset<MVCNN::Resources> resources) {
    fbb_.AddOffset(SummaryHeader::VT_RESOURCES, resources);
  }
  void add_original_structure(flatbuffers::Offset<MVCNN::SourceStructure> original_structure) {
    fbb_.AddOffset(SummaryHeader::VT_ORIGINAL_STRUCTURE, original_structure);
  }
  void add_in_tensor_desc(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MVCNN::TensorReference>>> in_tensor_desc) {
    fbb_.AddOffset(SummaryHeader::VT_IN_TENSOR_DESC, in_tensor_desc);
  }
  void add_out_tensor_desc(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MVCNN::TensorReference>>> out_tensor_desc) {
    fbb_.AddOffset(SummaryHeader::VT_OUT_TENSOR_DESC, out_tensor_desc);
  }
  explicit SummaryHeaderBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  SummaryHeaderBuilder &operator=(const SummaryHeaderBuilder &);
  flatbuffers::Offset<SummaryHeader> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<SummaryHeader>(end);
    return o;
  }
};

inline flatbuffers::Offset<SummaryHeader> CreateSummaryHeader(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<MVCNN::Version> version = 0,
    flatbuffers::Offset<flatbuffers::String> identifier = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MVCNN::TensorReference>>> net_input = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MVCNN::TensorReference>>> net_output = 0,
    uint32_t task_count = 0,
    uint32_t layer_count = 0,
    flatbuffers::Offset<flatbuffers::Vector<int8_t>> options = 0,
    flatbuffers::Offset<MVCNN::Resources> resources = 0,
    flatbuffers::Offset<MVCNN::SourceStructure> original_structure = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MVCNN::TensorReference>>> in_tensor_desc = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MVCNN::TensorReference>>> out_tensor_desc = 0) {
  SummaryHeaderBuilder builder_(_fbb);
  builder_.add_out_tensor_desc(out_tensor_desc);
  builder_.add_in_tensor_desc(in_tensor_desc);
  builder_.add_original_structure(original_structure);
  builder_.add_resources(resources);
  builder_.add_options(options);
  builder_.add_layer_count(layer_count);
  builder_.add_task_count(task_count);
  builder_.add_net_output(net_output);
  builder_.add_net_input(net_input);
  builder_.add_identifier(identifier);
  builder_.add_version(version);
  return builder_.Finish();
}

inline flatbuffers::Offset<SummaryHeader> CreateSummaryHeaderDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<MVCNN::Version> version = 0,
    const char *identifier = nullptr,
    const std::vector<flatbuffers::Offset<MVCNN::TensorReference>> *net_input = nullptr,
    const std::vector<flatbuffers::Offset<MVCNN::TensorReference>> *net_output = nullptr,
    uint32_t task_count = 0,
    uint32_t layer_count = 0,
    const std::vector<int8_t> *options = nullptr,
    flatbuffers::Offset<MVCNN::Resources> resources = 0,
    flatbuffers::Offset<MVCNN::SourceStructure> original_structure = 0,
    const std::vector<flatbuffers::Offset<MVCNN::TensorReference>> *in_tensor_desc = nullptr,
    const std::vector<flatbuffers::Offset<MVCNN::TensorReference>> *out_tensor_desc = nullptr) {
  auto identifier__ = identifier ? _fbb.CreateString(identifier) : 0;
  auto net_input__ = net_input ? _fbb.CreateVector<flatbuffers::Offset<MVCNN::TensorReference>>(*net_input) : 0;
  auto net_output__ = net_output ? _fbb.CreateVector<flatbuffers::Offset<MVCNN::TensorReference>>(*net_output) : 0;
  auto options__ = options ? _fbb.CreateVector<int8_t>(*options) : 0;
  auto in_tensor_desc__ = in_tensor_desc ? _fbb.CreateVector<flatbuffers::Offset<MVCNN::TensorReference>>(*in_tensor_desc) : 0;
  auto out_tensor_desc__ = out_tensor_desc ? _fbb.CreateVector<flatbuffers::Offset<MVCNN::TensorReference>>(*out_tensor_desc) : 0;
  return MVCNN::CreateSummaryHeader(
      _fbb,
      version,
      identifier__,
      net_input__,
      net_output__,
      task_count,
      layer_count,
      options__,
      resources,
      original_structure,
      in_tensor_desc__,
      out_tensor_desc__);
}

flatbuffers::Offset<SummaryHeader> CreateSummaryHeader(flatbuffers::FlatBufferBuilder &_fbb, const SummaryHeaderT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

inline VersionT *Version::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  std::unique_ptr<MVCNN::VersionT> _o = std::unique_ptr<MVCNN::VersionT>(new VersionT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void Version::UnPackTo(VersionT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = majorV(); _o->majorV = _e; }
  { auto _e = minorV(); _o->minorV = _e; }
  { auto _e = patchV(); _o->patchV = _e; }
  { auto _e = hash(); if (_e) _o->hash = _e->str(); }
  { auto _e = context(); if (_e) _o->context = _e->str(); }
}

inline flatbuffers::Offset<Version> Version::Pack(flatbuffers::FlatBufferBuilder &_fbb, const VersionT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateVersion(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<Version> CreateVersion(flatbuffers::FlatBufferBuilder &_fbb, const VersionT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const VersionT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _majorV = _o->majorV;
  auto _minorV = _o->minorV;
  auto _patchV = _o->patchV;
  auto _hash = _o->hash.empty() ? _fbb.CreateSharedString("") : _fbb.CreateString(_o->hash);
  auto _context = _o->context.empty() ? _fbb.CreateSharedString("") : _fbb.CreateString(_o->context);
  return MVCNN::CreateVersion(
      _fbb,
      _majorV,
      _minorV,
      _patchV,
      _hash,
      _context);
}

inline ResourcesT *Resources::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  std::unique_ptr<MVCNN::ResourcesT> _o = std::unique_ptr<MVCNN::ResourcesT>(new ResourcesT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void Resources::UnPackTo(ResourcesT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = processor_allocation(); if (_e) { _o->processor_allocation.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->processor_allocation[_i] = std::unique_ptr<MVCNN::ProcessorMappingT>(_e->Get(_i)->UnPack(_resolver)); } } }
  { auto _e = processor_frequencies(); if (_e) { _o->processor_frequencies.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->processor_frequencies[_i] = std::unique_ptr<MVCNN::ProcessorMappingT>(_e->Get(_i)->UnPack(_resolver)); } } }
  { auto _e = memory_sizes(); if (_e) { _o->memory_sizes.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->memory_sizes[_i] = std::unique_ptr<MVCNN::MemoryMappingT>(_e->Get(_i)->UnPack(_resolver)); } } }
  { auto _e = memory_bandwidth(); if (_e) { _o->memory_bandwidth.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->memory_bandwidth[_i] = std::unique_ptr<MVCNN::MemoryRelationshipMappingT>(_e->Get(_i)->UnPack(_resolver)); } } }
}

inline flatbuffers::Offset<Resources> Resources::Pack(flatbuffers::FlatBufferBuilder &_fbb, const ResourcesT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateResources(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<Resources> CreateResources(flatbuffers::FlatBufferBuilder &_fbb, const ResourcesT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const ResourcesT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _processor_allocation = _fbb.CreateVector<flatbuffers::Offset<MVCNN::ProcessorMapping>> (_o->processor_allocation.size(), [](size_t i, _VectorArgs *__va) { return CreateProcessorMapping(*__va->__fbb, __va->__o->processor_allocation[i].get(), __va->__rehasher); }, &_va );
  auto _processor_frequencies = _fbb.CreateVector<flatbuffers::Offset<MVCNN::ProcessorMapping>> (_o->processor_frequencies.size(), [](size_t i, _VectorArgs *__va) { return CreateProcessorMapping(*__va->__fbb, __va->__o->processor_frequencies[i].get(), __va->__rehasher); }, &_va );
  auto _memory_sizes = _fbb.CreateVector<flatbuffers::Offset<MVCNN::MemoryMapping>> (_o->memory_sizes.size(), [](size_t i, _VectorArgs *__va) { return CreateMemoryMapping(*__va->__fbb, __va->__o->memory_sizes[i].get(), __va->__rehasher); }, &_va );
  auto _memory_bandwidth = _fbb.CreateVector<flatbuffers::Offset<MVCNN::MemoryRelationshipMapping>> (_o->memory_bandwidth.size(), [](size_t i, _VectorArgs *__va) { return CreateMemoryRelationshipMapping(*__va->__fbb, __va->__o->memory_bandwidth[i].get(), __va->__rehasher); }, &_va );
  return MVCNN::CreateResources(
      _fbb,
      _processor_allocation,
      _processor_frequencies,
      _memory_sizes,
      _memory_bandwidth);
}

inline SummaryHeaderT *SummaryHeader::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  std::unique_ptr<MVCNN::SummaryHeaderT> _o = std::unique_ptr<MVCNN::SummaryHeaderT>(new SummaryHeaderT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void SummaryHeader::UnPackTo(SummaryHeaderT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = version(); if (_e) _o->version = std::unique_ptr<MVCNN::VersionT>(_e->UnPack(_resolver)); }
  { auto _e = identifier(); if (_e) _o->identifier = _e->str(); }
  { auto _e = net_input(); if (_e) { _o->net_input.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->net_input[_i] = std::unique_ptr<MVCNN::TensorReferenceT>(_e->Get(_i)->UnPack(_resolver)); } } }
  { auto _e = net_output(); if (_e) { _o->net_output.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->net_output[_i] = std::unique_ptr<MVCNN::TensorReferenceT>(_e->Get(_i)->UnPack(_resolver)); } } }
  { auto _e = task_count(); _o->task_count = _e; }
  { auto _e = layer_count(); _o->layer_count = _e; }
  { auto _e = options(); if (_e) { _o->options.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->options[_i] = static_cast<MVCNN::ExecutionFlag>(_e->Get(_i)); } } }
  { auto _e = resources(); if (_e) _o->resources = std::unique_ptr<MVCNN::ResourcesT>(_e->UnPack(_resolver)); }
  { auto _e = original_structure(); if (_e) _o->original_structure = std::unique_ptr<MVCNN::SourceStructureT>(_e->UnPack(_resolver)); }
  { auto _e = in_tensor_desc(); if (_e) { _o->in_tensor_desc.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->in_tensor_desc[_i] = std::unique_ptr<MVCNN::TensorReferenceT>(_e->Get(_i)->UnPack(_resolver)); } } }
  { auto _e = out_tensor_desc(); if (_e) { _o->out_tensor_desc.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->out_tensor_desc[_i] = std::unique_ptr<MVCNN::TensorReferenceT>(_e->Get(_i)->UnPack(_resolver)); } } }
}

inline flatbuffers::Offset<SummaryHeader> SummaryHeader::Pack(flatbuffers::FlatBufferBuilder &_fbb, const SummaryHeaderT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateSummaryHeader(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<SummaryHeader> CreateSummaryHeader(flatbuffers::FlatBufferBuilder &_fbb, const SummaryHeaderT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const SummaryHeaderT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _version = _o->version ? CreateVersion(_fbb, _o->version.get(), _rehasher) : 0;
  auto _identifier = _o->identifier.empty() ? _fbb.CreateSharedString("") : _fbb.CreateString(_o->identifier);
  auto _net_input = _fbb.CreateVector<flatbuffers::Offset<MVCNN::TensorReference>> (_o->net_input.size(), [](size_t i, _VectorArgs *__va) { return CreateTensorReference(*__va->__fbb, __va->__o->net_input[i].get(), __va->__rehasher); }, &_va );
  auto _net_output = _fbb.CreateVector<flatbuffers::Offset<MVCNN::TensorReference>> (_o->net_output.size(), [](size_t i, _VectorArgs *__va) { return CreateTensorReference(*__va->__fbb, __va->__o->net_output[i].get(), __va->__rehasher); }, &_va );
  auto _task_count = _o->task_count;
  auto _layer_count = _o->layer_count;
  auto _options = _fbb.CreateVectorScalarCast<int8_t>(flatbuffers::data(_o->options), _o->options.size());
  auto _resources = _o->resources ? CreateResources(_fbb, _o->resources.get(), _rehasher) : 0;
  auto _original_structure = _o->original_structure ? CreateSourceStructure(_fbb, _o->original_structure.get(), _rehasher) : 0;
  auto _in_tensor_desc = _fbb.CreateVector<flatbuffers::Offset<MVCNN::TensorReference>> (_o->in_tensor_desc.size(), [](size_t i, _VectorArgs *__va) { return CreateTensorReference(*__va->__fbb, __va->__o->in_tensor_desc[i].get(), __va->__rehasher); }, &_va );
  auto _out_tensor_desc = _fbb.CreateVector<flatbuffers::Offset<MVCNN::TensorReference>> (_o->out_tensor_desc.size(), [](size_t i, _VectorArgs *__va) { return CreateTensorReference(*__va->__fbb, __va->__o->out_tensor_desc[i].get(), __va->__rehasher); }, &_va );
  return MVCNN::CreateSummaryHeader(
      _fbb,
      _version,
      _identifier,
      _net_input,
      _net_output,
      _task_count,
      _layer_count,
      _options,
      _resources,
      _original_structure,
      _in_tensor_desc,
      _out_tensor_desc);
}

}  // namespace MVCNN

#endif  // FLATBUFFERS_GENERATED_FILEHEADER_MVCNN_H_
