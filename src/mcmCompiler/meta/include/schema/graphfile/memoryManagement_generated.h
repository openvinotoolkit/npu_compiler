// automatically generated by the FlatBuffers compiler, do not modify


#ifndef FLATBUFFERS_GENERATED_MEMORYMANAGEMENT_MVCNN_H_
#define FLATBUFFERS_GENERATED_MEMORYMANAGEMENT_MVCNN_H_

#include "flatbuffers/flatbuffers.h"

namespace MVCNN {

struct BinaryData;
struct BinaryDataBuilder;
struct BinaryDataT;

struct IndirectDataReference;
struct IndirectDataReferenceBuilder;
struct IndirectDataReferenceT;

struct TensorReference;
struct TensorReferenceBuilder;
struct TensorReferenceT;

enum MemoryLocation {
  MemoryLocation_NULL = 0,
  MemoryLocation_ProgrammableInput = 1,
  MemoryLocation_ProgrammableOutput = 2,
  MemoryLocation_VPU_DDR_Heap = 3,
  MemoryLocation_GraphFile = 4,
  MemoryLocation_VPU_CMX_NN = 5,
  MemoryLocation_VPU_CMX_UPA = 6,
  MemoryLocation_VPU_DDR_BSS = 7,
  MemoryLocation_VPU_CSRAM = 8,
  MemoryLocation_MIN = MemoryLocation_NULL,
  MemoryLocation_MAX = MemoryLocation_VPU_CSRAM
};

inline const MemoryLocation (&EnumValuesMemoryLocation())[9] {
  static const MemoryLocation values[] = {
    MemoryLocation_NULL,
    MemoryLocation_ProgrammableInput,
    MemoryLocation_ProgrammableOutput,
    MemoryLocation_VPU_DDR_Heap,
    MemoryLocation_GraphFile,
    MemoryLocation_VPU_CMX_NN,
    MemoryLocation_VPU_CMX_UPA,
    MemoryLocation_VPU_DDR_BSS,
    MemoryLocation_VPU_CSRAM
  };
  return values;
}

inline const char * const *EnumNamesMemoryLocation() {
  static const char * const names[10] = {
    "NULL",
    "ProgrammableInput",
    "ProgrammableOutput",
    "VPU_DDR_Heap",
    "GraphFile",
    "VPU_CMX_NN",
    "VPU_CMX_UPA",
    "VPU_DDR_BSS",
    "VPU_CSRAM",
    nullptr
  };
  return names;
}

inline const char *EnumNameMemoryLocation(MemoryLocation e) {
  if (flatbuffers::IsOutRange(e, MemoryLocation_NULL, MemoryLocation_VPU_CSRAM)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesMemoryLocation()[index];
}

enum DType {
  DType_NOT_SET = 0,
  DType_FP64 = 1,
  DType_FP32 = 2,
  DType_FP16 = 3,
  DType_FP8 = 4,
  DType_U64 = 5,
  DType_U32 = 6,
  DType_U16 = 7,
  DType_U8 = 8,
  DType_I64 = 9,
  DType_I32 = 10,
  DType_I16 = 11,
  DType_I8 = 12,
  DType_I4 = 13,
  DType_I2 = 14,
  DType_I4X = 15,
  DType_BIN = 16,
  DType_LOG = 17,
  DType_I2X = 18,
  DType_BFP16 = 19,
  DType_MIN = DType_NOT_SET,
  DType_MAX = DType_BFP16
};

inline const DType (&EnumValuesDType())[20] {
  static const DType values[] = {
    DType_NOT_SET,
    DType_FP64,
    DType_FP32,
    DType_FP16,
    DType_FP8,
    DType_U64,
    DType_U32,
    DType_U16,
    DType_U8,
    DType_I64,
    DType_I32,
    DType_I16,
    DType_I8,
    DType_I4,
    DType_I2,
    DType_I4X,
    DType_BIN,
    DType_LOG,
    DType_I2X,
    DType_BFP16
  };
  return values;
}

inline const char * const *EnumNamesDType() {
  static const char * const names[21] = {
    "NOT_SET",
    "FP64",
    "FP32",
    "FP16",
    "FP8",
    "U64",
    "U32",
    "U16",
    "U8",
    "I64",
    "I32",
    "I16",
    "I8",
    "I4",
    "I2",
    "I4X",
    "BIN",
    "LOG",
    "I2X",
    "BFP16",
    nullptr
  };
  return names;
}

inline const char *EnumNameDType(DType e) {
  if (flatbuffers::IsOutRange(e, DType_NOT_SET, DType_BFP16)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesDType()[index];
}

struct BinaryDataT : public flatbuffers::NativeTable {
  typedef BinaryData TableType;
  MVCNN::DType underlying_type;
  uint64_t length;
  uint64_t padding;
  uint64_t padding2;
  uint64_t padding3;
  uint64_t padding4;
  uint64_t padding5;
  uint64_t padding6;
  uint64_t padding7;
  uint64_t padding8;
  uint64_t padding9;
  uint64_t padding10;
  uint64_t padding11;
  uint64_t padding12;
  uint64_t padding13;
  uint64_t padding14;
  uint64_t padding15;
  uint64_t padding16;
  uint64_t padding17;
  uint64_t padding18;
  uint64_t padding19;
  uint64_t padding20;
  uint64_t padding21;
  uint64_t padding22;
  uint64_t padding23;
  uint64_t padding24;
  uint64_t padding25;
  uint64_t padding26;
  uint64_t padding27;
  uint64_t padding28;
  std::vector<uint64_t> data;
  bool csram_cacheable;
  BinaryDataT()
      : underlying_type(MVCNN::DType_NOT_SET),
        length(0),
        padding(0),
        padding2(0),
        padding3(0),
        padding4(0),
        padding5(0),
        padding6(0),
        padding7(0),
        padding8(0),
        padding9(0),
        padding10(0),
        padding11(0),
        padding12(0),
        padding13(0),
        padding14(0),
        padding15(0),
        padding16(0),
        padding17(0),
        padding18(0),
        padding19(0),
        padding20(0),
        padding21(0),
        padding22(0),
        padding23(0),
        padding24(0),
        padding25(0),
        padding26(0),
        padding27(0),
        padding28(0),
        csram_cacheable(false) {
  }
};

struct BinaryData FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef BinaryDataT NativeTableType;
  typedef BinaryDataBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_UNDERLYING_TYPE = 4,
    VT_LENGTH = 6,
    VT_PADDING = 8,
    VT_PADDING2 = 10,
    VT_PADDING3 = 12,
    VT_PADDING4 = 14,
    VT_PADDING5 = 16,
    VT_PADDING6 = 18,
    VT_PADDING7 = 20,
    VT_PADDING8 = 22,
    VT_PADDING9 = 24,
    VT_PADDING10 = 26,
    VT_PADDING11 = 28,
    VT_PADDING12 = 30,
    VT_PADDING13 = 32,
    VT_PADDING14 = 34,
    VT_PADDING15 = 36,
    VT_PADDING16 = 38,
    VT_PADDING17 = 40,
    VT_PADDING18 = 42,
    VT_PADDING19 = 44,
    VT_PADDING20 = 46,
    VT_PADDING21 = 48,
    VT_PADDING22 = 50,
    VT_PADDING23 = 52,
    VT_PADDING24 = 54,
    VT_PADDING25 = 56,
    VT_PADDING26 = 58,
    VT_PADDING27 = 60,
    VT_PADDING28 = 62,
    VT_DATA = 64,
    VT_CSRAM_CACHEABLE = 66
  };
  MVCNN::DType underlying_type() const {
    return static_cast<MVCNN::DType>(GetField<int8_t>(VT_UNDERLYING_TYPE, 0));
  }
  uint64_t length() const {
    return GetField<uint64_t>(VT_LENGTH, 0);
  }
  uint64_t padding() const {
    return GetField<uint64_t>(VT_PADDING, 0);
  }
  uint64_t padding2() const {
    return GetField<uint64_t>(VT_PADDING2, 0);
  }
  uint64_t padding3() const {
    return GetField<uint64_t>(VT_PADDING3, 0);
  }
  uint64_t padding4() const {
    return GetField<uint64_t>(VT_PADDING4, 0);
  }
  uint64_t padding5() const {
    return GetField<uint64_t>(VT_PADDING5, 0);
  }
  uint64_t padding6() const {
    return GetField<uint64_t>(VT_PADDING6, 0);
  }
  uint64_t padding7() const {
    return GetField<uint64_t>(VT_PADDING7, 0);
  }
  uint64_t padding8() const {
    return GetField<uint64_t>(VT_PADDING8, 0);
  }
  uint64_t padding9() const {
    return GetField<uint64_t>(VT_PADDING9, 0);
  }
  uint64_t padding10() const {
    return GetField<uint64_t>(VT_PADDING10, 0);
  }
  uint64_t padding11() const {
    return GetField<uint64_t>(VT_PADDING11, 0);
  }
  uint64_t padding12() const {
    return GetField<uint64_t>(VT_PADDING12, 0);
  }
  uint64_t padding13() const {
    return GetField<uint64_t>(VT_PADDING13, 0);
  }
  uint64_t padding14() const {
    return GetField<uint64_t>(VT_PADDING14, 0);
  }
  uint64_t padding15() const {
    return GetField<uint64_t>(VT_PADDING15, 0);
  }
  uint64_t padding16() const {
    return GetField<uint64_t>(VT_PADDING16, 0);
  }
  uint64_t padding17() const {
    return GetField<uint64_t>(VT_PADDING17, 0);
  }
  uint64_t padding18() const {
    return GetField<uint64_t>(VT_PADDING18, 0);
  }
  uint64_t padding19() const {
    return GetField<uint64_t>(VT_PADDING19, 0);
  }
  uint64_t padding20() const {
    return GetField<uint64_t>(VT_PADDING20, 0);
  }
  uint64_t padding21() const {
    return GetField<uint64_t>(VT_PADDING21, 0);
  }
  uint64_t padding22() const {
    return GetField<uint64_t>(VT_PADDING22, 0);
  }
  uint64_t padding23() const {
    return GetField<uint64_t>(VT_PADDING23, 0);
  }
  uint64_t padding24() const {
    return GetField<uint64_t>(VT_PADDING24, 0);
  }
  uint64_t padding25() const {
    return GetField<uint64_t>(VT_PADDING25, 0);
  }
  uint64_t padding26() const {
    return GetField<uint64_t>(VT_PADDING26, 0);
  }
  uint64_t padding27() const {
    return GetField<uint64_t>(VT_PADDING27, 0);
  }
  uint64_t padding28() const {
    return GetField<uint64_t>(VT_PADDING28, 0);
  }
  const flatbuffers::Vector<uint64_t> *data() const {
    return GetPointer<const flatbuffers::Vector<uint64_t> *>(VT_DATA);
  }
  bool csram_cacheable() const {
    return GetField<uint8_t>(VT_CSRAM_CACHEABLE, 0) != 0;
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int8_t>(verifier, VT_UNDERLYING_TYPE) &&
           VerifyField<uint64_t>(verifier, VT_LENGTH) &&
           VerifyField<uint64_t>(verifier, VT_PADDING) &&
           VerifyField<uint64_t>(verifier, VT_PADDING2) &&
           VerifyField<uint64_t>(verifier, VT_PADDING3) &&
           VerifyField<uint64_t>(verifier, VT_PADDING4) &&
           VerifyField<uint64_t>(verifier, VT_PADDING5) &&
           VerifyField<uint64_t>(verifier, VT_PADDING6) &&
           VerifyField<uint64_t>(verifier, VT_PADDING7) &&
           VerifyField<uint64_t>(verifier, VT_PADDING8) &&
           VerifyField<uint64_t>(verifier, VT_PADDING9) &&
           VerifyField<uint64_t>(verifier, VT_PADDING10) &&
           VerifyField<uint64_t>(verifier, VT_PADDING11) &&
           VerifyField<uint64_t>(verifier, VT_PADDING12) &&
           VerifyField<uint64_t>(verifier, VT_PADDING13) &&
           VerifyField<uint64_t>(verifier, VT_PADDING14) &&
           VerifyField<uint64_t>(verifier, VT_PADDING15) &&
           VerifyField<uint64_t>(verifier, VT_PADDING16) &&
           VerifyField<uint64_t>(verifier, VT_PADDING17) &&
           VerifyField<uint64_t>(verifier, VT_PADDING18) &&
           VerifyField<uint64_t>(verifier, VT_PADDING19) &&
           VerifyField<uint64_t>(verifier, VT_PADDING20) &&
           VerifyField<uint64_t>(verifier, VT_PADDING21) &&
           VerifyField<uint64_t>(verifier, VT_PADDING22) &&
           VerifyField<uint64_t>(verifier, VT_PADDING23) &&
           VerifyField<uint64_t>(verifier, VT_PADDING24) &&
           VerifyField<uint64_t>(verifier, VT_PADDING25) &&
           VerifyField<uint64_t>(verifier, VT_PADDING26) &&
           VerifyField<uint64_t>(verifier, VT_PADDING27) &&
           VerifyField<uint64_t>(verifier, VT_PADDING28) &&
           VerifyOffset(verifier, VT_DATA) &&
           verifier.VerifyVector(data()) &&
           VerifyField<uint8_t>(verifier, VT_CSRAM_CACHEABLE) &&
           verifier.EndTable();
  }
  BinaryDataT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(BinaryDataT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<BinaryData> Pack(flatbuffers::FlatBufferBuilder &_fbb, const BinaryDataT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct BinaryDataBuilder {
  typedef BinaryData Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_underlying_type(MVCNN::DType underlying_type) {
    fbb_.AddElement<int8_t>(BinaryData::VT_UNDERLYING_TYPE, static_cast<int8_t>(underlying_type), 0);
  }
  void add_length(uint64_t length) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_LENGTH, length, 0);
  }
  void add_padding(uint64_t padding) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING, padding, 0);
  }
  void add_padding2(uint64_t padding2) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING2, padding2, 0);
  }
  void add_padding3(uint64_t padding3) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING3, padding3, 0);
  }
  void add_padding4(uint64_t padding4) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING4, padding4, 0);
  }
  void add_padding5(uint64_t padding5) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING5, padding5, 0);
  }
  void add_padding6(uint64_t padding6) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING6, padding6, 0);
  }
  void add_padding7(uint64_t padding7) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING7, padding7, 0);
  }
  void add_padding8(uint64_t padding8) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING8, padding8, 0);
  }
  void add_padding9(uint64_t padding9) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING9, padding9, 0);
  }
  void add_padding10(uint64_t padding10) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING10, padding10, 0);
  }
  void add_padding11(uint64_t padding11) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING11, padding11, 0);
  }
  void add_padding12(uint64_t padding12) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING12, padding12, 0);
  }
  void add_padding13(uint64_t padding13) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING13, padding13, 0);
  }
  void add_padding14(uint64_t padding14) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING14, padding14, 0);
  }
  void add_padding15(uint64_t padding15) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING15, padding15, 0);
  }
  void add_padding16(uint64_t padding16) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING16, padding16, 0);
  }
  void add_padding17(uint64_t padding17) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING17, padding17, 0);
  }
  void add_padding18(uint64_t padding18) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING18, padding18, 0);
  }
  void add_padding19(uint64_t padding19) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING19, padding19, 0);
  }
  void add_padding20(uint64_t padding20) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING20, padding20, 0);
  }
  void add_padding21(uint64_t padding21) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING21, padding21, 0);
  }
  void add_padding22(uint64_t padding22) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING22, padding22, 0);
  }
  void add_padding23(uint64_t padding23) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING23, padding23, 0);
  }
  void add_padding24(uint64_t padding24) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING24, padding24, 0);
  }
  void add_padding25(uint64_t padding25) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING25, padding25, 0);
  }
  void add_padding26(uint64_t padding26) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING26, padding26, 0);
  }
  void add_padding27(uint64_t padding27) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING27, padding27, 0);
  }
  void add_padding28(uint64_t padding28) {
    fbb_.AddElement<uint64_t>(BinaryData::VT_PADDING28, padding28, 0);
  }
  void add_data(flatbuffers::Offset<flatbuffers::Vector<uint64_t>> data) {
    fbb_.AddOffset(BinaryData::VT_DATA, data);
  }
  void add_csram_cacheable(bool csram_cacheable) {
    fbb_.AddElement<uint8_t>(BinaryData::VT_CSRAM_CACHEABLE, static_cast<uint8_t>(csram_cacheable), 0);
  }
  explicit BinaryDataBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  BinaryDataBuilder &operator=(const BinaryDataBuilder &);
  flatbuffers::Offset<BinaryData> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<BinaryData>(end);
    return o;
  }
};

inline flatbuffers::Offset<BinaryData> CreateBinaryData(
    flatbuffers::FlatBufferBuilder &_fbb,
    MVCNN::DType underlying_type = MVCNN::DType_NOT_SET,
    uint64_t length = 0,
    uint64_t padding = 0,
    uint64_t padding2 = 0,
    uint64_t padding3 = 0,
    uint64_t padding4 = 0,
    uint64_t padding5 = 0,
    uint64_t padding6 = 0,
    uint64_t padding7 = 0,
    uint64_t padding8 = 0,
    uint64_t padding9 = 0,
    uint64_t padding10 = 0,
    uint64_t padding11 = 0,
    uint64_t padding12 = 0,
    uint64_t padding13 = 0,
    uint64_t padding14 = 0,
    uint64_t padding15 = 0,
    uint64_t padding16 = 0,
    uint64_t padding17 = 0,
    uint64_t padding18 = 0,
    uint64_t padding19 = 0,
    uint64_t padding20 = 0,
    uint64_t padding21 = 0,
    uint64_t padding22 = 0,
    uint64_t padding23 = 0,
    uint64_t padding24 = 0,
    uint64_t padding25 = 0,
    uint64_t padding26 = 0,
    uint64_t padding27 = 0,
    uint64_t padding28 = 0,
    flatbuffers::Offset<flatbuffers::Vector<uint64_t>> data = 0,
    bool csram_cacheable = false) {
  BinaryDataBuilder builder_(_fbb);
  builder_.add_padding28(padding28);
  builder_.add_padding27(padding27);
  builder_.add_padding26(padding26);
  builder_.add_padding25(padding25);
  builder_.add_padding24(padding24);
  builder_.add_padding23(padding23);
  builder_.add_padding22(padding22);
  builder_.add_padding21(padding21);
  builder_.add_padding20(padding20);
  builder_.add_padding19(padding19);
  builder_.add_padding18(padding18);
  builder_.add_padding17(padding17);
  builder_.add_padding16(padding16);
  builder_.add_padding15(padding15);
  builder_.add_padding14(padding14);
  builder_.add_padding13(padding13);
  builder_.add_padding12(padding12);
  builder_.add_padding11(padding11);
  builder_.add_padding10(padding10);
  builder_.add_padding9(padding9);
  builder_.add_padding8(padding8);
  builder_.add_padding7(padding7);
  builder_.add_padding6(padding6);
  builder_.add_padding5(padding5);
  builder_.add_padding4(padding4);
  builder_.add_padding3(padding3);
  builder_.add_padding2(padding2);
  builder_.add_padding(padding);
  builder_.add_length(length);
  builder_.add_data(data);
  builder_.add_csram_cacheable(csram_cacheable);
  builder_.add_underlying_type(underlying_type);
  return builder_.Finish();
}

inline flatbuffers::Offset<BinaryData> CreateBinaryDataDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    MVCNN::DType underlying_type = MVCNN::DType_NOT_SET,
    uint64_t length = 0,
    uint64_t padding = 0,
    uint64_t padding2 = 0,
    uint64_t padding3 = 0,
    uint64_t padding4 = 0,
    uint64_t padding5 = 0,
    uint64_t padding6 = 0,
    uint64_t padding7 = 0,
    uint64_t padding8 = 0,
    uint64_t padding9 = 0,
    uint64_t padding10 = 0,
    uint64_t padding11 = 0,
    uint64_t padding12 = 0,
    uint64_t padding13 = 0,
    uint64_t padding14 = 0,
    uint64_t padding15 = 0,
    uint64_t padding16 = 0,
    uint64_t padding17 = 0,
    uint64_t padding18 = 0,
    uint64_t padding19 = 0,
    uint64_t padding20 = 0,
    uint64_t padding21 = 0,
    uint64_t padding22 = 0,
    uint64_t padding23 = 0,
    uint64_t padding24 = 0,
    uint64_t padding25 = 0,
    uint64_t padding26 = 0,
    uint64_t padding27 = 0,
    uint64_t padding28 = 0,
    const std::vector<uint64_t> *data = nullptr,
    bool csram_cacheable = false) {
  auto data__ = data ? _fbb.CreateVector<uint64_t>(*data) : 0;
  return MVCNN::CreateBinaryData(
      _fbb,
      underlying_type,
      length,
      padding,
      padding2,
      padding3,
      padding4,
      padding5,
      padding6,
      padding7,
      padding8,
      padding9,
      padding10,
      padding11,
      padding12,
      padding13,
      padding14,
      padding15,
      padding16,
      padding17,
      padding18,
      padding19,
      padding20,
      padding21,
      padding22,
      padding23,
      padding24,
      padding25,
      padding26,
      padding27,
      padding28,
      data__,
      csram_cacheable);
}

flatbuffers::Offset<BinaryData> CreateBinaryData(flatbuffers::FlatBufferBuilder &_fbb, const BinaryDataT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct IndirectDataReferenceT : public flatbuffers::NativeTable {
  typedef IndirectDataReference TableType;
  uint64_t data_index;
  uint64_t sparsity_index;
  uint64_t storage_element_index;
  uint32_t storage_element_size;
  IndirectDataReferenceT()
      : data_index(999999999999999999ULL),
        sparsity_index(999999999999999999ULL),
        storage_element_index(999999999999999999ULL),
        storage_element_size(0) {
  }
};

struct IndirectDataReference FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef IndirectDataReferenceT NativeTableType;
  typedef IndirectDataReferenceBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_DATA_INDEX = 4,
    VT_SPARSITY_INDEX = 6,
    VT_STORAGE_ELEMENT_INDEX = 8,
    VT_STORAGE_ELEMENT_SIZE = 10
  };
  /// Index/Offsets from the start of a memory location (see MemoryLocation)
  ///
  /// The base address of a memory location is calculated via "MemoryLocation" and "Locale_Index".
  /// The Memory Location informs the device "what class" of Memory we are dealing with and the
  /// Locale Index informs "which one" when there are multiple.
  /// (e.g. Use the 2nd Programmable Input Buffer)
  /// (e.g. Use the 8th Index of the GraphFile's Binary Data)
  /// The relative offset to the data is then below as data_index.
  /// In some circumstances, you may require a larger buffer than nessicary (e.g. software overwrite)
  /// This buffer should be allocated and then the "leading_offset" and "trailing_offset" fields of TensorReference
  /// used to access the 'corrected' start of the tensor. This should be a rare circumstance.
  /// For device buffers, most of the time we are dealing with a starting pointer and a total size.
  uint64_t data_index() const {
    return GetField<uint64_t>(VT_DATA_INDEX, 999999999999999999ULL);
  }
  uint64_t sparsity_index() const {
    return GetField<uint64_t>(VT_SPARSITY_INDEX, 999999999999999999ULL);
  }
  uint64_t storage_element_index() const {
    return GetField<uint64_t>(VT_STORAGE_ELEMENT_INDEX, 999999999999999999ULL);
  }
  uint32_t storage_element_size() const {
    return GetField<uint32_t>(VT_STORAGE_ELEMENT_SIZE, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint64_t>(verifier, VT_DATA_INDEX) &&
           VerifyField<uint64_t>(verifier, VT_SPARSITY_INDEX) &&
           VerifyField<uint64_t>(verifier, VT_STORAGE_ELEMENT_INDEX) &&
           VerifyField<uint32_t>(verifier, VT_STORAGE_ELEMENT_SIZE) &&
           verifier.EndTable();
  }
  IndirectDataReferenceT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(IndirectDataReferenceT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<IndirectDataReference> Pack(flatbuffers::FlatBufferBuilder &_fbb, const IndirectDataReferenceT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct IndirectDataReferenceBuilder {
  typedef IndirectDataReference Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_data_index(uint64_t data_index) {
    fbb_.AddElement<uint64_t>(IndirectDataReference::VT_DATA_INDEX, data_index, 999999999999999999ULL);
  }
  void add_sparsity_index(uint64_t sparsity_index) {
    fbb_.AddElement<uint64_t>(IndirectDataReference::VT_SPARSITY_INDEX, sparsity_index, 999999999999999999ULL);
  }
  void add_storage_element_index(uint64_t storage_element_index) {
    fbb_.AddElement<uint64_t>(IndirectDataReference::VT_STORAGE_ELEMENT_INDEX, storage_element_index, 999999999999999999ULL);
  }
  void add_storage_element_size(uint32_t storage_element_size) {
    fbb_.AddElement<uint32_t>(IndirectDataReference::VT_STORAGE_ELEMENT_SIZE, storage_element_size, 0);
  }
  explicit IndirectDataReferenceBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  IndirectDataReferenceBuilder &operator=(const IndirectDataReferenceBuilder &);
  flatbuffers::Offset<IndirectDataReference> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<IndirectDataReference>(end);
    return o;
  }
};

inline flatbuffers::Offset<IndirectDataReference> CreateIndirectDataReference(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t data_index = 999999999999999999ULL,
    uint64_t sparsity_index = 999999999999999999ULL,
    uint64_t storage_element_index = 999999999999999999ULL,
    uint32_t storage_element_size = 0) {
  IndirectDataReferenceBuilder builder_(_fbb);
  builder_.add_storage_element_index(storage_element_index);
  builder_.add_sparsity_index(sparsity_index);
  builder_.add_data_index(data_index);
  builder_.add_storage_element_size(storage_element_size);
  return builder_.Finish();
}

flatbuffers::Offset<IndirectDataReference> CreateIndirectDataReference(flatbuffers::FlatBufferBuilder &_fbb, const IndirectDataReferenceT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct TensorReferenceT : public flatbuffers::NativeTable {
  typedef TensorReference TableType;
  std::string name;
  std::vector<uint32_t> dimensions;
  std::vector<float> strides;
  uint32_t leading_offset;
  uint32_t trailing_offset;
  std::unique_ptr<MVCNN::IndirectDataReferenceT> data;
  MVCNN::MemoryLocation locale;
  std::vector<uint32_t> locale_index;
  MVCNN::DType data_dtype;
  std::vector<uint8_t> quant_zero;
  std::vector<uint16_t> quant_mult;
  std::vector<uint8_t> quant_shift;
  int8_t quant_post_shift_right;
  uint64_t order;
  float density_rate;
  uint8_t swizzling_key;
  TensorReferenceT()
      : leading_offset(0),
        trailing_offset(0),
        locale(MVCNN::MemoryLocation_NULL),
        data_dtype(MVCNN::DType_NOT_SET),
        quant_post_shift_right(0),
        order(0),
        density_rate(1.0f),
        swizzling_key(0) {
  }
};

struct TensorReference FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef TensorReferenceT NativeTableType;
  typedef TensorReferenceBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_NAME = 4,
    VT_DIMENSIONS = 6,
    VT_STRIDES = 8,
    VT_LEADING_OFFSET = 10,
    VT_TRAILING_OFFSET = 12,
    VT_DATA = 14,
    VT_LOCALE = 16,
    VT_LOCALE_INDEX = 18,
    VT_DATA_DTYPE = 20,
    VT_QUANT_ZERO = 22,
    VT_QUANT_MULT = 24,
    VT_QUANT_SHIFT = 26,
    VT_QUANT_POST_SHIFT_RIGHT = 28,
    VT_ORDER = 30,
    VT_DENSITY_RATE = 32,
    VT_SWIZZLING_KEY = 34
  };
  /// Information on how to access a Tensor
  const flatbuffers::String *name() const {
    return GetPointer<const flatbuffers::String *>(VT_NAME);
  }
  const flatbuffers::Vector<uint32_t> *dimensions() const {
    return GetPointer<const flatbuffers::Vector<uint32_t> *>(VT_DIMENSIONS);
  }
  const flatbuffers::Vector<float> *strides() const {
    return GetPointer<const flatbuffers::Vector<float> *>(VT_STRIDES);
  }
  uint32_t leading_offset() const {
    return GetField<uint32_t>(VT_LEADING_OFFSET, 0);
  }
  uint32_t trailing_offset() const {
    return GetField<uint32_t>(VT_TRAILING_OFFSET, 0);
  }
  const MVCNN::IndirectDataReference *data() const {
    return GetPointer<const MVCNN::IndirectDataReference *>(VT_DATA);
  }
  MVCNN::MemoryLocation locale() const {
    return static_cast<MVCNN::MemoryLocation>(GetField<int8_t>(VT_LOCALE, 0));
  }
  const flatbuffers::Vector<uint32_t> *locale_index() const {
    return GetPointer<const flatbuffers::Vector<uint32_t> *>(VT_LOCALE_INDEX);
  }
  MVCNN::DType data_dtype() const {
    return static_cast<MVCNN::DType>(GetField<int8_t>(VT_DATA_DTYPE, 0));
  }
  const flatbuffers::Vector<uint8_t> *quant_zero() const {
    return GetPointer<const flatbuffers::Vector<uint8_t> *>(VT_QUANT_ZERO);
  }
  const flatbuffers::Vector<uint16_t> *quant_mult() const {
    return GetPointer<const flatbuffers::Vector<uint16_t> *>(VT_QUANT_MULT);
  }
  const flatbuffers::Vector<uint8_t> *quant_shift() const {
    return GetPointer<const flatbuffers::Vector<uint8_t> *>(VT_QUANT_SHIFT);
  }
  int8_t quant_post_shift_right() const {
    return GetField<int8_t>(VT_QUANT_POST_SHIFT_RIGHT, 0);
  }
  uint64_t order() const {
    return GetField<uint64_t>(VT_ORDER, 0);
  }
  float density_rate() const {
    return GetField<float>(VT_DENSITY_RATE, 1.0f);
  }
  uint8_t swizzling_key() const {
    return GetField<uint8_t>(VT_SWIZZLING_KEY, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_NAME) &&
           verifier.VerifyString(name()) &&
           VerifyOffset(verifier, VT_DIMENSIONS) &&
           verifier.VerifyVector(dimensions()) &&
           VerifyOffset(verifier, VT_STRIDES) &&
           verifier.VerifyVector(strides()) &&
           VerifyField<uint32_t>(verifier, VT_LEADING_OFFSET) &&
           VerifyField<uint32_t>(verifier, VT_TRAILING_OFFSET) &&
           VerifyOffset(verifier, VT_DATA) &&
           verifier.VerifyTable(data()) &&
           VerifyField<int8_t>(verifier, VT_LOCALE) &&
           VerifyOffset(verifier, VT_LOCALE_INDEX) &&
           verifier.VerifyVector(locale_index()) &&
           VerifyField<int8_t>(verifier, VT_DATA_DTYPE) &&
           VerifyOffset(verifier, VT_QUANT_ZERO) &&
           verifier.VerifyVector(quant_zero()) &&
           VerifyOffset(verifier, VT_QUANT_MULT) &&
           verifier.VerifyVector(quant_mult()) &&
           VerifyOffset(verifier, VT_QUANT_SHIFT) &&
           verifier.VerifyVector(quant_shift()) &&
           VerifyField<int8_t>(verifier, VT_QUANT_POST_SHIFT_RIGHT) &&
           VerifyField<uint64_t>(verifier, VT_ORDER) &&
           VerifyField<float>(verifier, VT_DENSITY_RATE) &&
           VerifyField<uint8_t>(verifier, VT_SWIZZLING_KEY) &&
           verifier.EndTable();
  }
  TensorReferenceT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(TensorReferenceT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<TensorReference> Pack(flatbuffers::FlatBufferBuilder &_fbb, const TensorReferenceT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct TensorReferenceBuilder {
  typedef TensorReference Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_name(flatbuffers::Offset<flatbuffers::String> name) {
    fbb_.AddOffset(TensorReference::VT_NAME, name);
  }
  void add_dimensions(flatbuffers::Offset<flatbuffers::Vector<uint32_t>> dimensions) {
    fbb_.AddOffset(TensorReference::VT_DIMENSIONS, dimensions);
  }
  void add_strides(flatbuffers::Offset<flatbuffers::Vector<float>> strides) {
    fbb_.AddOffset(TensorReference::VT_STRIDES, strides);
  }
  void add_leading_offset(uint32_t leading_offset) {
    fbb_.AddElement<uint32_t>(TensorReference::VT_LEADING_OFFSET, leading_offset, 0);
  }
  void add_trailing_offset(uint32_t trailing_offset) {
    fbb_.AddElement<uint32_t>(TensorReference::VT_TRAILING_OFFSET, trailing_offset, 0);
  }
  void add_data(flatbuffers::Offset<MVCNN::IndirectDataReference> data) {
    fbb_.AddOffset(TensorReference::VT_DATA, data);
  }
  void add_locale(MVCNN::MemoryLocation locale) {
    fbb_.AddElement<int8_t>(TensorReference::VT_LOCALE, static_cast<int8_t>(locale), 0);
  }
  void add_locale_index(flatbuffers::Offset<flatbuffers::Vector<uint32_t>> locale_index) {
    fbb_.AddOffset(TensorReference::VT_LOCALE_INDEX, locale_index);
  }
  void add_data_dtype(MVCNN::DType data_dtype) {
    fbb_.AddElement<int8_t>(TensorReference::VT_DATA_DTYPE, static_cast<int8_t>(data_dtype), 0);
  }
  void add_quant_zero(flatbuffers::Offset<flatbuffers::Vector<uint8_t>> quant_zero) {
    fbb_.AddOffset(TensorReference::VT_QUANT_ZERO, quant_zero);
  }
  void add_quant_mult(flatbuffers::Offset<flatbuffers::Vector<uint16_t>> quant_mult) {
    fbb_.AddOffset(TensorReference::VT_QUANT_MULT, quant_mult);
  }
  void add_quant_shift(flatbuffers::Offset<flatbuffers::Vector<uint8_t>> quant_shift) {
    fbb_.AddOffset(TensorReference::VT_QUANT_SHIFT, quant_shift);
  }
  void add_quant_post_shift_right(int8_t quant_post_shift_right) {
    fbb_.AddElement<int8_t>(TensorReference::VT_QUANT_POST_SHIFT_RIGHT, quant_post_shift_right, 0);
  }
  void add_order(uint64_t order) {
    fbb_.AddElement<uint64_t>(TensorReference::VT_ORDER, order, 0);
  }
  void add_density_rate(float density_rate) {
    fbb_.AddElement<float>(TensorReference::VT_DENSITY_RATE, density_rate, 1.0f);
  }
  void add_swizzling_key(uint8_t swizzling_key) {
    fbb_.AddElement<uint8_t>(TensorReference::VT_SWIZZLING_KEY, swizzling_key, 0);
  }
  explicit TensorReferenceBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  TensorReferenceBuilder &operator=(const TensorReferenceBuilder &);
  flatbuffers::Offset<TensorReference> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<TensorReference>(end);
    return o;
  }
};

inline flatbuffers::Offset<TensorReference> CreateTensorReference(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> name = 0,
    flatbuffers::Offset<flatbuffers::Vector<uint32_t>> dimensions = 0,
    flatbuffers::Offset<flatbuffers::Vector<float>> strides = 0,
    uint32_t leading_offset = 0,
    uint32_t trailing_offset = 0,
    flatbuffers::Offset<MVCNN::IndirectDataReference> data = 0,
    MVCNN::MemoryLocation locale = MVCNN::MemoryLocation_NULL,
    flatbuffers::Offset<flatbuffers::Vector<uint32_t>> locale_index = 0,
    MVCNN::DType data_dtype = MVCNN::DType_NOT_SET,
    flatbuffers::Offset<flatbuffers::Vector<uint8_t>> quant_zero = 0,
    flatbuffers::Offset<flatbuffers::Vector<uint16_t>> quant_mult = 0,
    flatbuffers::Offset<flatbuffers::Vector<uint8_t>> quant_shift = 0,
    int8_t quant_post_shift_right = 0,
    uint64_t order = 0,
    float density_rate = 1.0f,
    uint8_t swizzling_key = 0) {
  TensorReferenceBuilder builder_(_fbb);
  builder_.add_order(order);
  builder_.add_density_rate(density_rate);
  builder_.add_quant_shift(quant_shift);
  builder_.add_quant_mult(quant_mult);
  builder_.add_quant_zero(quant_zero);
  builder_.add_locale_index(locale_index);
  builder_.add_data(data);
  builder_.add_trailing_offset(trailing_offset);
  builder_.add_leading_offset(leading_offset);
  builder_.add_strides(strides);
  builder_.add_dimensions(dimensions);
  builder_.add_name(name);
  builder_.add_swizzling_key(swizzling_key);
  builder_.add_quant_post_shift_right(quant_post_shift_right);
  builder_.add_data_dtype(data_dtype);
  builder_.add_locale(locale);
  return builder_.Finish();
}

inline flatbuffers::Offset<TensorReference> CreateTensorReferenceDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *name = nullptr,
    const std::vector<uint32_t> *dimensions = nullptr,
    const std::vector<float> *strides = nullptr,
    uint32_t leading_offset = 0,
    uint32_t trailing_offset = 0,
    flatbuffers::Offset<MVCNN::IndirectDataReference> data = 0,
    MVCNN::MemoryLocation locale = MVCNN::MemoryLocation_NULL,
    const std::vector<uint32_t> *locale_index = nullptr,
    MVCNN::DType data_dtype = MVCNN::DType_NOT_SET,
    const std::vector<uint8_t> *quant_zero = nullptr,
    const std::vector<uint16_t> *quant_mult = nullptr,
    const std::vector<uint8_t> *quant_shift = nullptr,
    int8_t quant_post_shift_right = 0,
    uint64_t order = 0,
    float density_rate = 1.0f,
    uint8_t swizzling_key = 0) {
  auto name__ = name ? _fbb.CreateString(name) : 0;
  auto dimensions__ = dimensions ? _fbb.CreateVector<uint32_t>(*dimensions) : 0;
  auto strides__ = strides ? _fbb.CreateVector<float>(*strides) : 0;
  auto locale_index__ = locale_index ? _fbb.CreateVector<uint32_t>(*locale_index) : 0;
  auto quant_zero__ = quant_zero ? _fbb.CreateVector<uint8_t>(*quant_zero) : 0;
  auto quant_mult__ = quant_mult ? _fbb.CreateVector<uint16_t>(*quant_mult) : 0;
  auto quant_shift__ = quant_shift ? _fbb.CreateVector<uint8_t>(*quant_shift) : 0;
  return MVCNN::CreateTensorReference(
      _fbb,
      name__,
      dimensions__,
      strides__,
      leading_offset,
      trailing_offset,
      data,
      locale,
      locale_index__,
      data_dtype,
      quant_zero__,
      quant_mult__,
      quant_shift__,
      quant_post_shift_right,
      order,
      density_rate,
      swizzling_key);
}

flatbuffers::Offset<TensorReference> CreateTensorReference(flatbuffers::FlatBufferBuilder &_fbb, const TensorReferenceT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

inline BinaryDataT *BinaryData::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  std::unique_ptr<MVCNN::BinaryDataT> _o = std::unique_ptr<MVCNN::BinaryDataT>(new BinaryDataT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void BinaryData::UnPackTo(BinaryDataT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = underlying_type(); _o->underlying_type = _e; }
  { auto _e = length(); _o->length = _e; }
  { auto _e = padding(); _o->padding = _e; }
  { auto _e = padding2(); _o->padding2 = _e; }
  { auto _e = padding3(); _o->padding3 = _e; }
  { auto _e = padding4(); _o->padding4 = _e; }
  { auto _e = padding5(); _o->padding5 = _e; }
  { auto _e = padding6(); _o->padding6 = _e; }
  { auto _e = padding7(); _o->padding7 = _e; }
  { auto _e = padding8(); _o->padding8 = _e; }
  { auto _e = padding9(); _o->padding9 = _e; }
  { auto _e = padding10(); _o->padding10 = _e; }
  { auto _e = padding11(); _o->padding11 = _e; }
  { auto _e = padding12(); _o->padding12 = _e; }
  { auto _e = padding13(); _o->padding13 = _e; }
  { auto _e = padding14(); _o->padding14 = _e; }
  { auto _e = padding15(); _o->padding15 = _e; }
  { auto _e = padding16(); _o->padding16 = _e; }
  { auto _e = padding17(); _o->padding17 = _e; }
  { auto _e = padding18(); _o->padding18 = _e; }
  { auto _e = padding19(); _o->padding19 = _e; }
  { auto _e = padding20(); _o->padding20 = _e; }
  { auto _e = padding21(); _o->padding21 = _e; }
  { auto _e = padding22(); _o->padding22 = _e; }
  { auto _e = padding23(); _o->padding23 = _e; }
  { auto _e = padding24(); _o->padding24 = _e; }
  { auto _e = padding25(); _o->padding25 = _e; }
  { auto _e = padding26(); _o->padding26 = _e; }
  { auto _e = padding27(); _o->padding27 = _e; }
  { auto _e = padding28(); _o->padding28 = _e; }
  { auto _e = data(); if (_e) { _o->data.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->data[_i] = _e->Get(_i); } } }
  { auto _e = csram_cacheable(); _o->csram_cacheable = _e; }
}

inline flatbuffers::Offset<BinaryData> BinaryData::Pack(flatbuffers::FlatBufferBuilder &_fbb, const BinaryDataT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateBinaryData(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<BinaryData> CreateBinaryData(flatbuffers::FlatBufferBuilder &_fbb, const BinaryDataT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const BinaryDataT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _underlying_type = _o->underlying_type;
  auto _length = _o->length;
  auto _padding = _o->padding;
  auto _padding2 = _o->padding2;
  auto _padding3 = _o->padding3;
  auto _padding4 = _o->padding4;
  auto _padding5 = _o->padding5;
  auto _padding6 = _o->padding6;
  auto _padding7 = _o->padding7;
  auto _padding8 = _o->padding8;
  auto _padding9 = _o->padding9;
  auto _padding10 = _o->padding10;
  auto _padding11 = _o->padding11;
  auto _padding12 = _o->padding12;
  auto _padding13 = _o->padding13;
  auto _padding14 = _o->padding14;
  auto _padding15 = _o->padding15;
  auto _padding16 = _o->padding16;
  auto _padding17 = _o->padding17;
  auto _padding18 = _o->padding18;
  auto _padding19 = _o->padding19;
  auto _padding20 = _o->padding20;
  auto _padding21 = _o->padding21;
  auto _padding22 = _o->padding22;
  auto _padding23 = _o->padding23;
  auto _padding24 = _o->padding24;
  auto _padding25 = _o->padding25;
  auto _padding26 = _o->padding26;
  auto _padding27 = _o->padding27;
  auto _padding28 = _o->padding28;
  auto _data = _fbb.CreateVector(_o->data);
  auto _csram_cacheable = _o->csram_cacheable;
  return MVCNN::CreateBinaryData(
      _fbb,
      _underlying_type,
      _length,
      _padding,
      _padding2,
      _padding3,
      _padding4,
      _padding5,
      _padding6,
      _padding7,
      _padding8,
      _padding9,
      _padding10,
      _padding11,
      _padding12,
      _padding13,
      _padding14,
      _padding15,
      _padding16,
      _padding17,
      _padding18,
      _padding19,
      _padding20,
      _padding21,
      _padding22,
      _padding23,
      _padding24,
      _padding25,
      _padding26,
      _padding27,
      _padding28,
      _data,
      _csram_cacheable);
}

inline IndirectDataReferenceT *IndirectDataReference::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  std::unique_ptr<MVCNN::IndirectDataReferenceT> _o = std::unique_ptr<MVCNN::IndirectDataReferenceT>(new IndirectDataReferenceT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void IndirectDataReference::UnPackTo(IndirectDataReferenceT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = data_index(); _o->data_index = _e; }
  { auto _e = sparsity_index(); _o->sparsity_index = _e; }
  { auto _e = storage_element_index(); _o->storage_element_index = _e; }
  { auto _e = storage_element_size(); _o->storage_element_size = _e; }
}

inline flatbuffers::Offset<IndirectDataReference> IndirectDataReference::Pack(flatbuffers::FlatBufferBuilder &_fbb, const IndirectDataReferenceT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateIndirectDataReference(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<IndirectDataReference> CreateIndirectDataReference(flatbuffers::FlatBufferBuilder &_fbb, const IndirectDataReferenceT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const IndirectDataReferenceT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _data_index = _o->data_index;
  auto _sparsity_index = _o->sparsity_index;
  auto _storage_element_index = _o->storage_element_index;
  auto _storage_element_size = _o->storage_element_size;
  return MVCNN::CreateIndirectDataReference(
      _fbb,
      _data_index,
      _sparsity_index,
      _storage_element_index,
      _storage_element_size);
}

inline TensorReferenceT *TensorReference::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  std::unique_ptr<MVCNN::TensorReferenceT> _o = std::unique_ptr<MVCNN::TensorReferenceT>(new TensorReferenceT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void TensorReference::UnPackTo(TensorReferenceT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = name(); if (_e) _o->name = _e->str(); }
  { auto _e = dimensions(); if (_e) { _o->dimensions.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->dimensions[_i] = _e->Get(_i); } } }
  { auto _e = strides(); if (_e) { _o->strides.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->strides[_i] = _e->Get(_i); } } }
  { auto _e = leading_offset(); _o->leading_offset = _e; }
  { auto _e = trailing_offset(); _o->trailing_offset = _e; }
  { auto _e = data(); if (_e) _o->data = std::unique_ptr<MVCNN::IndirectDataReferenceT>(_e->UnPack(_resolver)); }
  { auto _e = locale(); _o->locale = _e; }
  { auto _e = locale_index(); if (_e) { _o->locale_index.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->locale_index[_i] = _e->Get(_i); } } }
  { auto _e = data_dtype(); _o->data_dtype = _e; }
  { auto _e = quant_zero(); if (_e) { _o->quant_zero.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->quant_zero[_i] = _e->Get(_i); } } }
  { auto _e = quant_mult(); if (_e) { _o->quant_mult.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->quant_mult[_i] = _e->Get(_i); } } }
  { auto _e = quant_shift(); if (_e) { _o->quant_shift.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->quant_shift[_i] = _e->Get(_i); } } }
  { auto _e = quant_post_shift_right(); _o->quant_post_shift_right = _e; }
  { auto _e = order(); _o->order = _e; }
  { auto _e = density_rate(); _o->density_rate = _e; }
  { auto _e = swizzling_key(); _o->swizzling_key = _e; }
}

inline flatbuffers::Offset<TensorReference> TensorReference::Pack(flatbuffers::FlatBufferBuilder &_fbb, const TensorReferenceT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateTensorReference(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<TensorReference> CreateTensorReference(flatbuffers::FlatBufferBuilder &_fbb, const TensorReferenceT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const TensorReferenceT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _name = _o->name.empty() ? _fbb.CreateSharedString("") : _fbb.CreateString(_o->name);
  auto _dimensions = _fbb.CreateVector(_o->dimensions);
  auto _strides = _fbb.CreateVector(_o->strides);
  auto _leading_offset = _o->leading_offset;
  auto _trailing_offset = _o->trailing_offset;
  auto _data = _o->data ? CreateIndirectDataReference(_fbb, _o->data.get(), _rehasher) : 0;
  auto _locale = _o->locale;
  auto _locale_index = _fbb.CreateVector(_o->locale_index);
  auto _data_dtype = _o->data_dtype;
  auto _quant_zero = _fbb.CreateVector(_o->quant_zero);
  auto _quant_mult = _fbb.CreateVector(_o->quant_mult);
  auto _quant_shift = _fbb.CreateVector(_o->quant_shift);
  auto _quant_post_shift_right = _o->quant_post_shift_right;
  auto _order = _o->order;
  auto _density_rate = _o->density_rate;
  auto _swizzling_key = _o->swizzling_key;
  return MVCNN::CreateTensorReference(
      _fbb,
      _name,
      _dimensions,
      _strides,
      _leading_offset,
      _trailing_offset,
      _data,
      _locale,
      _locale_index,
      _data_dtype,
      _quant_zero,
      _quant_mult,
      _quant_shift,
      _quant_post_shift_right,
      _order,
      _density_rate,
      _swizzling_key);
}

}  // namespace MVCNN

#endif  // FLATBUFFERS_GENERATED_MEMORYMANAGEMENT_MVCNN_H_
