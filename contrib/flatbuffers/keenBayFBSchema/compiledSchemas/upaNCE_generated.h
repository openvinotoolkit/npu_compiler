// automatically generated by the FlatBuffers compiler, do not modify


#ifndef FLATBUFFERS_GENERATED_UPANCE_MVCNN_H_
#define FLATBUFFERS_GENERATED_UPANCE_MVCNN_H_

#include "flatbuffers/flatbuffers.h"

#include "dma_generated.h"
#include "memoryManagement_generated.h"
#include "software_generated.h"

namespace MVCNN {

struct NCE1Task;

struct NCE1Conv;

struct NCE1Pool;

struct NCE1FCL;

enum NCE1Layer {
  NCE1Layer_NONE = 0,
  NCE1Layer_NCE1Conv = 1,
  NCE1Layer_NCE1Pool = 2,
  NCE1Layer_NCE1FCL = 3,
  NCE1Layer_MIN = NCE1Layer_NONE,
  NCE1Layer_MAX = NCE1Layer_NCE1FCL
};

inline const NCE1Layer (&EnumValuesNCE1Layer())[4] {
  static const NCE1Layer values[] = {
    NCE1Layer_NONE,
    NCE1Layer_NCE1Conv,
    NCE1Layer_NCE1Pool,
    NCE1Layer_NCE1FCL
  };
  return values;
}

inline const char * const *EnumNamesNCE1Layer() {
  static const char * const names[] = {
    "NONE",
    "NCE1Conv",
    "NCE1Pool",
    "NCE1FCL",
    nullptr
  };
  return names;
}

inline const char *EnumNameNCE1Layer(NCE1Layer e) {
  if (e < NCE1Layer_NONE || e > NCE1Layer_NCE1FCL) return "";
  const size_t index = static_cast<int>(e);
  return EnumNamesNCE1Layer()[index];
}

template<typename T> struct NCE1LayerTraits {
  static const NCE1Layer enum_value = NCE1Layer_NONE;
};

template<> struct NCE1LayerTraits<NCE1Conv> {
  static const NCE1Layer enum_value = NCE1Layer_NCE1Conv;
};

template<> struct NCE1LayerTraits<NCE1Pool> {
  static const NCE1Layer enum_value = NCE1Layer_NCE1Pool;
};

template<> struct NCE1LayerTraits<NCE1FCL> {
  static const NCE1Layer enum_value = NCE1Layer_NCE1FCL;
};

bool VerifyNCE1Layer(flatbuffers::Verifier &verifier, const void *obj, NCE1Layer type);
bool VerifyNCE1LayerVector(flatbuffers::Verifier &verifier, const flatbuffers::Vector<flatbuffers::Offset<void>> *values, const flatbuffers::Vector<uint8_t> *types);

struct NCE1Task FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_LAYER_TYPE = 4,
    VT_LAYER = 6
  };
  NCE1Layer layer_type() const {
    return static_cast<NCE1Layer>(GetField<uint8_t>(VT_LAYER_TYPE, 0));
  }
  const void *layer() const {
    return GetPointer<const void *>(VT_LAYER);
  }
  template<typename T> const T *layer_as() const;
  const NCE1Conv *layer_as_NCE1Conv() const {
    return layer_type() == NCE1Layer_NCE1Conv ? static_cast<const NCE1Conv *>(layer()) : nullptr;
  }
  const NCE1Pool *layer_as_NCE1Pool() const {
    return layer_type() == NCE1Layer_NCE1Pool ? static_cast<const NCE1Pool *>(layer()) : nullptr;
  }
  const NCE1FCL *layer_as_NCE1FCL() const {
    return layer_type() == NCE1Layer_NCE1FCL ? static_cast<const NCE1FCL *>(layer()) : nullptr;
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint8_t>(verifier, VT_LAYER_TYPE) &&
           VerifyOffset(verifier, VT_LAYER) &&
           VerifyNCE1Layer(verifier, layer(), layer_type()) &&
           verifier.EndTable();
  }
};

template<> inline const NCE1Conv *NCE1Task::layer_as<NCE1Conv>() const {
  return layer_as_NCE1Conv();
}

template<> inline const NCE1Pool *NCE1Task::layer_as<NCE1Pool>() const {
  return layer_as_NCE1Pool();
}

template<> inline const NCE1FCL *NCE1Task::layer_as<NCE1FCL>() const {
  return layer_as_NCE1FCL();
}

struct NCE1TaskBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_layer_type(NCE1Layer layer_type) {
    fbb_.AddElement<uint8_t>(NCE1Task::VT_LAYER_TYPE, static_cast<uint8_t>(layer_type), 0);
  }
  void add_layer(flatbuffers::Offset<void> layer) {
    fbb_.AddOffset(NCE1Task::VT_LAYER, layer);
  }
  explicit NCE1TaskBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  NCE1TaskBuilder &operator=(const NCE1TaskBuilder &);
  flatbuffers::Offset<NCE1Task> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<NCE1Task>(end);
    return o;
  }
};

inline flatbuffers::Offset<NCE1Task> CreateNCE1Task(
    flatbuffers::FlatBufferBuilder &_fbb,
    NCE1Layer layer_type = NCE1Layer_NONE,
    flatbuffers::Offset<void> layer = 0) {
  NCE1TaskBuilder builder_(_fbb);
  builder_.add_layer(layer);
  builder_.add_layer_type(layer_type);
  return builder_.Finish();
}

struct NCE1Conv FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_STREAMINGMASK = 4,
    VT_INPUTSIZE = 6,
    VT_OUTPUTSIZE = 8,
    VT_CONCATOFFSET = 10,
    VT_UNLOADCMX = 12,
    VT_OVERWRITEINPUT = 14,
    VT_CMXSIZE = 16,
    VT_RELUSHVACC = 18,
    VT_SHVNEGSLOPE = 20,
    VT_SHVPOSSLOPE = 22,
    VT_DESC_COUNT = 24,
    VT_DESCRIPTORS = 26,
    VT_INPUT = 28,
    VT_OUTPUT = 30,
    VT_WEIGHT = 32,
    VT_BIAS = 34
  };
  uint32_t streamingMask() const {
    return GetField<uint32_t>(VT_STREAMINGMASK, 0);
  }
  uint32_t inputSize() const {
    return GetField<uint32_t>(VT_INPUTSIZE, 0);
  }
  uint32_t outputSize() const {
    return GetField<uint32_t>(VT_OUTPUTSIZE, 0);
  }
  uint32_t concatOffset() const {
    return GetField<uint32_t>(VT_CONCATOFFSET, 0);
  }
  uint32_t unloadCMX() const {
    return GetField<uint32_t>(VT_UNLOADCMX, 0);
  }
  uint32_t overwriteInput() const {
    return GetField<uint32_t>(VT_OVERWRITEINPUT, 0);
  }
  uint32_t CMXSize() const {
    return GetField<uint32_t>(VT_CMXSIZE, 0);
  }
  uint32_t reluSHVAcc() const {
    return GetField<uint32_t>(VT_RELUSHVACC, 0);
  }
  uint32_t shvNegSlope() const {
    return GetField<uint32_t>(VT_SHVNEGSLOPE, 0);
  }
  uint32_t shvPosSlope() const {
    return GetField<uint32_t>(VT_SHVPOSSLOPE, 0);
  }
  uint32_t desc_count() const {
    return GetField<uint32_t>(VT_DESC_COUNT, 0);
  }
  const flatbuffers::Vector<int8_t> *descriptors() const {
    return GetPointer<const flatbuffers::Vector<int8_t> *>(VT_DESCRIPTORS);
  }
  const Tensor *input() const {
    return GetPointer<const Tensor *>(VT_INPUT);
  }
  const Tensor *output() const {
    return GetPointer<const Tensor *>(VT_OUTPUT);
  }
  const Tensor *weight() const {
    return GetPointer<const Tensor *>(VT_WEIGHT);
  }
  const Tensor *bias() const {
    return GetPointer<const Tensor *>(VT_BIAS);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint32_t>(verifier, VT_STREAMINGMASK) &&
           VerifyField<uint32_t>(verifier, VT_INPUTSIZE) &&
           VerifyField<uint32_t>(verifier, VT_OUTPUTSIZE) &&
           VerifyField<uint32_t>(verifier, VT_CONCATOFFSET) &&
           VerifyField<uint32_t>(verifier, VT_UNLOADCMX) &&
           VerifyField<uint32_t>(verifier, VT_OVERWRITEINPUT) &&
           VerifyField<uint32_t>(verifier, VT_CMXSIZE) &&
           VerifyField<uint32_t>(verifier, VT_RELUSHVACC) &&
           VerifyField<uint32_t>(verifier, VT_SHVNEGSLOPE) &&
           VerifyField<uint32_t>(verifier, VT_SHVPOSSLOPE) &&
           VerifyField<uint32_t>(verifier, VT_DESC_COUNT) &&
           VerifyOffset(verifier, VT_DESCRIPTORS) &&
           verifier.VerifyVector(descriptors()) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyTable(input()) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyTable(output()) &&
           VerifyOffset(verifier, VT_WEIGHT) &&
           verifier.VerifyTable(weight()) &&
           VerifyOffset(verifier, VT_BIAS) &&
           verifier.VerifyTable(bias()) &&
           verifier.EndTable();
  }
};

struct NCE1ConvBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_streamingMask(uint32_t streamingMask) {
    fbb_.AddElement<uint32_t>(NCE1Conv::VT_STREAMINGMASK, streamingMask, 0);
  }
  void add_inputSize(uint32_t inputSize) {
    fbb_.AddElement<uint32_t>(NCE1Conv::VT_INPUTSIZE, inputSize, 0);
  }
  void add_outputSize(uint32_t outputSize) {
    fbb_.AddElement<uint32_t>(NCE1Conv::VT_OUTPUTSIZE, outputSize, 0);
  }
  void add_concatOffset(uint32_t concatOffset) {
    fbb_.AddElement<uint32_t>(NCE1Conv::VT_CONCATOFFSET, concatOffset, 0);
  }
  void add_unloadCMX(uint32_t unloadCMX) {
    fbb_.AddElement<uint32_t>(NCE1Conv::VT_UNLOADCMX, unloadCMX, 0);
  }
  void add_overwriteInput(uint32_t overwriteInput) {
    fbb_.AddElement<uint32_t>(NCE1Conv::VT_OVERWRITEINPUT, overwriteInput, 0);
  }
  void add_CMXSize(uint32_t CMXSize) {
    fbb_.AddElement<uint32_t>(NCE1Conv::VT_CMXSIZE, CMXSize, 0);
  }
  void add_reluSHVAcc(uint32_t reluSHVAcc) {
    fbb_.AddElement<uint32_t>(NCE1Conv::VT_RELUSHVACC, reluSHVAcc, 0);
  }
  void add_shvNegSlope(uint32_t shvNegSlope) {
    fbb_.AddElement<uint32_t>(NCE1Conv::VT_SHVNEGSLOPE, shvNegSlope, 0);
  }
  void add_shvPosSlope(uint32_t shvPosSlope) {
    fbb_.AddElement<uint32_t>(NCE1Conv::VT_SHVPOSSLOPE, shvPosSlope, 0);
  }
  void add_desc_count(uint32_t desc_count) {
    fbb_.AddElement<uint32_t>(NCE1Conv::VT_DESC_COUNT, desc_count, 0);
  }
  void add_descriptors(flatbuffers::Offset<flatbuffers::Vector<int8_t>> descriptors) {
    fbb_.AddOffset(NCE1Conv::VT_DESCRIPTORS, descriptors);
  }
  void add_input(flatbuffers::Offset<Tensor> input) {
    fbb_.AddOffset(NCE1Conv::VT_INPUT, input);
  }
  void add_output(flatbuffers::Offset<Tensor> output) {
    fbb_.AddOffset(NCE1Conv::VT_OUTPUT, output);
  }
  void add_weight(flatbuffers::Offset<Tensor> weight) {
    fbb_.AddOffset(NCE1Conv::VT_WEIGHT, weight);
  }
  void add_bias(flatbuffers::Offset<Tensor> bias) {
    fbb_.AddOffset(NCE1Conv::VT_BIAS, bias);
  }
  explicit NCE1ConvBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  NCE1ConvBuilder &operator=(const NCE1ConvBuilder &);
  flatbuffers::Offset<NCE1Conv> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<NCE1Conv>(end);
    return o;
  }
};

inline flatbuffers::Offset<NCE1Conv> CreateNCE1Conv(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint32_t streamingMask = 0,
    uint32_t inputSize = 0,
    uint32_t outputSize = 0,
    uint32_t concatOffset = 0,
    uint32_t unloadCMX = 0,
    uint32_t overwriteInput = 0,
    uint32_t CMXSize = 0,
    uint32_t reluSHVAcc = 0,
    uint32_t shvNegSlope = 0,
    uint32_t shvPosSlope = 0,
    uint32_t desc_count = 0,
    flatbuffers::Offset<flatbuffers::Vector<int8_t>> descriptors = 0,
    flatbuffers::Offset<Tensor> input = 0,
    flatbuffers::Offset<Tensor> output = 0,
    flatbuffers::Offset<Tensor> weight = 0,
    flatbuffers::Offset<Tensor> bias = 0) {
  NCE1ConvBuilder builder_(_fbb);
  builder_.add_bias(bias);
  builder_.add_weight(weight);
  builder_.add_output(output);
  builder_.add_input(input);
  builder_.add_descriptors(descriptors);
  builder_.add_desc_count(desc_count);
  builder_.add_shvPosSlope(shvPosSlope);
  builder_.add_shvNegSlope(shvNegSlope);
  builder_.add_reluSHVAcc(reluSHVAcc);
  builder_.add_CMXSize(CMXSize);
  builder_.add_overwriteInput(overwriteInput);
  builder_.add_unloadCMX(unloadCMX);
  builder_.add_concatOffset(concatOffset);
  builder_.add_outputSize(outputSize);
  builder_.add_inputSize(inputSize);
  builder_.add_streamingMask(streamingMask);
  return builder_.Finish();
}

inline flatbuffers::Offset<NCE1Conv> CreateNCE1ConvDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint32_t streamingMask = 0,
    uint32_t inputSize = 0,
    uint32_t outputSize = 0,
    uint32_t concatOffset = 0,
    uint32_t unloadCMX = 0,
    uint32_t overwriteInput = 0,
    uint32_t CMXSize = 0,
    uint32_t reluSHVAcc = 0,
    uint32_t shvNegSlope = 0,
    uint32_t shvPosSlope = 0,
    uint32_t desc_count = 0,
    const std::vector<int8_t> *descriptors = nullptr,
    flatbuffers::Offset<Tensor> input = 0,
    flatbuffers::Offset<Tensor> output = 0,
    flatbuffers::Offset<Tensor> weight = 0,
    flatbuffers::Offset<Tensor> bias = 0) {
  auto descriptors__ = descriptors ? _fbb.CreateVector<int8_t>(*descriptors) : 0;
  return MVCNN::CreateNCE1Conv(
      _fbb,
      streamingMask,
      inputSize,
      outputSize,
      concatOffset,
      unloadCMX,
      overwriteInput,
      CMXSize,
      reluSHVAcc,
      shvNegSlope,
      shvPosSlope,
      desc_count,
      descriptors__,
      input,
      output,
      weight,
      bias);
}

struct NCE1Pool FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_STREAMINGMASK = 4,
    VT_INPUTSIZE = 6,
    VT_OUTPUTSIZE = 8,
    VT_CONCATOFFSET = 10,
    VT_UNLOADCMX = 12,
    VT_OVERWRITEINPUT = 14,
    VT_CMXSIZE = 16,
    VT_RELUSHVACC = 18,
    VT_SHVNEGSLOPE = 20,
    VT_SHVPOSSLOPE = 22,
    VT_DESC_COUNT = 24,
    VT_DESCRIPTORS = 26,
    VT_INPUT = 28,
    VT_OUTPUT = 30,
    VT_WEIGHT = 32,
    VT_BIAS = 34
  };
  uint32_t streamingMask() const {
    return GetField<uint32_t>(VT_STREAMINGMASK, 0);
  }
  uint32_t inputSize() const {
    return GetField<uint32_t>(VT_INPUTSIZE, 0);
  }
  uint32_t outputSize() const {
    return GetField<uint32_t>(VT_OUTPUTSIZE, 0);
  }
  uint32_t concatOffset() const {
    return GetField<uint32_t>(VT_CONCATOFFSET, 0);
  }
  uint32_t unloadCMX() const {
    return GetField<uint32_t>(VT_UNLOADCMX, 0);
  }
  uint32_t overwriteInput() const {
    return GetField<uint32_t>(VT_OVERWRITEINPUT, 0);
  }
  uint32_t CMXSize() const {
    return GetField<uint32_t>(VT_CMXSIZE, 0);
  }
  uint32_t reluSHVAcc() const {
    return GetField<uint32_t>(VT_RELUSHVACC, 0);
  }
  uint32_t shvNegSlope() const {
    return GetField<uint32_t>(VT_SHVNEGSLOPE, 0);
  }
  uint32_t shvPosSlope() const {
    return GetField<uint32_t>(VT_SHVPOSSLOPE, 0);
  }
  uint32_t desc_count() const {
    return GetField<uint32_t>(VT_DESC_COUNT, 0);
  }
  const flatbuffers::Vector<int8_t> *descriptors() const {
    return GetPointer<const flatbuffers::Vector<int8_t> *>(VT_DESCRIPTORS);
  }
  const Tensor *input() const {
    return GetPointer<const Tensor *>(VT_INPUT);
  }
  const Tensor *output() const {
    return GetPointer<const Tensor *>(VT_OUTPUT);
  }
  const Tensor *weight() const {
    return GetPointer<const Tensor *>(VT_WEIGHT);
  }
  const Tensor *bias() const {
    return GetPointer<const Tensor *>(VT_BIAS);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint32_t>(verifier, VT_STREAMINGMASK) &&
           VerifyField<uint32_t>(verifier, VT_INPUTSIZE) &&
           VerifyField<uint32_t>(verifier, VT_OUTPUTSIZE) &&
           VerifyField<uint32_t>(verifier, VT_CONCATOFFSET) &&
           VerifyField<uint32_t>(verifier, VT_UNLOADCMX) &&
           VerifyField<uint32_t>(verifier, VT_OVERWRITEINPUT) &&
           VerifyField<uint32_t>(verifier, VT_CMXSIZE) &&
           VerifyField<uint32_t>(verifier, VT_RELUSHVACC) &&
           VerifyField<uint32_t>(verifier, VT_SHVNEGSLOPE) &&
           VerifyField<uint32_t>(verifier, VT_SHVPOSSLOPE) &&
           VerifyField<uint32_t>(verifier, VT_DESC_COUNT) &&
           VerifyOffset(verifier, VT_DESCRIPTORS) &&
           verifier.VerifyVector(descriptors()) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyTable(input()) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyTable(output()) &&
           VerifyOffset(verifier, VT_WEIGHT) &&
           verifier.VerifyTable(weight()) &&
           VerifyOffset(verifier, VT_BIAS) &&
           verifier.VerifyTable(bias()) &&
           verifier.EndTable();
  }
};

struct NCE1PoolBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_streamingMask(uint32_t streamingMask) {
    fbb_.AddElement<uint32_t>(NCE1Pool::VT_STREAMINGMASK, streamingMask, 0);
  }
  void add_inputSize(uint32_t inputSize) {
    fbb_.AddElement<uint32_t>(NCE1Pool::VT_INPUTSIZE, inputSize, 0);
  }
  void add_outputSize(uint32_t outputSize) {
    fbb_.AddElement<uint32_t>(NCE1Pool::VT_OUTPUTSIZE, outputSize, 0);
  }
  void add_concatOffset(uint32_t concatOffset) {
    fbb_.AddElement<uint32_t>(NCE1Pool::VT_CONCATOFFSET, concatOffset, 0);
  }
  void add_unloadCMX(uint32_t unloadCMX) {
    fbb_.AddElement<uint32_t>(NCE1Pool::VT_UNLOADCMX, unloadCMX, 0);
  }
  void add_overwriteInput(uint32_t overwriteInput) {
    fbb_.AddElement<uint32_t>(NCE1Pool::VT_OVERWRITEINPUT, overwriteInput, 0);
  }
  void add_CMXSize(uint32_t CMXSize) {
    fbb_.AddElement<uint32_t>(NCE1Pool::VT_CMXSIZE, CMXSize, 0);
  }
  void add_reluSHVAcc(uint32_t reluSHVAcc) {
    fbb_.AddElement<uint32_t>(NCE1Pool::VT_RELUSHVACC, reluSHVAcc, 0);
  }
  void add_shvNegSlope(uint32_t shvNegSlope) {
    fbb_.AddElement<uint32_t>(NCE1Pool::VT_SHVNEGSLOPE, shvNegSlope, 0);
  }
  void add_shvPosSlope(uint32_t shvPosSlope) {
    fbb_.AddElement<uint32_t>(NCE1Pool::VT_SHVPOSSLOPE, shvPosSlope, 0);
  }
  void add_desc_count(uint32_t desc_count) {
    fbb_.AddElement<uint32_t>(NCE1Pool::VT_DESC_COUNT, desc_count, 0);
  }
  void add_descriptors(flatbuffers::Offset<flatbuffers::Vector<int8_t>> descriptors) {
    fbb_.AddOffset(NCE1Pool::VT_DESCRIPTORS, descriptors);
  }
  void add_input(flatbuffers::Offset<Tensor> input) {
    fbb_.AddOffset(NCE1Pool::VT_INPUT, input);
  }
  void add_output(flatbuffers::Offset<Tensor> output) {
    fbb_.AddOffset(NCE1Pool::VT_OUTPUT, output);
  }
  void add_weight(flatbuffers::Offset<Tensor> weight) {
    fbb_.AddOffset(NCE1Pool::VT_WEIGHT, weight);
  }
  void add_bias(flatbuffers::Offset<Tensor> bias) {
    fbb_.AddOffset(NCE1Pool::VT_BIAS, bias);
  }
  explicit NCE1PoolBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  NCE1PoolBuilder &operator=(const NCE1PoolBuilder &);
  flatbuffers::Offset<NCE1Pool> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<NCE1Pool>(end);
    return o;
  }
};

inline flatbuffers::Offset<NCE1Pool> CreateNCE1Pool(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint32_t streamingMask = 0,
    uint32_t inputSize = 0,
    uint32_t outputSize = 0,
    uint32_t concatOffset = 0,
    uint32_t unloadCMX = 0,
    uint32_t overwriteInput = 0,
    uint32_t CMXSize = 0,
    uint32_t reluSHVAcc = 0,
    uint32_t shvNegSlope = 0,
    uint32_t shvPosSlope = 0,
    uint32_t desc_count = 0,
    flatbuffers::Offset<flatbuffers::Vector<int8_t>> descriptors = 0,
    flatbuffers::Offset<Tensor> input = 0,
    flatbuffers::Offset<Tensor> output = 0,
    flatbuffers::Offset<Tensor> weight = 0,
    flatbuffers::Offset<Tensor> bias = 0) {
  NCE1PoolBuilder builder_(_fbb);
  builder_.add_bias(bias);
  builder_.add_weight(weight);
  builder_.add_output(output);
  builder_.add_input(input);
  builder_.add_descriptors(descriptors);
  builder_.add_desc_count(desc_count);
  builder_.add_shvPosSlope(shvPosSlope);
  builder_.add_shvNegSlope(shvNegSlope);
  builder_.add_reluSHVAcc(reluSHVAcc);
  builder_.add_CMXSize(CMXSize);
  builder_.add_overwriteInput(overwriteInput);
  builder_.add_unloadCMX(unloadCMX);
  builder_.add_concatOffset(concatOffset);
  builder_.add_outputSize(outputSize);
  builder_.add_inputSize(inputSize);
  builder_.add_streamingMask(streamingMask);
  return builder_.Finish();
}

inline flatbuffers::Offset<NCE1Pool> CreateNCE1PoolDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint32_t streamingMask = 0,
    uint32_t inputSize = 0,
    uint32_t outputSize = 0,
    uint32_t concatOffset = 0,
    uint32_t unloadCMX = 0,
    uint32_t overwriteInput = 0,
    uint32_t CMXSize = 0,
    uint32_t reluSHVAcc = 0,
    uint32_t shvNegSlope = 0,
    uint32_t shvPosSlope = 0,
    uint32_t desc_count = 0,
    const std::vector<int8_t> *descriptors = nullptr,
    flatbuffers::Offset<Tensor> input = 0,
    flatbuffers::Offset<Tensor> output = 0,
    flatbuffers::Offset<Tensor> weight = 0,
    flatbuffers::Offset<Tensor> bias = 0) {
  auto descriptors__ = descriptors ? _fbb.CreateVector<int8_t>(*descriptors) : 0;
  return MVCNN::CreateNCE1Pool(
      _fbb,
      streamingMask,
      inputSize,
      outputSize,
      concatOffset,
      unloadCMX,
      overwriteInput,
      CMXSize,
      reluSHVAcc,
      shvNegSlope,
      shvPosSlope,
      desc_count,
      descriptors__,
      input,
      output,
      weight,
      bias);
}

struct NCE1FCL FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_STREAMINGMASK = 4,
    VT_INPUTSIZE = 6,
    VT_OUTPUTSIZE = 8,
    VT_CONCATOFFSET = 10,
    VT_UNLOADCMX = 12,
    VT_OVERWRITEINPUT = 14,
    VT_CMXSIZE = 16,
    VT_RELUSHVACC = 18,
    VT_SHVNEGSLOPE = 20,
    VT_SHVPOSSLOPE = 22,
    VT_DESC_COUNT = 24,
    VT_DESCRIPTORS = 26,
    VT_INPUT = 28,
    VT_OUTPUT = 30,
    VT_WEIGHT = 32,
    VT_BIAS = 34
  };
  uint32_t streamingMask() const {
    return GetField<uint32_t>(VT_STREAMINGMASK, 0);
  }
  uint32_t inputSize() const {
    return GetField<uint32_t>(VT_INPUTSIZE, 0);
  }
  uint32_t outputSize() const {
    return GetField<uint32_t>(VT_OUTPUTSIZE, 0);
  }
  uint32_t concatOffset() const {
    return GetField<uint32_t>(VT_CONCATOFFSET, 0);
  }
  uint32_t unloadCMX() const {
    return GetField<uint32_t>(VT_UNLOADCMX, 0);
  }
  uint32_t overwriteInput() const {
    return GetField<uint32_t>(VT_OVERWRITEINPUT, 0);
  }
  uint32_t CMXSize() const {
    return GetField<uint32_t>(VT_CMXSIZE, 0);
  }
  uint32_t reluSHVAcc() const {
    return GetField<uint32_t>(VT_RELUSHVACC, 0);
  }
  uint32_t shvNegSlope() const {
    return GetField<uint32_t>(VT_SHVNEGSLOPE, 0);
  }
  uint32_t shvPosSlope() const {
    return GetField<uint32_t>(VT_SHVPOSSLOPE, 0);
  }
  uint32_t desc_count() const {
    return GetField<uint32_t>(VT_DESC_COUNT, 0);
  }
  const flatbuffers::Vector<int8_t> *descriptors() const {
    return GetPointer<const flatbuffers::Vector<int8_t> *>(VT_DESCRIPTORS);
  }
  const Tensor *input() const {
    return GetPointer<const Tensor *>(VT_INPUT);
  }
  const Tensor *output() const {
    return GetPointer<const Tensor *>(VT_OUTPUT);
  }
  const Tensor *weight() const {
    return GetPointer<const Tensor *>(VT_WEIGHT);
  }
  const Tensor *bias() const {
    return GetPointer<const Tensor *>(VT_BIAS);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint32_t>(verifier, VT_STREAMINGMASK) &&
           VerifyField<uint32_t>(verifier, VT_INPUTSIZE) &&
           VerifyField<uint32_t>(verifier, VT_OUTPUTSIZE) &&
           VerifyField<uint32_t>(verifier, VT_CONCATOFFSET) &&
           VerifyField<uint32_t>(verifier, VT_UNLOADCMX) &&
           VerifyField<uint32_t>(verifier, VT_OVERWRITEINPUT) &&
           VerifyField<uint32_t>(verifier, VT_CMXSIZE) &&
           VerifyField<uint32_t>(verifier, VT_RELUSHVACC) &&
           VerifyField<uint32_t>(verifier, VT_SHVNEGSLOPE) &&
           VerifyField<uint32_t>(verifier, VT_SHVPOSSLOPE) &&
           VerifyField<uint32_t>(verifier, VT_DESC_COUNT) &&
           VerifyOffset(verifier, VT_DESCRIPTORS) &&
           verifier.VerifyVector(descriptors()) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyTable(input()) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyTable(output()) &&
           VerifyOffset(verifier, VT_WEIGHT) &&
           verifier.VerifyTable(weight()) &&
           VerifyOffset(verifier, VT_BIAS) &&
           verifier.VerifyTable(bias()) &&
           verifier.EndTable();
  }
};

struct NCE1FCLBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_streamingMask(uint32_t streamingMask) {
    fbb_.AddElement<uint32_t>(NCE1FCL::VT_STREAMINGMASK, streamingMask, 0);
  }
  void add_inputSize(uint32_t inputSize) {
    fbb_.AddElement<uint32_t>(NCE1FCL::VT_INPUTSIZE, inputSize, 0);
  }
  void add_outputSize(uint32_t outputSize) {
    fbb_.AddElement<uint32_t>(NCE1FCL::VT_OUTPUTSIZE, outputSize, 0);
  }
  void add_concatOffset(uint32_t concatOffset) {
    fbb_.AddElement<uint32_t>(NCE1FCL::VT_CONCATOFFSET, concatOffset, 0);
  }
  void add_unloadCMX(uint32_t unloadCMX) {
    fbb_.AddElement<uint32_t>(NCE1FCL::VT_UNLOADCMX, unloadCMX, 0);
  }
  void add_overwriteInput(uint32_t overwriteInput) {
    fbb_.AddElement<uint32_t>(NCE1FCL::VT_OVERWRITEINPUT, overwriteInput, 0);
  }
  void add_CMXSize(uint32_t CMXSize) {
    fbb_.AddElement<uint32_t>(NCE1FCL::VT_CMXSIZE, CMXSize, 0);
  }
  void add_reluSHVAcc(uint32_t reluSHVAcc) {
    fbb_.AddElement<uint32_t>(NCE1FCL::VT_RELUSHVACC, reluSHVAcc, 0);
  }
  void add_shvNegSlope(uint32_t shvNegSlope) {
    fbb_.AddElement<uint32_t>(NCE1FCL::VT_SHVNEGSLOPE, shvNegSlope, 0);
  }
  void add_shvPosSlope(uint32_t shvPosSlope) {
    fbb_.AddElement<uint32_t>(NCE1FCL::VT_SHVPOSSLOPE, shvPosSlope, 0);
  }
  void add_desc_count(uint32_t desc_count) {
    fbb_.AddElement<uint32_t>(NCE1FCL::VT_DESC_COUNT, desc_count, 0);
  }
  void add_descriptors(flatbuffers::Offset<flatbuffers::Vector<int8_t>> descriptors) {
    fbb_.AddOffset(NCE1FCL::VT_DESCRIPTORS, descriptors);
  }
  void add_input(flatbuffers::Offset<Tensor> input) {
    fbb_.AddOffset(NCE1FCL::VT_INPUT, input);
  }
  void add_output(flatbuffers::Offset<Tensor> output) {
    fbb_.AddOffset(NCE1FCL::VT_OUTPUT, output);
  }
  void add_weight(flatbuffers::Offset<Tensor> weight) {
    fbb_.AddOffset(NCE1FCL::VT_WEIGHT, weight);
  }
  void add_bias(flatbuffers::Offset<Tensor> bias) {
    fbb_.AddOffset(NCE1FCL::VT_BIAS, bias);
  }
  explicit NCE1FCLBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  NCE1FCLBuilder &operator=(const NCE1FCLBuilder &);
  flatbuffers::Offset<NCE1FCL> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<NCE1FCL>(end);
    return o;
  }
};

inline flatbuffers::Offset<NCE1FCL> CreateNCE1FCL(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint32_t streamingMask = 0,
    uint32_t inputSize = 0,
    uint32_t outputSize = 0,
    uint32_t concatOffset = 0,
    uint32_t unloadCMX = 0,
    uint32_t overwriteInput = 0,
    uint32_t CMXSize = 0,
    uint32_t reluSHVAcc = 0,
    uint32_t shvNegSlope = 0,
    uint32_t shvPosSlope = 0,
    uint32_t desc_count = 0,
    flatbuffers::Offset<flatbuffers::Vector<int8_t>> descriptors = 0,
    flatbuffers::Offset<Tensor> input = 0,
    flatbuffers::Offset<Tensor> output = 0,
    flatbuffers::Offset<Tensor> weight = 0,
    flatbuffers::Offset<Tensor> bias = 0) {
  NCE1FCLBuilder builder_(_fbb);
  builder_.add_bias(bias);
  builder_.add_weight(weight);
  builder_.add_output(output);
  builder_.add_input(input);
  builder_.add_descriptors(descriptors);
  builder_.add_desc_count(desc_count);
  builder_.add_shvPosSlope(shvPosSlope);
  builder_.add_shvNegSlope(shvNegSlope);
  builder_.add_reluSHVAcc(reluSHVAcc);
  builder_.add_CMXSize(CMXSize);
  builder_.add_overwriteInput(overwriteInput);
  builder_.add_unloadCMX(unloadCMX);
  builder_.add_concatOffset(concatOffset);
  builder_.add_outputSize(outputSize);
  builder_.add_inputSize(inputSize);
  builder_.add_streamingMask(streamingMask);
  return builder_.Finish();
}

inline flatbuffers::Offset<NCE1FCL> CreateNCE1FCLDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint32_t streamingMask = 0,
    uint32_t inputSize = 0,
    uint32_t outputSize = 0,
    uint32_t concatOffset = 0,
    uint32_t unloadCMX = 0,
    uint32_t overwriteInput = 0,
    uint32_t CMXSize = 0,
    uint32_t reluSHVAcc = 0,
    uint32_t shvNegSlope = 0,
    uint32_t shvPosSlope = 0,
    uint32_t desc_count = 0,
    const std::vector<int8_t> *descriptors = nullptr,
    flatbuffers::Offset<Tensor> input = 0,
    flatbuffers::Offset<Tensor> output = 0,
    flatbuffers::Offset<Tensor> weight = 0,
    flatbuffers::Offset<Tensor> bias = 0) {
  auto descriptors__ = descriptors ? _fbb.CreateVector<int8_t>(*descriptors) : 0;
  return MVCNN::CreateNCE1FCL(
      _fbb,
      streamingMask,
      inputSize,
      outputSize,
      concatOffset,
      unloadCMX,
      overwriteInput,
      CMXSize,
      reluSHVAcc,
      shvNegSlope,
      shvPosSlope,
      desc_count,
      descriptors__,
      input,
      output,
      weight,
      bias);
}

inline bool VerifyNCE1Layer(flatbuffers::Verifier &verifier, const void *obj, NCE1Layer type) {
  switch (type) {
    case NCE1Layer_NONE: {
      return true;
    }
    case NCE1Layer_NCE1Conv: {
      auto ptr = reinterpret_cast<const NCE1Conv *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case NCE1Layer_NCE1Pool: {
      auto ptr = reinterpret_cast<const NCE1Pool *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case NCE1Layer_NCE1FCL: {
      auto ptr = reinterpret_cast<const NCE1FCL *>(obj);
      return verifier.VerifyTable(ptr);
    }
    default: return false;
  }
}

inline bool VerifyNCE1LayerVector(flatbuffers::Verifier &verifier, const flatbuffers::Vector<flatbuffers::Offset<void>> *values, const flatbuffers::Vector<uint8_t> *types) {
  if (!values || !types) return !values && !types;
  if (values->size() != types->size()) return false;
  for (flatbuffers::uoffset_t i = 0; i < values->size(); ++i) {
    if (!VerifyNCE1Layer(
        verifier,  values->Get(i), types->GetEnum<NCE1Layer>(i))) {
      return false;
    }
  }
  return true;
}

}  // namespace MVCNN

#endif  // FLATBUFFERS_GENERATED_UPANCE_MVCNN_H_
